
kernel.riscv:     file format elf32-littleriscv


Disassembly of section .dmem:

00000000 <_interrupt_arr>:
	...

Disassembly of section .sdata.dmem:

00000008 <__bsg_tile_group_id>:
int __bsg_grp_org_y = -1;
int __bsg_grid_dim_x = -1;
int __bsg_grid_dim_y = -1;
int __bsg_tile_group_id_x = -1;
int __bsg_tile_group_id_y = -1;
int __bsg_tile_group_id = -1;
   8:	ffff                	0xffff
  .globl _start
_start:
  li  x1, 0
  // li  x2, 0
  li  x3, 0
  li  x4, 0
   a:	ffff                	0xffff

0000000c <__bsg_tile_group_id_y>:
int __bsg_tile_group_id_y = -1;
   c:	ffff                	0xffff
  li  x5, 0
   e:	ffff                	0xffff

00000010 <__bsg_tile_group_id_x>:
int __bsg_tile_group_id_x = -1;
  10:	ffff                	0xffff
  li  x6, 0
  12:	ffff                	0xffff

00000014 <__bsg_grid_dim_y>:
int __bsg_grid_dim_y = -1;
  14:	ffff                	0xffff
  li  x7, 0
  16:	ffff                	0xffff

00000018 <__bsg_grid_dim_x>:
int __bsg_grid_dim_x = -1;
  18:	ffff                	0xffff
  li  x8, 0
  1a:	ffff                	0xffff

0000001c <__bsg_grp_org_y>:
int __bsg_grp_org_y = -1;
  1c:	ffff                	0xffff
  li  x9, 0
  1e:	ffff                	0xffff

00000020 <__bsg_grp_org_x>:
int __bsg_grp_org_x = -1;
  20:	ffff                	0xffff
  li  x10,0
  22:	ffff                	0xffff

00000024 <__bsg_id>:
int __bsg_id = -1;
  24:	ffff                	0xffff
  li  x11,0
  26:	ffff                	0xffff

00000028 <__bsg_y>:
int __bsg_y = -1;
  28:	ffff                	0xffff
  li  x12,0
  2a:	ffff                	0xffff

0000002c <__bsg_x>:
int __bsg_x = -1;
  2c:	ffff                	0xffff
  li  x13,0
  2e:	ffff                	0xffff
	...

Disassembly of section .init_array:

00000038 <.init_array>:
  li  x14,0
  li  x15,0
  li  x16,0
  38:	0e38                	addi	x14,x2,792
	...

Disassembly of section .sbss.dmem:

0000003c <cuda_kernel_not_loaded_val>:
 // Location kernel writes it's finish signal into
uint32_t cuda_finish_signal_addr = 0;
// The value that kernel writes in cuda_finish_signal_addr when it is finished
uint32_t cuda_finish_signal_val = 0;
// When cuda_kernel_ptr equals this value means the kernel is not loaded 
uint32_t cuda_kernel_not_loaded_val = 0;
  3c:	0000                	unimp
	...

00000040 <cuda_finish_signal_val>:
uint32_t cuda_finish_signal_val = 0;
  40:	0000                	unimp
	...

00000044 <cuda_finish_signal_addr>:
uint32_t cuda_finish_signal_addr = 0;
  44:	0000                	unimp
	...

00000048 <cuda_argv_ptr>:
uint32_t cuda_argv_ptr = 0;
  48:	0000                	unimp
	...

0000004c <cuda_argc>:
uint32_t cuda_argc = 0;	
  4c:	0000                	unimp
	...

00000050 <cuda_kernel_ptr>:
	...

Disassembly of section .bss.dmem:

00000058 <barrier>:
	...

Disassembly of section .text.dram:

00000000 <_start>:
  li  x1, 0
   0:	00000093          	li	x1,0
  li  x3, 0
   4:	00000193          	li	x3,0
  li  x4, 0
   8:	00000213          	li	x4,0
  li  x5, 0
   c:	00000293          	li	x5,0
  li  x6, 0
  10:	00000313          	li	x6,0
  li  x7, 0
  14:	00000393          	li	x7,0
  li  x8, 0
  18:	00000413          	li	x8,0
  li  x9, 0
  1c:	00000493          	li	x9,0
  li  x10,0
  20:	00000513          	li	x10,0
  li  x11,0
  24:	00000593          	li	x11,0
  li  x12,0
  28:	00000613          	li	x12,0
  li  x13,0
  2c:	00000693          	li	x13,0
  li  x14,0
  30:	00000713          	li	x14,0
  li  x15,0
  34:	00000793          	li	x15,0
  li  x16,0
  38:	00000813          	li	x16,0
  li  x17,0
  3c:	00000893          	li	x17,0
  li  x18,0
  40:	00000913          	li	x18,0
  li  x19,0
  44:	00000993          	li	x19,0
  li  x20,0
  48:	00000a13          	li	x20,0
  li  x21,0
  4c:	00000a93          	li	x21,0
  li  x22,0
  50:	00000b13          	li	x22,0
  li  x23,0
  54:	00000b93          	li	x23,0
  li  x24,0
  58:	00000c13          	li	x24,0
  li  x25,0
  5c:	00000c93          	li	x25,0
  li  x26,0
  60:	00000d13          	li	x26,0
  li  x27,0
  64:	00000d93          	li	x27,0
  li  x28,0
  68:	00000e13          	li	x28,0
  li  x29,0
  6c:	00000e93          	li	x29,0
  li  x30,0
  70:	00000f13          	li	x30,0
  li  x31,0
  74:	00000f93          	li	x31,0
  # Enable FPU and clear fcsr.
  #
  # These are ignored by manycore hardware but might be
  # required by execution environments supporting 
  # exceptions (such as Spike).
  li t0, 0x00003000 # mstatus.FS
  78:	000032b7          	lui	x5,0x3
  csrs mstatus, t0 # enable FPU
  7c:	3002a073          	csrs	mstatus,x5
  fscsr x0
  80:	00301073          	fscsr	x0
  li t0, 0
  84:	00000293          	li	x5,0

  fcvt.s.w f0, x0 
  88:	d0007053          	fcvt.s.w	f0,x0
  fcvt.s.w f1, x0 
  8c:	d00070d3          	fcvt.s.w	f1,x0
  fcvt.s.w f2, x0 
  90:	d0007153          	fcvt.s.w	f2,x0
  fcvt.s.w f3, x0 
  94:	d00071d3          	fcvt.s.w	f3,x0
  fcvt.s.w f4, x0 
  98:	d0007253          	fcvt.s.w	f4,x0
  fcvt.s.w f5, x0 
  9c:	d00072d3          	fcvt.s.w	f5,x0
  fcvt.s.w f6, x0 
  a0:	d0007353          	fcvt.s.w	f6,x0
  fcvt.s.w f7, x0 
  a4:	d00073d3          	fcvt.s.w	f7,x0
  fcvt.s.w f8, x0 
  a8:	d0007453          	fcvt.s.w	f8,x0
  fcvt.s.w f9, x0 
  ac:	d00074d3          	fcvt.s.w	f9,x0
  fcvt.s.w f10,x0 
  b0:	d0007553          	fcvt.s.w	f10,x0
  fcvt.s.w f11,x0 
  b4:	d00075d3          	fcvt.s.w	f11,x0
  fcvt.s.w f12,x0 
  b8:	d0007653          	fcvt.s.w	f12,x0
  fcvt.s.w f13,x0 
  bc:	d00076d3          	fcvt.s.w	f13,x0
  fcvt.s.w f14,x0 
  c0:	d0007753          	fcvt.s.w	f14,x0
  fcvt.s.w f15,x0 
  c4:	d00077d3          	fcvt.s.w	f15,x0
  fcvt.s.w f16,x0 
  c8:	d0007853          	fcvt.s.w	f16,x0
  fcvt.s.w f17,x0 
  cc:	d00078d3          	fcvt.s.w	f17,x0
  fcvt.s.w f18,x0 
  d0:	d0007953          	fcvt.s.w	f18,x0
  fcvt.s.w f19,x0 
  d4:	d00079d3          	fcvt.s.w	f19,x0
  fcvt.s.w f20,x0 
  d8:	d0007a53          	fcvt.s.w	f20,x0
  fcvt.s.w f21,x0 
  dc:	d0007ad3          	fcvt.s.w	f21,x0
  fcvt.s.w f22,x0 
  e0:	d0007b53          	fcvt.s.w	f22,x0
  fcvt.s.w f23,x0 
  e4:	d0007bd3          	fcvt.s.w	f23,x0
  fcvt.s.w f24,x0 
  e8:	d0007c53          	fcvt.s.w	f24,x0
  fcvt.s.w f25,x0 
  ec:	d0007cd3          	fcvt.s.w	f25,x0
  fcvt.s.w f26,x0 
  f0:	d0007d53          	fcvt.s.w	f26,x0
  fcvt.s.w f27,x0 
  f4:	d0007dd3          	fcvt.s.w	f27,x0
  fcvt.s.w f28,x0 
  f8:	d0007e53          	fcvt.s.w	f28,x0
  fcvt.s.w f29,x0 
  fc:	d0007ed3          	fcvt.s.w	f29,x0
  fcvt.s.w f30,x0 
 100:	d0007f53          	fcvt.s.w	f30,x0
  fcvt.s.w f31,x0 
 104:	d0007fd3          	fcvt.s.w	f31,x0



  # initialize global pointer
  la gp, _gp
 108:	00000197          	auipc	x3,0x0
 10c:	70018193          	addi	x3,x3,1792 # 808 <_gp>

  la  tp, _bsg_data_end_addr + 63
 110:	0a700213          	li	x4,167
 114:	fc027213          	andi	x4,x4,-64
  and tp, tp, -64
 118:	00001117          	auipc	x2,0x1

  # mbt: put stack at top of local memory
  # mbt fix for 4KB IMEM / 4KB DMEM
  la sp, _sp
 11c:	ee410113          	addi	x2,x2,-284 # ffc <_bsg_elf_stack_ptr>
 120:	5510006f          	j	e70 <main>
  lw a1, -4(sp)    # argv
  li a2, 0         # envp = NULL
  call main
  tail exit
#else
  j main
 124:	0000006f          	j	124 <__dmem_end+0xbc>

00000128 <bsg_set_tile_x_y>:

  bsg_remote_int_ptr grp_org_x_p;
  bsg_remote_int_ptr grp_org_y_p;

  // everybody stores to tile 0,0
  bsg_remote_store(0,0,bsg_x_v,0);
 128:	200007b7          	lui	x15,0x20000
 12c:	02c00593          	li	x11,44
 130:	00b7e2b3          	or	x5,x15,x11
  bsg_remote_store(0,0,bsg_y_v,0);
 134:	02800613          	li	x12,40
  bsg_remote_store(0,0,bsg_x_v,0);
 138:	0002a023          	sw	x0,0(x5) # 3000 <_bsg_elf_stack_ptr+0x2004>
  bsg_remote_store(0,0,bsg_y_v,0);
 13c:	00c7e333          	or	x6,x15,x12
 140:	00032023          	sw	x0,0(x6)

  bsg_wait_while(*bsg_x_v < 0);
 144:	02c02383          	lw	x7,44(x0) # 2c <__bsg_x>
 148:	fe03cee3          	bltz	x7,144 <bsg_set_tile_x_y+0x1c>
  bsg_wait_while(*bsg_y_v < 0);
 14c:	02802503          	lw	x10,40(x0) # 28 <__bsg_y>
 150:	fe054ee3          	bltz	x10,14c <bsg_set_tile_x_y+0x24>

  if (!*bsg_x_v && !*bsg_y_v)
 154:	02c02803          	lw	x16,44(x0) # 2c <__bsg_x>
 158:	00081a63          	bnez	x16,16c <bsg_set_tile_x_y+0x44>
 15c:	02802883          	lw	x17,40(x0) # 28 <__bsg_y>
 160:	00089663          	bnez	x17,16c <bsg_set_tile_x_y+0x44>
    for (int x = 0; x < bsg_tiles_X; x++)
      for (int y = 0; y < bsg_tiles_Y; y++)
      {
        bsg_remote_store(x,y,bsg_x_v,x);
 164:	0002a023          	sw	x0,0(x5)
        bsg_remote_store(x,y,bsg_y_v,y);
 168:	00032023          	sw	x0,0(x6)
      }

  grp_org_x_p = bsg_remote_ptr_control( __bsg_x, __bsg_y, CSR_TGO_X );
 16c:	02802e03          	lw	x28,40(x0) # 28 <__bsg_y>
 170:	02c02e83          	lw	x29,44(x0) # 2c <__bsg_x>
 174:	20020f37          	lui	x30,0x20020
 178:	018e1f93          	slli	x31,x28,0x18
 17c:	012e9713          	slli	x14,x29,0x12
 180:	00efe7b3          	or	x15,x31,x14
 184:	004f0593          	addi	x11,x30,4 # 20020004 <_bsg_elf_vcache_size+0x1ff20004>
 188:	00b7e6b3          	or	x13,x15,x11
  grp_org_y_p = bsg_remote_ptr_control( __bsg_x, __bsg_y, CSR_TGO_Y );

  __bsg_grp_org_x  = * grp_org_x_p;
 18c:	0006a283          	lw	x5,0(x13)
  grp_org_y_p = bsg_remote_ptr_control( __bsg_x, __bsg_y, CSR_TGO_Y );
 190:	008f0613          	addi	x12,x30,8
 194:	00c7e333          	or	x6,x15,x12
  __bsg_grp_org_x  = * grp_org_x_p;
 198:	02502023          	sw	x5,32(x0) # 20 <__bsg_grp_org_x>
  __bsg_grp_org_y  = * grp_org_y_p;
 19c:	00032503          	lw	x10,0(x6)
  __bsg_id = __bsg_y * bsg_tiles_X + __bsg_x;
 1a0:	01de08b3          	add	x17,x28,x29
  __bsg_grid_dim_x = 1;
 1a4:	00100813          	li	x16,1
  __bsg_grp_org_y  = * grp_org_y_p;
 1a8:	00a02e23          	sw	x10,28(x0) # 1c <__bsg_grp_org_y>
  __bsg_id = __bsg_y * bsg_tiles_X + __bsg_x;
 1ac:	03102223          	sw	x17,36(x0) # 24 <__bsg_id>
  __bsg_grid_dim_x = 1;
 1b0:	01002c23          	sw	x16,24(x0) # 18 <__bsg_grid_dim_x>
  __bsg_grid_dim_y = 1;
 1b4:	01002a23          	sw	x16,20(x0) # 14 <__bsg_grid_dim_y>
  __bsg_tile_group_id_x = 0;
 1b8:	00002823          	sw	x0,16(x0) # 10 <__bsg_tile_group_id_x>
  __bsg_tile_group_id_y = 0;
 1bc:	00002623          	sw	x0,12(x0) # c <__bsg_tile_group_id_y>
  __bsg_tile_group_id = 0;
 1c0:	00002423          	sw	x0,8(x0) # 8 <__bsg_tile_group_id>
}
 1c4:	00008067          	ret

000001c8 <write_finish_signal>:



int write_finish_signal () 
{
  if (__bsg_id == 0) 
 1c8:	02402283          	lw	x5,36(x0) # 24 <__bsg_id>
 1cc:	00029863          	bnez	x5,1dc <write_finish_signal+0x14>
  {
     int *signal_ptr = (int *) cuda_finish_signal_addr; 
     *signal_ptr = cuda_finish_signal_val;     
 1d0:	04402383          	lw	x7,68(x0) # 44 <cuda_finish_signal_addr>
 1d4:	04002503          	lw	x10,64(x0) # 40 <cuda_finish_signal_val>
 1d8:	00a3a023          	sw	x10,0(x7)
  }
}
 1dc:	00008067          	ret

000001e0 <kernel_energy_fadd_demo>:
#include <bsg_tile_group_barrier.hpp>

bsg_barrier<bsg_tiles_X, bsg_tiles_Y> barrier;

extern "C" __attribute__ ((noinline))
int kernel_energy_fadd_demo(float *A, float *B, float *C, int N) {
 1e0:	80010113          	addi	x2,x2,-2048
 1e4:	00000793          	li	x15,0
 1e8:	00810813          	addi	x16,x2,8
 1ec:	40410893          	addi	x17,x2,1028
 1f0:	3fc00293          	li	x5,1020
  float B_spm[255];
  float A_tmp, B_tmp, C_tmp = 0.0f;
  float* A_ptr = &A_spm[0];
  float* B_ptr = &B_spm[0];
  for(uint32_t i = 0; i < 255; i++) {
    asm volatile("flw     %0,    0(%1)"   : "=f"(A_tmp) : "r"(A)     : "memory");
 1f4:	00f50733          	add	x14,x10,x15
 1f8:	00072007          	flw	f0,0(x14)
 1fc:	00f88733          	add	x14,x17,x15
 200:	00f586b3          	add	x13,x11,x15
    asm volatile("fsw     %0,    0(%1)"   :: "f"(A_tmp) , "r"(A_ptr) : "memory");
 204:	00072027          	fsw	f0,0(x14)
    asm volatile("flw     %0,    0(%1)"   : "=f"(B_tmp) : "r"(B)     : "memory");
 208:	0006a007          	flw	f0,0(x13)
    asm volatile("flw     %0,    0(%1)"   : "=f"(A_tmp) : "r"(A)     : "memory");
 20c:	00f806b3          	add	x13,x16,x15
    asm volatile("fsw     %0,    0(%1)"   :: "f"(B_tmp) , "r"(B_ptr) : "memory");
 210:	0006a027          	fsw	f0,0(x13)
  for(uint32_t i = 0; i < 255; i++) {
 214:	00478793          	addi	x15,x15,4 # 20000004 <_bsg_elf_vcache_size+0x1ff00004>
 218:	fc579ee3          	bne	x15,x5,1f4 <kernel_energy_fadd_demo+0x14>
    B_ptr++;
  }
  A_ptr = &A_spm[0];
  B_ptr = &B_spm[0];
  //------------------------------------
  bsg_saif_start();
 21c:	00100013          	li	x0,1
  //------------------------------------
  asm volatile("flw     %0,    0(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 220:	0008a087          	flw	f1,0(x17)
  asm volatile("flw     %0,    0(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 224:	00082107          	flw	f2,0(x16)
 228:	03000513          	li	x10,48
 22c:	00052007          	flw	f0,0(x10)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 230:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,    4(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 234:	0048a087          	flw	f1,4(x17)
  asm volatile("flw     %0,    4(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 238:	00482107          	flw	f2,4(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 23c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,    8(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 240:	0088a087          	flw	f1,8(x17)
  asm volatile("flw     %0,    8(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 244:	00882107          	flw	f2,8(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 248:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,   12(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 24c:	00c8a087          	flw	f1,12(x17)
  asm volatile("flw     %0,   12(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 250:	00c82107          	flw	f2,12(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 254:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,   16(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 258:	0108a087          	flw	f1,16(x17)
  asm volatile("flw     %0,   16(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 25c:	01082107          	flw	f2,16(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 260:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,   20(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 264:	0148a087          	flw	f1,20(x17)
  asm volatile("flw     %0,   20(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 268:	01482107          	flw	f2,20(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 26c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,   24(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 270:	0188a087          	flw	f1,24(x17)
  asm volatile("flw     %0,   24(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 274:	01882107          	flw	f2,24(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 278:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,   28(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 27c:	01c8a087          	flw	f1,28(x17)
  asm volatile("flw     %0,   28(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 280:	01c82107          	flw	f2,28(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 284:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,   32(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 288:	0208a087          	flw	f1,32(x17)
  asm volatile("flw     %0,   32(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 28c:	02082107          	flw	f2,32(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 290:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,   36(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 294:	0248a087          	flw	f1,36(x17)
  asm volatile("flw     %0,   36(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 298:	02482107          	flw	f2,36(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 29c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,   40(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2a0:	0288a087          	flw	f1,40(x17)
  asm volatile("flw     %0,   40(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2a4:	02882107          	flw	f2,40(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2a8:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,   44(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2ac:	02c8a087          	flw	f1,44(x17)
  asm volatile("flw     %0,   44(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2b0:	02c82107          	flw	f2,44(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2b4:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,   48(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2b8:	0308a087          	flw	f1,48(x17)
  asm volatile("flw     %0,   48(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2bc:	03082107          	flw	f2,48(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2c0:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,   52(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2c4:	0348a087          	flw	f1,52(x17)
  asm volatile("flw     %0,   52(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2c8:	03482107          	flw	f2,52(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2cc:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,   56(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2d0:	0388a087          	flw	f1,56(x17)
  asm volatile("flw     %0,   56(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2d4:	03882107          	flw	f2,56(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2d8:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,   60(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2dc:	03c8a087          	flw	f1,60(x17)
  asm volatile("flw     %0,   60(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2e0:	03c82107          	flw	f2,60(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2e4:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,   64(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2e8:	0408a087          	flw	f1,64(x17)
  asm volatile("flw     %0,   64(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2ec:	04082107          	flw	f2,64(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2f0:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,   68(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2f4:	0448a087          	flw	f1,68(x17)
  asm volatile("flw     %0,   68(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2f8:	04482107          	flw	f2,68(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2fc:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,   72(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 300:	0488a087          	flw	f1,72(x17)
  asm volatile("flw     %0,   72(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 304:	04882107          	flw	f2,72(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 308:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,   76(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 30c:	04c8a087          	flw	f1,76(x17)
  asm volatile("flw     %0,   76(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 310:	04c82107          	flw	f2,76(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 314:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,   80(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 318:	0508a087          	flw	f1,80(x17)
  asm volatile("flw     %0,   80(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 31c:	05082107          	flw	f2,80(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 320:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,   84(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 324:	0548a087          	flw	f1,84(x17)
  asm volatile("flw     %0,   84(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 328:	05482107          	flw	f2,84(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 32c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,   88(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 330:	0588a087          	flw	f1,88(x17)
  asm volatile("flw     %0,   88(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 334:	05882107          	flw	f2,88(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 338:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,   92(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 33c:	05c8a087          	flw	f1,92(x17)
  asm volatile("flw     %0,   92(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 340:	05c82107          	flw	f2,92(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 344:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,   96(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 348:	0608a087          	flw	f1,96(x17)
  asm volatile("flw     %0,   96(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 34c:	06082107          	flw	f2,96(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 350:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  100(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 354:	0648a087          	flw	f1,100(x17)
  asm volatile("flw     %0,  100(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 358:	06482107          	flw	f2,100(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 35c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  104(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 360:	0688a087          	flw	f1,104(x17)
  asm volatile("flw     %0,  104(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 364:	06882107          	flw	f2,104(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 368:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  108(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 36c:	06c8a087          	flw	f1,108(x17)
  asm volatile("flw     %0,  108(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 370:	06c82107          	flw	f2,108(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 374:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  112(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 378:	0708a087          	flw	f1,112(x17)
  asm volatile("flw     %0,  112(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 37c:	07082107          	flw	f2,112(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 380:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  116(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 384:	0748a087          	flw	f1,116(x17)
  asm volatile("flw     %0,  116(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 388:	07482107          	flw	f2,116(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 38c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  120(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 390:	0788a087          	flw	f1,120(x17)
  asm volatile("flw     %0,  120(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 394:	07882107          	flw	f2,120(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 398:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  124(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 39c:	07c8a087          	flw	f1,124(x17)
  asm volatile("flw     %0,  124(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 3a0:	07c82107          	flw	f2,124(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 3a4:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  128(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 3a8:	0808a087          	flw	f1,128(x17)
  asm volatile("flw     %0,  128(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 3ac:	08082107          	flw	f2,128(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 3b0:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  132(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 3b4:	0848a087          	flw	f1,132(x17)
  asm volatile("flw     %0,  132(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 3b8:	08482107          	flw	f2,132(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 3bc:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  136(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 3c0:	0888a087          	flw	f1,136(x17)
  asm volatile("flw     %0,  136(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 3c4:	08882107          	flw	f2,136(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 3c8:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  140(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 3cc:	08c8a087          	flw	f1,140(x17)
  asm volatile("flw     %0,  140(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 3d0:	08c82107          	flw	f2,140(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 3d4:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  144(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 3d8:	0908a087          	flw	f1,144(x17)
  asm volatile("flw     %0,  144(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 3dc:	09082107          	flw	f2,144(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 3e0:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  148(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 3e4:	0948a087          	flw	f1,148(x17)
  asm volatile("flw     %0,  148(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 3e8:	09482107          	flw	f2,148(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 3ec:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  152(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 3f0:	0988a087          	flw	f1,152(x17)
  asm volatile("flw     %0,  152(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 3f4:	09882107          	flw	f2,152(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 3f8:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  156(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 3fc:	09c8a087          	flw	f1,156(x17)
  asm volatile("flw     %0,  156(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 400:	09c82107          	flw	f2,156(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 404:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  160(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 408:	0a08a087          	flw	f1,160(x17)
  asm volatile("flw     %0,  160(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 40c:	0a082107          	flw	f2,160(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 410:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  164(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 414:	0a48a087          	flw	f1,164(x17)
  asm volatile("flw     %0,  164(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 418:	0a482107          	flw	f2,164(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 41c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  168(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 420:	0a88a087          	flw	f1,168(x17)
  asm volatile("flw     %0,  168(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 424:	0a882107          	flw	f2,168(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 428:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  172(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 42c:	0ac8a087          	flw	f1,172(x17)
  asm volatile("flw     %0,  172(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 430:	0ac82107          	flw	f2,172(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 434:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  176(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 438:	0b08a087          	flw	f1,176(x17)
  asm volatile("flw     %0,  176(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 43c:	0b082107          	flw	f2,176(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 440:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  180(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 444:	0b48a087          	flw	f1,180(x17)
  asm volatile("flw     %0,  180(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 448:	0b482107          	flw	f2,180(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 44c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  184(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 450:	0b88a087          	flw	f1,184(x17)
  asm volatile("flw     %0,  184(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 454:	0b882107          	flw	f2,184(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 458:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  188(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 45c:	0bc8a087          	flw	f1,188(x17)
  asm volatile("flw     %0,  188(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 460:	0bc82107          	flw	f2,188(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 464:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  192(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 468:	0c08a087          	flw	f1,192(x17)
  asm volatile("flw     %0,  192(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 46c:	0c082107          	flw	f2,192(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 470:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  196(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 474:	0c48a087          	flw	f1,196(x17)
  asm volatile("flw     %0,  196(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 478:	0c482107          	flw	f2,196(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 47c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  200(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 480:	0c88a087          	flw	f1,200(x17)
  asm volatile("flw     %0,  200(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 484:	0c882107          	flw	f2,200(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 488:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  204(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 48c:	0cc8a087          	flw	f1,204(x17)
  asm volatile("flw     %0,  204(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 490:	0cc82107          	flw	f2,204(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 494:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  208(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 498:	0d08a087          	flw	f1,208(x17)
  asm volatile("flw     %0,  208(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 49c:	0d082107          	flw	f2,208(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 4a0:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  212(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 4a4:	0d48a087          	flw	f1,212(x17)
  asm volatile("flw     %0,  212(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 4a8:	0d482107          	flw	f2,212(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 4ac:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  216(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 4b0:	0d88a087          	flw	f1,216(x17)
  asm volatile("flw     %0,  216(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 4b4:	0d882107          	flw	f2,216(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 4b8:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  220(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 4bc:	0dc8a087          	flw	f1,220(x17)
  asm volatile("flw     %0,  220(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 4c0:	0dc82107          	flw	f2,220(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 4c4:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  224(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 4c8:	0e08a087          	flw	f1,224(x17)
  asm volatile("flw     %0,  224(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 4cc:	0e082107          	flw	f2,224(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 4d0:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  228(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 4d4:	0e48a087          	flw	f1,228(x17)
  asm volatile("flw     %0,  228(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 4d8:	0e482107          	flw	f2,228(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 4dc:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  232(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 4e0:	0e88a087          	flw	f1,232(x17)
  asm volatile("flw     %0,  232(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 4e4:	0e882107          	flw	f2,232(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 4e8:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  236(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 4ec:	0ec8a087          	flw	f1,236(x17)
  asm volatile("flw     %0,  236(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 4f0:	0ec82107          	flw	f2,236(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 4f4:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  240(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 4f8:	0f08a087          	flw	f1,240(x17)
  asm volatile("flw     %0,  240(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 4fc:	0f082107          	flw	f2,240(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 500:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  244(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 504:	0f48a087          	flw	f1,244(x17)
  asm volatile("flw     %0,  244(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 508:	0f482107          	flw	f2,244(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 50c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  248(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 510:	0f88a087          	flw	f1,248(x17)
  asm volatile("flw     %0,  248(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 514:	0f882107          	flw	f2,248(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 518:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  252(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 51c:	0fc8a087          	flw	f1,252(x17)
  asm volatile("flw     %0,  252(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 520:	0fc82107          	flw	f2,252(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 524:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  256(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 528:	1008a087          	flw	f1,256(x17)
  asm volatile("flw     %0,  256(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 52c:	10082107          	flw	f2,256(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 530:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  260(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 534:	1048a087          	flw	f1,260(x17)
  asm volatile("flw     %0,  260(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 538:	10482107          	flw	f2,260(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 53c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  264(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 540:	1088a087          	flw	f1,264(x17)
  asm volatile("flw     %0,  264(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 544:	10882107          	flw	f2,264(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 548:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  268(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 54c:	10c8a087          	flw	f1,268(x17)
  asm volatile("flw     %0,  268(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 550:	10c82107          	flw	f2,268(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 554:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  272(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 558:	1108a087          	flw	f1,272(x17)
  asm volatile("flw     %0,  272(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 55c:	11082107          	flw	f2,272(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 560:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  276(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 564:	1148a087          	flw	f1,276(x17)
  asm volatile("flw     %0,  276(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 568:	11482107          	flw	f2,276(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 56c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  280(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 570:	1188a087          	flw	f1,280(x17)
  asm volatile("flw     %0,  280(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 574:	11882107          	flw	f2,280(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 578:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  284(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 57c:	11c8a087          	flw	f1,284(x17)
  asm volatile("flw     %0,  284(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 580:	11c82107          	flw	f2,284(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 584:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  288(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 588:	1208a087          	flw	f1,288(x17)
  asm volatile("flw     %0,  288(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 58c:	12082107          	flw	f2,288(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 590:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  292(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 594:	1248a087          	flw	f1,292(x17)
  asm volatile("flw     %0,  292(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 598:	12482107          	flw	f2,292(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 59c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  296(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 5a0:	1288a087          	flw	f1,296(x17)
  asm volatile("flw     %0,  296(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 5a4:	12882107          	flw	f2,296(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 5a8:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  300(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 5ac:	12c8a087          	flw	f1,300(x17)
  asm volatile("flw     %0,  300(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 5b0:	12c82107          	flw	f2,300(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 5b4:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  304(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 5b8:	1308a087          	flw	f1,304(x17)
  asm volatile("flw     %0,  304(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 5bc:	13082107          	flw	f2,304(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 5c0:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  308(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 5c4:	1348a087          	flw	f1,308(x17)
  asm volatile("flw     %0,  308(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 5c8:	13482107          	flw	f2,308(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 5cc:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  312(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 5d0:	1388a087          	flw	f1,312(x17)
  asm volatile("flw     %0,  312(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 5d4:	13882107          	flw	f2,312(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 5d8:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  316(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 5dc:	13c8a087          	flw	f1,316(x17)
  asm volatile("flw     %0,  316(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 5e0:	13c82107          	flw	f2,316(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 5e4:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  320(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 5e8:	1408a087          	flw	f1,320(x17)
  asm volatile("flw     %0,  320(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 5ec:	14082107          	flw	f2,320(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 5f0:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  324(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 5f4:	1448a087          	flw	f1,324(x17)
  asm volatile("flw     %0,  324(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 5f8:	14482107          	flw	f2,324(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 5fc:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  328(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 600:	1488a087          	flw	f1,328(x17)
  asm volatile("flw     %0,  328(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 604:	14882107          	flw	f2,328(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 608:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  332(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 60c:	14c8a087          	flw	f1,332(x17)
  asm volatile("flw     %0,  332(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 610:	14c82107          	flw	f2,332(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 614:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  336(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 618:	1508a087          	flw	f1,336(x17)
  asm volatile("flw     %0,  336(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 61c:	15082107          	flw	f2,336(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 620:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  340(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 624:	1548a087          	flw	f1,340(x17)
  asm volatile("flw     %0,  340(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 628:	15482107          	flw	f2,340(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 62c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  344(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 630:	1588a087          	flw	f1,344(x17)
  asm volatile("flw     %0,  344(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 634:	15882107          	flw	f2,344(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 638:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  348(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 63c:	15c8a087          	flw	f1,348(x17)
  asm volatile("flw     %0,  348(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 640:	15c82107          	flw	f2,348(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 644:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  352(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 648:	1608a087          	flw	f1,352(x17)
  asm volatile("flw     %0,  352(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 64c:	16082107          	flw	f2,352(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 650:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  356(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 654:	1648a087          	flw	f1,356(x17)
  asm volatile("flw     %0,  356(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 658:	16482107          	flw	f2,356(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 65c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  360(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 660:	1688a087          	flw	f1,360(x17)
  asm volatile("flw     %0,  360(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 664:	16882107          	flw	f2,360(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 668:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  364(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 66c:	16c8a087          	flw	f1,364(x17)
  asm volatile("flw     %0,  364(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 670:	16c82107          	flw	f2,364(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 674:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  368(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 678:	1708a087          	flw	f1,368(x17)
  asm volatile("flw     %0,  368(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 67c:	17082107          	flw	f2,368(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 680:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  372(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 684:	1748a087          	flw	f1,372(x17)
  asm volatile("flw     %0,  372(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 688:	17482107          	flw	f2,372(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 68c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  376(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 690:	1788a087          	flw	f1,376(x17)
  asm volatile("flw     %0,  376(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 694:	17882107          	flw	f2,376(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 698:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  380(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 69c:	17c8a087          	flw	f1,380(x17)
  asm volatile("flw     %0,  380(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 6a0:	17c82107          	flw	f2,380(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 6a4:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  384(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 6a8:	1808a087          	flw	f1,384(x17)
  asm volatile("flw     %0,  384(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 6ac:	18082107          	flw	f2,384(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 6b0:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  388(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 6b4:	1848a087          	flw	f1,388(x17)
  asm volatile("flw     %0,  388(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 6b8:	18482107          	flw	f2,388(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 6bc:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  392(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 6c0:	1888a087          	flw	f1,392(x17)
  asm volatile("flw     %0,  392(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 6c4:	18882107          	flw	f2,392(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 6c8:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  396(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 6cc:	18c8a087          	flw	f1,396(x17)
  asm volatile("flw     %0,  396(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 6d0:	18c82107          	flw	f2,396(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 6d4:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  400(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 6d8:	1908a087          	flw	f1,400(x17)
  asm volatile("flw     %0,  400(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 6dc:	19082107          	flw	f2,400(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 6e0:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  404(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 6e4:	1948a087          	flw	f1,404(x17)
  asm volatile("flw     %0,  404(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 6e8:	19482107          	flw	f2,404(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 6ec:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  408(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 6f0:	1988a087          	flw	f1,408(x17)
  asm volatile("flw     %0,  408(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 6f4:	19882107          	flw	f2,408(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 6f8:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  412(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 6fc:	19c8a087          	flw	f1,412(x17)
  asm volatile("flw     %0,  412(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 700:	19c82107          	flw	f2,412(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 704:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  416(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 708:	1a08a087          	flw	f1,416(x17)
  asm volatile("flw     %0,  416(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 70c:	1a082107          	flw	f2,416(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 710:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  420(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 714:	1a48a087          	flw	f1,420(x17)
  asm volatile("flw     %0,  420(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 718:	1a482107          	flw	f2,420(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 71c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  424(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 720:	1a88a087          	flw	f1,424(x17)
  asm volatile("flw     %0,  424(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 724:	1a882107          	flw	f2,424(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 728:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  428(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 72c:	1ac8a087          	flw	f1,428(x17)
  asm volatile("flw     %0,  428(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 730:	1ac82107          	flw	f2,428(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 734:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  432(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 738:	1b08a087          	flw	f1,432(x17)
  asm volatile("flw     %0,  432(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 73c:	1b082107          	flw	f2,432(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 740:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  436(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 744:	1b48a087          	flw	f1,436(x17)
  asm volatile("flw     %0,  436(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 748:	1b482107          	flw	f2,436(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 74c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  440(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 750:	1b88a087          	flw	f1,440(x17)
  asm volatile("flw     %0,  440(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 754:	1b882107          	flw	f2,440(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 758:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  444(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 75c:	1bc8a087          	flw	f1,444(x17)
  asm volatile("flw     %0,  444(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 760:	1bc82107          	flw	f2,444(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 764:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  448(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 768:	1c08a087          	flw	f1,448(x17)
  asm volatile("flw     %0,  448(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 76c:	1c082107          	flw	f2,448(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 770:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  452(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 774:	1c48a087          	flw	f1,452(x17)
  asm volatile("flw     %0,  452(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 778:	1c482107          	flw	f2,452(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 77c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  456(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 780:	1c88a087          	flw	f1,456(x17)
  asm volatile("flw     %0,  456(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 784:	1c882107          	flw	f2,456(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 788:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  460(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 78c:	1cc8a087          	flw	f1,460(x17)
  asm volatile("flw     %0,  460(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 790:	1cc82107          	flw	f2,460(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 794:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  464(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 798:	1d08a087          	flw	f1,464(x17)
  asm volatile("flw     %0,  464(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 79c:	1d082107          	flw	f2,464(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 7a0:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  468(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 7a4:	1d48a087          	flw	f1,468(x17)
  asm volatile("flw     %0,  468(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 7a8:	1d482107          	flw	f2,468(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 7ac:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  472(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 7b0:	1d88a087          	flw	f1,472(x17)
  asm volatile("flw     %0,  472(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 7b4:	1d882107          	flw	f2,472(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 7b8:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  476(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 7bc:	1dc8a087          	flw	f1,476(x17)
  asm volatile("flw     %0,  476(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 7c0:	1dc82107          	flw	f2,476(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 7c4:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  480(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 7c8:	1e08a087          	flw	f1,480(x17)
  asm volatile("flw     %0,  480(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 7cc:	1e082107          	flw	f2,480(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 7d0:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  484(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 7d4:	1e48a087          	flw	f1,484(x17)
  asm volatile("flw     %0,  484(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 7d8:	1e482107          	flw	f2,484(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 7dc:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  488(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 7e0:	1e88a087          	flw	f1,488(x17)
  asm volatile("flw     %0,  488(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 7e4:	1e882107          	flw	f2,488(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 7e8:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  492(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 7ec:	1ec8a087          	flw	f1,492(x17)
  asm volatile("flw     %0,  492(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 7f0:	1ec82107          	flw	f2,492(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 7f4:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  496(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 7f8:	1f08a087          	flw	f1,496(x17)
  asm volatile("flw     %0,  496(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 7fc:	1f082107          	flw	f2,496(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 800:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  500(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 804:	1f48a087          	flw	f1,500(x17)
  asm volatile("flw     %0,  500(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 808:	1f482107          	flw	f2,500(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 80c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  504(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 810:	1f88a087          	flw	f1,504(x17)
  asm volatile("flw     %0,  504(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 814:	1f882107          	flw	f2,504(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 818:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  508(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 81c:	1fc8a087          	flw	f1,508(x17)
  asm volatile("flw     %0,  508(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 820:	1fc82107          	flw	f2,508(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 824:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  512(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 828:	2008a087          	flw	f1,512(x17)
  asm volatile("flw     %0,  512(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 82c:	20082107          	flw	f2,512(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 830:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  516(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 834:	2048a087          	flw	f1,516(x17)
  asm volatile("flw     %0,  516(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 838:	20482107          	flw	f2,516(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 83c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  520(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 840:	2088a087          	flw	f1,520(x17)
  asm volatile("flw     %0,  520(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 844:	20882107          	flw	f2,520(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 848:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  524(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 84c:	20c8a087          	flw	f1,524(x17)
  asm volatile("flw     %0,  524(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 850:	20c82107          	flw	f2,524(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 854:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  528(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 858:	2108a087          	flw	f1,528(x17)
  asm volatile("flw     %0,  528(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 85c:	21082107          	flw	f2,528(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 860:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  532(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 864:	2148a087          	flw	f1,532(x17)
  asm volatile("flw     %0,  532(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 868:	21482107          	flw	f2,532(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 86c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  536(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 870:	2188a087          	flw	f1,536(x17)
  asm volatile("flw     %0,  536(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 874:	21882107          	flw	f2,536(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 878:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  540(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 87c:	21c8a087          	flw	f1,540(x17)
  asm volatile("flw     %0,  540(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 880:	21c82107          	flw	f2,540(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 884:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  544(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 888:	2208a087          	flw	f1,544(x17)
  asm volatile("flw     %0,  544(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 88c:	22082107          	flw	f2,544(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 890:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  548(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 894:	2248a087          	flw	f1,548(x17)
  asm volatile("flw     %0,  548(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 898:	22482107          	flw	f2,548(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 89c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  552(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 8a0:	2288a087          	flw	f1,552(x17)
  asm volatile("flw     %0,  552(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 8a4:	22882107          	flw	f2,552(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 8a8:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  556(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 8ac:	22c8a087          	flw	f1,556(x17)
  asm volatile("flw     %0,  556(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 8b0:	22c82107          	flw	f2,556(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 8b4:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  560(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 8b8:	2308a087          	flw	f1,560(x17)
  asm volatile("flw     %0,  560(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 8bc:	23082107          	flw	f2,560(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 8c0:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  564(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 8c4:	2348a087          	flw	f1,564(x17)
  asm volatile("flw     %0,  564(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 8c8:	23482107          	flw	f2,564(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 8cc:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  568(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 8d0:	2388a087          	flw	f1,568(x17)
  asm volatile("flw     %0,  568(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 8d4:	23882107          	flw	f2,568(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 8d8:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  572(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 8dc:	23c8a087          	flw	f1,572(x17)
  asm volatile("flw     %0,  572(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 8e0:	23c82107          	flw	f2,572(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 8e4:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  576(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 8e8:	2408a087          	flw	f1,576(x17)
  asm volatile("flw     %0,  576(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 8ec:	24082107          	flw	f2,576(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 8f0:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  580(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 8f4:	2448a087          	flw	f1,580(x17)
  asm volatile("flw     %0,  580(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 8f8:	24482107          	flw	f2,580(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 8fc:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  584(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 900:	2488a087          	flw	f1,584(x17)
  asm volatile("flw     %0,  584(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 904:	24882107          	flw	f2,584(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 908:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  588(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 90c:	24c8a087          	flw	f1,588(x17)
  asm volatile("flw     %0,  588(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 910:	24c82107          	flw	f2,588(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 914:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  592(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 918:	2508a087          	flw	f1,592(x17)
  asm volatile("flw     %0,  592(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 91c:	25082107          	flw	f2,592(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 920:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  596(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 924:	2548a087          	flw	f1,596(x17)
  asm volatile("flw     %0,  596(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 928:	25482107          	flw	f2,596(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 92c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  600(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 930:	2588a087          	flw	f1,600(x17)
  asm volatile("flw     %0,  600(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 934:	25882107          	flw	f2,600(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 938:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  604(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 93c:	25c8a087          	flw	f1,604(x17)
  asm volatile("flw     %0,  604(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 940:	25c82107          	flw	f2,604(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 944:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  608(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 948:	2608a087          	flw	f1,608(x17)
  asm volatile("flw     %0,  608(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 94c:	26082107          	flw	f2,608(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 950:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  612(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 954:	2648a087          	flw	f1,612(x17)
  asm volatile("flw     %0,  612(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 958:	26482107          	flw	f2,612(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 95c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  616(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 960:	2688a087          	flw	f1,616(x17)
  asm volatile("flw     %0,  616(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 964:	26882107          	flw	f2,616(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 968:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  620(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 96c:	26c8a087          	flw	f1,620(x17)
  asm volatile("flw     %0,  620(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 970:	26c82107          	flw	f2,620(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 974:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  624(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 978:	2708a087          	flw	f1,624(x17)
  asm volatile("flw     %0,  624(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 97c:	27082107          	flw	f2,624(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 980:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  628(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 984:	2748a087          	flw	f1,628(x17)
  asm volatile("flw     %0,  628(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 988:	27482107          	flw	f2,628(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 98c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  632(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 990:	2788a087          	flw	f1,632(x17)
  asm volatile("flw     %0,  632(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 994:	27882107          	flw	f2,632(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 998:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  636(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 99c:	27c8a087          	flw	f1,636(x17)
  asm volatile("flw     %0,  636(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 9a0:	27c82107          	flw	f2,636(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 9a4:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  640(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 9a8:	2808a087          	flw	f1,640(x17)
  asm volatile("flw     %0,  640(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 9ac:	28082107          	flw	f2,640(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 9b0:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  644(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 9b4:	2848a087          	flw	f1,644(x17)
  asm volatile("flw     %0,  644(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 9b8:	28482107          	flw	f2,644(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 9bc:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  648(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 9c0:	2888a087          	flw	f1,648(x17)
  asm volatile("flw     %0,  648(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 9c4:	28882107          	flw	f2,648(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 9c8:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  652(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 9cc:	28c8a087          	flw	f1,652(x17)
  asm volatile("flw     %0,  652(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 9d0:	28c82107          	flw	f2,652(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 9d4:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  656(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 9d8:	2908a087          	flw	f1,656(x17)
  asm volatile("flw     %0,  656(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 9dc:	29082107          	flw	f2,656(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 9e0:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  660(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 9e4:	2948a087          	flw	f1,660(x17)
  asm volatile("flw     %0,  660(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 9e8:	29482107          	flw	f2,660(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 9ec:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  664(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 9f0:	2988a087          	flw	f1,664(x17)
  asm volatile("flw     %0,  664(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 9f4:	29882107          	flw	f2,664(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 9f8:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  668(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 9fc:	29c8a087          	flw	f1,668(x17)
  asm volatile("flw     %0,  668(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a00:	29c82107          	flw	f2,668(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a04:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  672(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a08:	2a08a087          	flw	f1,672(x17)
  asm volatile("flw     %0,  672(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a0c:	2a082107          	flw	f2,672(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a10:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  676(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a14:	2a48a087          	flw	f1,676(x17)
  asm volatile("flw     %0,  676(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a18:	2a482107          	flw	f2,676(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a1c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  680(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a20:	2a88a087          	flw	f1,680(x17)
  asm volatile("flw     %0,  680(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a24:	2a882107          	flw	f2,680(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a28:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  684(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a2c:	2ac8a087          	flw	f1,684(x17)
  asm volatile("flw     %0,  684(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a30:	2ac82107          	flw	f2,684(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a34:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  688(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a38:	2b08a087          	flw	f1,688(x17)
  asm volatile("flw     %0,  688(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a3c:	2b082107          	flw	f2,688(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a40:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  692(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a44:	2b48a087          	flw	f1,692(x17)
  asm volatile("flw     %0,  692(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a48:	2b482107          	flw	f2,692(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a4c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  696(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a50:	2b88a087          	flw	f1,696(x17)
  asm volatile("flw     %0,  696(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a54:	2b882107          	flw	f2,696(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a58:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  700(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a5c:	2bc8a087          	flw	f1,700(x17)
  asm volatile("flw     %0,  700(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a60:	2bc82107          	flw	f2,700(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a64:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  704(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a68:	2c08a087          	flw	f1,704(x17)
  asm volatile("flw     %0,  704(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a6c:	2c082107          	flw	f2,704(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a70:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  708(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a74:	2c48a087          	flw	f1,708(x17)
  asm volatile("flw     %0,  708(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a78:	2c482107          	flw	f2,708(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a7c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  712(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a80:	2c88a087          	flw	f1,712(x17)
  asm volatile("flw     %0,  712(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a84:	2c882107          	flw	f2,712(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a88:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  716(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a8c:	2cc8a087          	flw	f1,716(x17)
  asm volatile("flw     %0,  716(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a90:	2cc82107          	flw	f2,716(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a94:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  720(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a98:	2d08a087          	flw	f1,720(x17)
  asm volatile("flw     %0,  720(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a9c:	2d082107          	flw	f2,720(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 aa0:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  724(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 aa4:	2d48a087          	flw	f1,724(x17)
  asm volatile("flw     %0,  724(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 aa8:	2d482107          	flw	f2,724(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 aac:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  728(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 ab0:	2d88a087          	flw	f1,728(x17)
  asm volatile("flw     %0,  728(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 ab4:	2d882107          	flw	f2,728(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 ab8:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  732(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 abc:	2dc8a087          	flw	f1,732(x17)
  asm volatile("flw     %0,  732(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 ac0:	2dc82107          	flw	f2,732(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 ac4:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  736(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 ac8:	2e08a087          	flw	f1,736(x17)
  asm volatile("flw     %0,  736(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 acc:	2e082107          	flw	f2,736(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 ad0:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  740(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 ad4:	2e48a087          	flw	f1,740(x17)
  asm volatile("flw     %0,  740(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 ad8:	2e482107          	flw	f2,740(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 adc:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  744(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 ae0:	2e88a087          	flw	f1,744(x17)
  asm volatile("flw     %0,  744(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 ae4:	2e882107          	flw	f2,744(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 ae8:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  748(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 aec:	2ec8a087          	flw	f1,748(x17)
  asm volatile("flw     %0,  748(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 af0:	2ec82107          	flw	f2,748(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 af4:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  752(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 af8:	2f08a087          	flw	f1,752(x17)
  asm volatile("flw     %0,  752(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 afc:	2f082107          	flw	f2,752(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 b00:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  756(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 b04:	2f48a087          	flw	f1,756(x17)
  asm volatile("flw     %0,  756(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 b08:	2f482107          	flw	f2,756(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 b0c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  760(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 b10:	2f88a087          	flw	f1,760(x17)
  asm volatile("flw     %0,  760(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 b14:	2f882107          	flw	f2,760(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 b18:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  764(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 b1c:	2fc8a087          	flw	f1,764(x17)
  asm volatile("flw     %0,  764(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 b20:	2fc82107          	flw	f2,764(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 b24:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  768(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 b28:	3008a087          	flw	f1,768(x17)
  asm volatile("flw     %0,  768(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 b2c:	30082107          	flw	f2,768(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 b30:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  772(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 b34:	3048a087          	flw	f1,772(x17)
  asm volatile("flw     %0,  772(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 b38:	30482107          	flw	f2,772(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 b3c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  776(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 b40:	3088a087          	flw	f1,776(x17)
  asm volatile("flw     %0,  776(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 b44:	30882107          	flw	f2,776(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 b48:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  780(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 b4c:	30c8a087          	flw	f1,780(x17)
  asm volatile("flw     %0,  780(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 b50:	30c82107          	flw	f2,780(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 b54:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  784(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 b58:	3108a087          	flw	f1,784(x17)
  asm volatile("flw     %0,  784(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 b5c:	31082107          	flw	f2,784(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 b60:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  788(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 b64:	3148a087          	flw	f1,788(x17)
  asm volatile("flw     %0,  788(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 b68:	31482107          	flw	f2,788(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 b6c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  792(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 b70:	3188a087          	flw	f1,792(x17)
  asm volatile("flw     %0,  792(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 b74:	31882107          	flw	f2,792(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 b78:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  796(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 b7c:	31c8a087          	flw	f1,796(x17)
  asm volatile("flw     %0,  796(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 b80:	31c82107          	flw	f2,796(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 b84:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  800(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 b88:	3208a087          	flw	f1,800(x17)
  asm volatile("flw     %0,  800(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 b8c:	32082107          	flw	f2,800(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 b90:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  804(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 b94:	3248a087          	flw	f1,804(x17)
  asm volatile("flw     %0,  804(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 b98:	32482107          	flw	f2,804(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 b9c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  808(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 ba0:	3288a087          	flw	f1,808(x17)
  asm volatile("flw     %0,  808(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 ba4:	32882107          	flw	f2,808(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 ba8:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  812(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 bac:	32c8a087          	flw	f1,812(x17)
  asm volatile("flw     %0,  812(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 bb0:	32c82107          	flw	f2,812(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 bb4:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  816(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 bb8:	3308a087          	flw	f1,816(x17)
  asm volatile("flw     %0,  816(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 bbc:	33082107          	flw	f2,816(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 bc0:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  820(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 bc4:	3348a087          	flw	f1,820(x17)
  asm volatile("flw     %0,  820(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 bc8:	33482107          	flw	f2,820(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 bcc:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  824(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 bd0:	3388a087          	flw	f1,824(x17)
  asm volatile("flw     %0,  824(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 bd4:	33882107          	flw	f2,824(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 bd8:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  828(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 bdc:	33c8a087          	flw	f1,828(x17)
  asm volatile("flw     %0,  828(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 be0:	33c82107          	flw	f2,828(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 be4:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  832(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 be8:	3408a087          	flw	f1,832(x17)
  asm volatile("flw     %0,  832(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 bec:	34082107          	flw	f2,832(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 bf0:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  836(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 bf4:	3448a087          	flw	f1,836(x17)
  asm volatile("flw     %0,  836(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 bf8:	34482107          	flw	f2,836(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 bfc:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  840(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 c00:	3488a087          	flw	f1,840(x17)
  asm volatile("flw     %0,  840(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 c04:	34882107          	flw	f2,840(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 c08:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  844(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 c0c:	34c8a087          	flw	f1,844(x17)
  asm volatile("flw     %0,  844(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 c10:	34c82107          	flw	f2,844(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 c14:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  848(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 c18:	3508a087          	flw	f1,848(x17)
  asm volatile("flw     %0,  848(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 c1c:	35082107          	flw	f2,848(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 c20:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  852(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 c24:	3548a087          	flw	f1,852(x17)
  asm volatile("flw     %0,  852(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 c28:	35482107          	flw	f2,852(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 c2c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  856(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 c30:	3588a087          	flw	f1,856(x17)
  asm volatile("flw     %0,  856(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 c34:	35882107          	flw	f2,856(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 c38:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  860(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 c3c:	35c8a087          	flw	f1,860(x17)
  asm volatile("flw     %0,  860(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 c40:	35c82107          	flw	f2,860(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 c44:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  864(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 c48:	3608a087          	flw	f1,864(x17)
  asm volatile("flw     %0,  864(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 c4c:	36082107          	flw	f2,864(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 c50:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  868(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 c54:	3648a087          	flw	f1,868(x17)
  asm volatile("flw     %0,  868(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 c58:	36482107          	flw	f2,868(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 c5c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  872(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 c60:	3688a087          	flw	f1,872(x17)
  asm volatile("flw     %0,  872(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 c64:	36882107          	flw	f2,872(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 c68:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  876(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 c6c:	36c8a087          	flw	f1,876(x17)
  asm volatile("flw     %0,  876(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 c70:	36c82107          	flw	f2,876(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 c74:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  880(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 c78:	3708a087          	flw	f1,880(x17)
  asm volatile("flw     %0,  880(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 c7c:	37082107          	flw	f2,880(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 c80:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  884(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 c84:	3748a087          	flw	f1,884(x17)
  asm volatile("flw     %0,  884(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 c88:	37482107          	flw	f2,884(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 c8c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  888(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 c90:	3788a087          	flw	f1,888(x17)
  asm volatile("flw     %0,  888(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 c94:	37882107          	flw	f2,888(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 c98:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  892(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 c9c:	37c8a087          	flw	f1,892(x17)
  asm volatile("flw     %0,  892(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 ca0:	37c82107          	flw	f2,892(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 ca4:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  896(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 ca8:	3808a087          	flw	f1,896(x17)
  asm volatile("flw     %0,  896(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 cac:	38082107          	flw	f2,896(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 cb0:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  900(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 cb4:	3848a087          	flw	f1,900(x17)
  asm volatile("flw     %0,  900(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 cb8:	38482107          	flw	f2,900(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 cbc:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  904(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 cc0:	3888a087          	flw	f1,904(x17)
  asm volatile("flw     %0,  904(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 cc4:	38882107          	flw	f2,904(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 cc8:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  908(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 ccc:	38c8a087          	flw	f1,908(x17)
  asm volatile("flw     %0,  908(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 cd0:	38c82107          	flw	f2,908(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 cd4:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  912(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 cd8:	3908a087          	flw	f1,912(x17)
  asm volatile("flw     %0,  912(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 cdc:	39082107          	flw	f2,912(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 ce0:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  916(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 ce4:	3948a087          	flw	f1,916(x17)
  asm volatile("flw     %0,  916(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 ce8:	39482107          	flw	f2,916(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 cec:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  920(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 cf0:	3988a087          	flw	f1,920(x17)
  asm volatile("flw     %0,  920(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 cf4:	39882107          	flw	f2,920(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 cf8:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  924(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 cfc:	39c8a087          	flw	f1,924(x17)
  asm volatile("flw     %0,  924(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 d00:	39c82107          	flw	f2,924(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 d04:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  928(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 d08:	3a08a087          	flw	f1,928(x17)
  asm volatile("flw     %0,  928(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 d0c:	3a082107          	flw	f2,928(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 d10:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  932(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 d14:	3a48a087          	flw	f1,932(x17)
  asm volatile("flw     %0,  932(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 d18:	3a482107          	flw	f2,932(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 d1c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  936(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 d20:	3a88a087          	flw	f1,936(x17)
  asm volatile("flw     %0,  936(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 d24:	3a882107          	flw	f2,936(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 d28:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  940(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 d2c:	3ac8a087          	flw	f1,940(x17)
  asm volatile("flw     %0,  940(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 d30:	3ac82107          	flw	f2,940(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 d34:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  944(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 d38:	3b08a087          	flw	f1,944(x17)
  asm volatile("flw     %0,  944(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 d3c:	3b082107          	flw	f2,944(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 d40:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  948(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 d44:	3b48a087          	flw	f1,948(x17)
  asm volatile("flw     %0,  948(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 d48:	3b482107          	flw	f2,948(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 d4c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  952(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 d50:	3b88a087          	flw	f1,952(x17)
  asm volatile("flw     %0,  952(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 d54:	3b882107          	flw	f2,952(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 d58:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  956(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 d5c:	3bc8a087          	flw	f1,956(x17)
  asm volatile("flw     %0,  956(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 d60:	3bc82107          	flw	f2,956(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 d64:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  960(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 d68:	3c08a087          	flw	f1,960(x17)
  asm volatile("flw     %0,  960(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 d6c:	3c082107          	flw	f2,960(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 d70:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  964(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 d74:	3c48a087          	flw	f1,964(x17)
  asm volatile("flw     %0,  964(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 d78:	3c482107          	flw	f2,964(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 d7c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  968(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 d80:	3c88a087          	flw	f1,968(x17)
  asm volatile("flw     %0,  968(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 d84:	3c882107          	flw	f2,968(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 d88:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  972(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 d8c:	3cc8a087          	flw	f1,972(x17)
  asm volatile("flw     %0,  972(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 d90:	3cc82107          	flw	f2,972(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 d94:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  976(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 d98:	3d08a087          	flw	f1,976(x17)
  asm volatile("flw     %0,  976(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 d9c:	3d082107          	flw	f2,976(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 da0:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  980(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 da4:	3d48a087          	flw	f1,980(x17)
  asm volatile("flw     %0,  980(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 da8:	3d482107          	flw	f2,980(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 dac:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  984(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 db0:	3d88a087          	flw	f1,984(x17)
  asm volatile("flw     %0,  984(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 db4:	3d882107          	flw	f2,984(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 db8:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  988(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 dbc:	3dc8a087          	flw	f1,988(x17)
  asm volatile("flw     %0,  988(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 dc0:	3dc82107          	flw	f2,988(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 dc4:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  992(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 dc8:	3e08a087          	flw	f1,992(x17)
  asm volatile("flw     %0,  992(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 dcc:	3e082107          	flw	f2,992(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 dd0:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0,  996(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 dd4:	3e48a087          	flw	f1,996(x17)
  asm volatile("flw     %0,  996(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 dd8:	3e482107          	flw	f2,996(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 ddc:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0, 1000(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 de0:	3e88a087          	flw	f1,1000(x17)
  asm volatile("flw     %0, 1000(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 de4:	3e882107          	flw	f2,1000(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 de8:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0, 1004(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 dec:	3ec8a087          	flw	f1,1004(x17)
  asm volatile("flw     %0, 1004(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 df0:	3ec82107          	flw	f2,1004(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 df4:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0, 1008(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 df8:	3f08a087          	flw	f1,1008(x17)
  asm volatile("flw     %0, 1008(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 dfc:	3f082107          	flw	f2,1008(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 e00:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0, 1012(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 e04:	3f48a087          	flw	f1,1012(x17)
  asm volatile("flw     %0, 1012(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 e08:	3f482107          	flw	f2,1012(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 e0c:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  asm volatile("flw     %0, 1016(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 e10:	3f88a087          	flw	f1,1016(x17)
  asm volatile("flw     %0, 1016(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 e14:	3f882107          	flw	f2,1016(x16)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 e18:	0020f053          	fadd.s	f0,f1,f2
  //------------------------------------
  bsg_saif_end();
 e1c:	00200013          	li	x0,2
  //------------------------------------
  C[0] = C_tmp;
 e20:	00062027          	fsw	f0,0(x12)
	barrier.sync();

	return 0;
 e24:	00000513          	li	x10,0
 e28:	000015b7          	lui	x11,0x1
 e2c:	80058593          	addi	x11,x11,-2048 # 800 <kernel_energy_fadd_demo+0x620>
 e30:	00b10133          	add	x2,x2,x11
 e34:	00008067          	ret

00000e38 <_GLOBAL__sub_I_kernel.cpp>:

        // IF the location of _local_alsert and _done_list changes in
        // the linker sections (e.g. to DRAM, for some reason) they
        // MUST be initialized to 0 to work correctly.
        
    volatile unsigned int  _local_alert = 0;
 e38:	04002c23          	sw	x0,88(x0) # 58 <barrier>
 e3c:	05800593          	li	x11,88
    volatile unsigned char _done_list[ BARRIER_X_DIM ] = {0};
 e40:	00058223          	sb	x0,4(x11)


    // Reinitializes the done_list to zero
    void reset() {
        for (int i = 0; i < BARRIER_X_DIM; i ++) {
            this->_done_list[i] = 0;
 e44:	00058223          	sb	x0,4(x11)
        }
        _local_alert = 0;
 e48:	04002c23          	sw	x0,88(x0) # 58 <barrier>

template <int BARRIER_Y_DIM>
class bsg_col_barrier {
private:

    volatile unsigned int  _local_alert = 0;
 e4c:	0005a423          	sw	x0,8(x11)
    volatile unsigned char _done_list[ BARRIER_Y_DIM ] = {0};
 e50:	00058623          	sb	x0,12(x11)


    // Reinitializes the done_list to zero
    void reset() {
        for (int i = 0; i < BARRIER_Y_DIM; i ++) {
            this->_done_list[i] = 0;
 e54:	00058623          	sb	x0,12(x11)
        }
        _local_alert = 0;
 e58:	0005a423          	sw	x0,8(x11)
            this->_done_list[i] = 0;
 e5c:	00058223          	sb	x0,4(x11)
        _local_alert = 0;
 e60:	04002c23          	sw	x0,88(x0) # 58 <barrier>
            this->_done_list[i] = 0;
 e64:	00058623          	sb	x0,12(x11)
        _local_alert = 0;
 e68:	0005a423          	sw	x0,8(x11)
 e6c:	00008067          	ret

00000e70 <main>:
#include "bsg_cuda_lite_runtime.h"


int main()
{
        __wait_until_valid_func();
 e70:	03c02283          	lw	x5,60(x0) # 3c <cuda_kernel_not_loaded_val>
 e74:	05000413          	li	x8,80
 e78:	1004232f          	lr.w	x6,(x8)
 e7c:	00629463          	bne	x5,x6,e84 <__init_param>
 e80:	140422af          	lr.w.aq	x5,(x8)

00000e84 <__init_param>:
 e84:	05000293          	li	x5,80
 e88:	0002a483          	lw	x9,0(x5)
 e8c:	04c00293          	li	x5,76
 e90:	0002a903          	lw	x18,0(x5)
 e94:	04800293          	li	x5,72
 e98:	0002a983          	lw	x19,0(x5)
 e9c:	04400293          	li	x5,68
 ea0:	0002aa03          	lw	x20,0(x5)

00000ea4 <__load_argument>:
 ea4:	0009a503          	lw	x10,0(x19)
 ea8:	0049a583          	lw	x11,4(x19)
 eac:	0089a603          	lw	x12,8(x19)
 eb0:	00c9a683          	lw	x13,12(x19)
 eb4:	0109a703          	lw	x14,16(x19)
 eb8:	0149a783          	lw	x15,20(x19)
 ebc:	0189a803          	lw	x16,24(x19)
 ec0:	01c9a883          	lw	x17,28(x19)
 ec4:	00800293          	li	x5,8
 ec8:	0322de63          	bge	x5,x18,f04 <__invoke_kernel>
 ecc:	ff890293          	addi	x5,x18,-8
 ed0:	00229293          	slli	x5,x5,0x2
 ed4:	40510133          	sub	x2,x2,x5
 ed8:	00800293          	li	x5,8
 edc:	02000313          	li	x6,32
 ee0:	00000e13          	li	x28,0

00000ee4 <__load_stack>:
 ee4:	013303b3          	add	x7,x6,x19
 ee8:	0003ae83          	lw	x29,0(x7)
 eec:	002e0f33          	add	x30,x28,x2
 ef0:	01df2023          	sw	x29,0(x30)
 ef4:	00128293          	addi	x5,x5,1
 ef8:	00430313          	addi	x6,x6,4
 efc:	004e0e13          	addi	x28,x28,4
 f00:	ff22c2e3          	blt	x5,x18,ee4 <__load_stack>

00000f04 <__invoke_kernel>:
 f04:	000480e7          	jalr	x9
 f08:	00800293          	li	x5,8
 f0c:	0122d863          	bge	x5,x18,f1c <__kernel_return>
 f10:	ff890293          	addi	x5,x18,-8
 f14:	00229293          	slli	x5,x5,0x2
 f18:	00510133          	add	x2,x2,x5

00000f1c <__kernel_return>:
 f1c:	03c02283          	lw	x5,60(x0) # 3c <cuda_kernel_not_loaded_val>
 f20:	00542023          	sw	x5,0(x8)
  if (__bsg_id == 0) 
 f24:	02402283          	lw	x5,36(x0) # 24 <__bsg_id>
 f28:	00029863          	bnez	x5,f38 <__kernel_return+0x1c>
     *signal_ptr = cuda_finish_signal_val;     
 f2c:	04402383          	lw	x7,68(x0) # 44 <cuda_finish_signal_addr>
 f30:	04002503          	lw	x10,64(x0) # 40 <cuda_finish_signal_val>
 f34:	00a3a023          	sw	x10,0(x7)
 f38:	f39ff06f          	j	e70 <main>
}
 f3c:	00000513          	li	x10,0
 f40:	00008067          	ret

00000f44 <__.text.dram_end>:
 f44:	0000                	unimp
	...

Disassembly of section .debug_line:

00000000 <.debug_line>:
  li  x1, 0
       0:	00000247          	fmsub.s	f4,f0,f0,f0,rne
  li  x3, 0
       4:	00870003          	lb	x0,8(x14)
  li  x4, 0
       8:	0000                	unimp
       a:	0101                	addi	x2,x2,0
  li  x5, 0
       c:	000d0efb          	0xd0efb
  li  x6, 0
      10:	0101                	addi	x2,x2,0
      12:	0101                	addi	x2,x2,0
  li  x7, 0
      14:	0000                	unimp
      16:	0100                	addi	x8,x2,128
  li  x8, 0
      18:	0000                	unimp
      1a:	2f01                	jal	72a <kernel_energy_fadd_demo+0x54a>
  li  x9, 0
      1c:	6b726f77          	0x6b726f77
  li  x10,0
      20:	6f6c672f          	0x6f6c672f
  li  x11,0
      24:	6162                	flw	f2,24(x2)
      26:	2f6c                	fld	f11,216(x14)
  li  x12,0
      28:	636c                	flw	f11,68(x14)
      2a:	3738                	fld	f14,104(x14)
  li  x13,0
      2c:	6f772f33          	0x6f772f33
  li  x14,0
      30:	6b72                	flw	f22,28(x2)
      32:	6864732f          	0x6864732f
  li  x15,0
      36:	616c702f          	0x616c702f
  li  x16,0
      3a:	6779                	lui	x14,0x1e
  li  x17,0
      3c:	6f72                	flw	f30,28(x2)
      3e:	6e75                	lui	x28,0x1d
  li  x18,0
      40:	2f64                	fld	f9,216(x14)
      42:	6962                	flw	f18,24(x2)
  li  x19,0
      44:	616c6267          	0x616c6267
  li  x20,0
      48:	6564                	flw	f9,76(x10)
      4a:	652d                	lui	x10,0xb
  li  x21,0
      4c:	656e                	flw	f10,216(x2)
      4e:	6772                	flw	f14,28(x2)
  li  x22,0
      50:	2f79                	jal	7ee <kernel_energy_fadd_demo+0x60e>
      52:	7362                	flw	f6,56(x2)
  li  x23,0
      54:	6c625f67          	0x6c625f67
  li  x24,0
      58:	6461                	lui	x8,0x18
      5a:	7265                	lui	x4,0xffff9
  li  x25,0
      5c:	6e75                	lui	x28,0x1d
      5e:	656e                	flw	f10,216(x2)
  li  x26,0
      60:	2f72                	fld	f30,280(x2)
      62:	7362                	flw	f6,56(x2)
  li  x27,0
      64:	616d5f67          	0x616d5f67
  li  x28,0
      68:	796e                	flw	f18,248(x2)
      6a:	65726f63          	bltu	x4,x23,6c8 <kernel_energy_fadd_demo+0x4e8>
  li  x29,0
      6e:	666f732f          	0x666f732f
  li  x30,0
      72:	7774                	flw	f13,108(x14)
  li  x31,0
      74:	7261                	lui	x4,0xffff8
      76:	2f65                	jal	82e <_gp+0x26>
  li t0, 0x00003000 # mstatus.FS
      78:	646d7073          	csrci	0x646,26
  csrs mstatus, t0 # enable FPU
      7c:	6f632f2f          	0x6f632f2f
  fscsr x0
      80:	6d6d                	lui	x26,0x1b
      82:	002f6e6f          	jal	x28,f6084 <_bsg_elf_stack_ptr+0xf5088>
  li t0, 0
      86:	6300                	flw	f8,0(x14)
  fcvt.s.w f0, x0 
      88:	7472                	flw	f8,60(x2)
      8a:	532e                	lw	x6,232(x2)
  fcvt.s.w f1, x0 
      8c:	0100                	addi	x8,x2,128
      8e:	0000                	unimp
  fcvt.s.w f2, x0 
      90:	0000                	unimp
      92:	0205                	addi	x4,x4,1
  fcvt.s.w f3, x0 
      94:	0000                	unimp
      96:	0000                	unimp
  fcvt.s.w f4, x0 
      98:	03010c03          	lb	x24,48(x2)
  fcvt.s.w f5, x0 
      9c:	0902                	c.slli64	x18
      9e:	0004                	0x4
  fcvt.s.w f6, x0 
      a0:	0301                	addi	x6,x6,0
      a2:	0901                	addi	x18,x18,0
  fcvt.s.w f7, x0 
      a4:	0004                	0x4
      a6:	0301                	addi	x6,x6,0
  fcvt.s.w f8, x0 
      a8:	0901                	addi	x18,x18,0
      aa:	0004                	0x4
  fcvt.s.w f9, x0 
      ac:	0301                	addi	x6,x6,0
      ae:	0901                	addi	x18,x18,0
  fcvt.s.w f10,x0 
      b0:	0004                	0x4
      b2:	0301                	addi	x6,x6,0
  fcvt.s.w f11,x0 
      b4:	0901                	addi	x18,x18,0
      b6:	0004                	0x4
  fcvt.s.w f12,x0 
      b8:	0301                	addi	x6,x6,0
      ba:	0901                	addi	x18,x18,0
  fcvt.s.w f13,x0 
      bc:	0004                	0x4
      be:	0301                	addi	x6,x6,0
  fcvt.s.w f14,x0 
      c0:	0901                	addi	x18,x18,0
      c2:	0004                	0x4
  fcvt.s.w f15,x0 
      c4:	0301                	addi	x6,x6,0
      c6:	0901                	addi	x18,x18,0
  fcvt.s.w f16,x0 
      c8:	0004                	0x4
      ca:	0301                	addi	x6,x6,0
  fcvt.s.w f17,x0 
      cc:	0901                	addi	x18,x18,0
      ce:	0004                	0x4
  fcvt.s.w f18,x0 
      d0:	0301                	addi	x6,x6,0
      d2:	0901                	addi	x18,x18,0
  fcvt.s.w f19,x0 
      d4:	0004                	0x4
      d6:	0301                	addi	x6,x6,0
  fcvt.s.w f20,x0 
      d8:	0901                	addi	x18,x18,0
      da:	0004                	0x4
  fcvt.s.w f21,x0 
      dc:	0301                	addi	x6,x6,0
      de:	0901                	addi	x18,x18,0
  fcvt.s.w f22,x0 
      e0:	0004                	0x4
      e2:	0301                	addi	x6,x6,0
  fcvt.s.w f23,x0 
      e4:	0901                	addi	x18,x18,0
      e6:	0004                	0x4
  fcvt.s.w f24,x0 
      e8:	0301                	addi	x6,x6,0
      ea:	0901                	addi	x18,x18,0
  fcvt.s.w f25,x0 
      ec:	0004                	0x4
      ee:	0301                	addi	x6,x6,0
  fcvt.s.w f26,x0 
      f0:	0901                	addi	x18,x18,0
      f2:	0004                	0x4
  fcvt.s.w f27,x0 
      f4:	0301                	addi	x6,x6,0
      f6:	0901                	addi	x18,x18,0
  fcvt.s.w f28,x0 
      f8:	0004                	0x4
      fa:	0301                	addi	x6,x6,0
  fcvt.s.w f29,x0 
      fc:	0901                	addi	x18,x18,0
      fe:	0004                	0x4
  fcvt.s.w f30,x0 
     100:	0301                	addi	x6,x6,0
     102:	0901                	addi	x18,x18,0
  fcvt.s.w f31,x0 
     104:	0004                	0x4
     106:	0301                	addi	x6,x6,0
  la gp, _gp
     108:	0901                	addi	x18,x18,0
     10a:	0004                	0x4
     10c:	0301                	addi	x6,x6,0
     10e:	0901                	addi	x18,x18,0
  la  tp, _bsg_data_end_addr + 63
     110:	0004                	0x4
     112:	0301                	addi	x6,x6,0
     114:	0901                	addi	x18,x18,0
     116:	0004                	0x4
  and tp, tp, -64
     118:	0301                	addi	x6,x6,0
     11a:	0901                	addi	x18,x18,0
  la sp, _sp
     11c:	0004                	0x4
     11e:	0301                	addi	x6,x6,0
     120:	0901                	addi	x18,x18,0
     122:	0004                	0x4
  j main
     124:	0301                	addi	x6,x6,0
     126:	0901                	addi	x18,x18,0
  bsg_remote_store(0,0,bsg_x_v,0);
     128:	0004                	0x4
     12a:	0301                	addi	x6,x6,0
     12c:	0901                	addi	x18,x18,0
     12e:	0004                	0x4
     130:	0301                	addi	x6,x6,0
     132:	0901                	addi	x18,x18,0
  bsg_remote_store(0,0,bsg_y_v,0);
     134:	0004                	0x4
     136:	0301                	addi	x6,x6,0
  bsg_remote_store(0,0,bsg_x_v,0);
     138:	0901                	addi	x18,x18,0
     13a:	0004                	0x4
  bsg_remote_store(0,0,bsg_y_v,0);
     13c:	0301                	addi	x6,x6,0
     13e:	0901                	addi	x18,x18,0
     140:	0004                	0x4
     142:	0301                	addi	x6,x6,0
  bsg_wait_while(*bsg_x_v < 0);
     144:	0901                	addi	x18,x18,0
     146:	0004                	0x4
     148:	0301                	addi	x6,x6,0
     14a:	00040907          	0x40907
  bsg_wait_while(*bsg_y_v < 0);
     14e:	0301                	addi	x6,x6,0
     150:	0901                	addi	x18,x18,0
     152:	0004                	0x4
  if (!*bsg_x_v && !*bsg_y_v)
     154:	0301                	addi	x6,x6,0
     156:	0901                	addi	x18,x18,0
     158:	0004                	0x4
     15a:	0301                	addi	x6,x6,0
     15c:	0901                	addi	x18,x18,0
     15e:	0004                	0x4
     160:	0301                	addi	x6,x6,0
     162:	0902                	c.slli64	x18
        bsg_remote_store(x,y,bsg_x_v,x);
     164:	0004                	0x4
     166:	0301                	addi	x6,x6,0
        bsg_remote_store(x,y,bsg_y_v,y);
     168:	0901                	addi	x18,x18,0
     16a:	0004                	0x4
  grp_org_x_p = bsg_remote_ptr_control( __bsg_x, __bsg_y, CSR_TGO_X );
     16c:	0301                	addi	x6,x6,0
     16e:	0901                	addi	x18,x18,0
     170:	0004                	0x4
     172:	0301                	addi	x6,x6,0
     174:	0901                	addi	x18,x18,0
     176:	0004                	0x4
     178:	0301                	addi	x6,x6,0
     17a:	0901                	addi	x18,x18,0
     17c:	0004                	0x4
     17e:	0301                	addi	x6,x6,0
     180:	0901                	addi	x18,x18,0
     182:	0004                	0x4
     184:	0301                	addi	x6,x6,0
     186:	0901                	addi	x18,x18,0
     188:	0004                	0x4
     18a:	0301                	addi	x6,x6,0
  __bsg_grp_org_x  = * grp_org_x_p;
     18c:	0901                	addi	x18,x18,0
     18e:	0004                	0x4
  grp_org_y_p = bsg_remote_ptr_control( __bsg_x, __bsg_y, CSR_TGO_Y );
     190:	0301                	addi	x6,x6,0
     192:	0901                	addi	x18,x18,0
     194:	0004                	0x4
     196:	0301                	addi	x6,x6,0
  __bsg_grp_org_x  = * grp_org_x_p;
     198:	0901                	addi	x18,x18,0
     19a:	0004                	0x4
  __bsg_grp_org_y  = * grp_org_y_p;
     19c:	0301                	addi	x6,x6,0
     19e:	0901                	addi	x18,x18,0
  __bsg_id = __bsg_y * bsg_tiles_X + __bsg_x;
     1a0:	0004                	0x4
     1a2:	0301                	addi	x6,x6,0
  __bsg_grid_dim_x = 1;
     1a4:	0901                	addi	x18,x18,0
     1a6:	0004                	0x4
  __bsg_grp_org_y  = * grp_org_y_p;
     1a8:	0301                	addi	x6,x6,0
     1aa:	0901                	addi	x18,x18,0
  __bsg_id = __bsg_y * bsg_tiles_X + __bsg_x;
     1ac:	0004                	0x4
     1ae:	0301                	addi	x6,x6,0
  __bsg_grid_dim_x = 1;
     1b0:	0901                	addi	x18,x18,0
     1b2:	0004                	0x4
  __bsg_grid_dim_y = 1;
     1b4:	0301                	addi	x6,x6,0
     1b6:	0901                	addi	x18,x18,0
  __bsg_tile_group_id_x = 0;
     1b8:	0004                	0x4
     1ba:	0301                	addi	x6,x6,0
  __bsg_tile_group_id_y = 0;
     1bc:	0901                	addi	x18,x18,0
     1be:	0004                	0x4
  __bsg_tile_group_id = 0;
     1c0:	0301                	addi	x6,x6,0
     1c2:	0901                	addi	x18,x18,0
}
     1c4:	0004                	0x4
     1c6:	0301                	addi	x6,x6,0
  if (__bsg_id == 0) 
     1c8:	0901                	addi	x18,x18,0
     1ca:	0004                	0x4
     1cc:	0301                	addi	x6,x6,0
     1ce:	0901                	addi	x18,x18,0
     *signal_ptr = cuda_finish_signal_val;     
     1d0:	0004                	0x4
     1d2:	0301                	addi	x6,x6,0
     1d4:	0901                	addi	x18,x18,0
     1d6:	0004                	0x4
     1d8:	0301                	addi	x6,x6,0
     1da:	0901                	addi	x18,x18,0
}
     1dc:	0004                	0x4
     1de:	0301                	addi	x6,x6,0
int kernel_energy_fadd_demo(float *A, float *B, float *C, int N) {
     1e0:	0901                	addi	x18,x18,0
     1e2:	0004                	0x4
     1e4:	0301                	addi	x6,x6,0
     1e6:	0901                	addi	x18,x18,0
     1e8:	0004                	0x4
     1ea:	0301                	addi	x6,x6,0
     1ec:	0901                	addi	x18,x18,0
     1ee:	0004                	0x4
     1f0:	0301                	addi	x6,x6,0
     1f2:	0901                	addi	x18,x18,0
    asm volatile("flw     %0,    0(%1)"   : "=f"(A_tmp) : "r"(A)     : "memory");
     1f4:	0004                	0x4
     1f6:	0301                	addi	x6,x6,0
     1f8:	0901                	addi	x18,x18,0
     1fa:	0004                	0x4
     1fc:	0301                	addi	x6,x6,0
     1fe:	0901                	addi	x18,x18,0
     200:	0004                	0x4
     202:	0301                	addi	x6,x6,0
    asm volatile("fsw     %0,    0(%1)"   :: "f"(A_tmp) , "r"(A_ptr) : "memory");
     204:	0901                	addi	x18,x18,0
     206:	0004                	0x4
    asm volatile("flw     %0,    0(%1)"   : "=f"(B_tmp) : "r"(B)     : "memory");
     208:	0301                	addi	x6,x6,0
     20a:	0901                	addi	x18,x18,0
    asm volatile("flw     %0,    0(%1)"   : "=f"(A_tmp) : "r"(A)     : "memory");
     20c:	0004                	0x4
     20e:	0301                	addi	x6,x6,0
    asm volatile("fsw     %0,    0(%1)"   :: "f"(B_tmp) , "r"(B_ptr) : "memory");
     210:	0901                	addi	x18,x18,0
     212:	0004                	0x4
  for(uint32_t i = 0; i < 255; i++) {
     214:	0301                	addi	x6,x6,0
     216:	0901                	addi	x18,x18,0
     218:	0004                	0x4
     21a:	0301                	addi	x6,x6,0
  bsg_saif_start();
     21c:	0901                	addi	x18,x18,0
     21e:	0004                	0x4
  asm volatile("flw     %0,    0(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     220:	0301                	addi	x6,x6,0
     222:	0905                	addi	x18,x18,1
  asm volatile("flw     %0,    0(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     224:	0004                	0x4
     226:	0301                	addi	x6,x6,0
     228:	0902                	c.slli64	x18
     22a:	0008                	0x8
     22c:	0301                	addi	x6,x6,0
     22e:	0901                	addi	x18,x18,0
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     230:	0008                	0x8
     232:	0301                	addi	x6,x6,0
  asm volatile("flw     %0,    4(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     234:	0904                	addi	x9,x2,144
     236:	0004                	0x4
  asm volatile("flw     %0,    4(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     238:	0301                	addi	x6,x6,0
     23a:	0008090b          	0x8090b
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     23e:	0301                	addi	x6,x6,0
  asm volatile("flw     %0,    8(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     240:	0905                	addi	x18,x18,1
     242:	0004                	0x4
  asm volatile("flw     %0,    8(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     244:	0901                	addi	x18,x18,0
     246:	0004                	0x4
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     248:	0100                	addi	x8,x2,128
     24a:	3801                	jal	fffffa5a <_bsg_dram_end_addr+0x7efffa5a>
  asm volatile("flw     %0,   12(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     24c:	03000003          	lb	x0,48(x0) # 30 <__bsg_x+0x4>
  asm volatile("flw     %0,   12(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     250:	c300                	sw	x8,0(x14)
     252:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     254:	0100                	addi	x8,x2,128
     256:	fb01                	bnez	x14,166 <bsg_set_tile_x_y+0x3e>
  asm volatile("flw     %0,   16(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     258:	0d0e                	slli	x26,x26,0x3
     25a:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,   16(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     25c:	0101                	addi	x2,x2,0
     25e:	0001                	nop
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     260:	0000                	unimp
     262:	0001                	nop
  asm volatile("flw     %0,   20(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     264:	0100                	addi	x8,x2,128
     266:	726f772f          	0x726f772f
  asm volatile("flw     %0,   20(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     26a:	6c672f6b          	0x6c672f6b
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     26e:	6c61626f          	jal	x4,16934 <_bsg_elf_stack_ptr+0x15938>
  asm volatile("flw     %0,   24(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     272:	38636c2f          	0x38636c2f
  asm volatile("flw     %0,   24(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     276:	772f3337          	lui	x6,0x772f3
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     27a:	2f6b726f          	jal	x4,b7570 <_bsg_elf_stack_ptr+0xb6574>
  asm volatile("flw     %0,   28(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     27e:	2f686473          	csrrsi	x8,0x2f6,16
  asm volatile("flw     %0,   28(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     282:	6c70                	flw	f12,92(x8)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     284:	7961                	lui	x18,0xffff8
     286:	756f7267          	0x756f7267
  asm volatile("flw     %0,   32(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     28a:	646e                	flw	f8,216(x2)
  asm volatile("flw     %0,   32(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     28c:	6769622f          	0x6769622f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     290:	6c62                	flw	f24,24(x2)
     292:	6461                	lui	x8,0x18
  asm volatile("flw     %0,   36(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     294:	2d65                	jal	94c <_gp+0x144>
     296:	6e65                	lui	x28,0x19
  asm volatile("flw     %0,   36(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     298:	7265                	lui	x4,0xffff9
     29a:	622f7967          	0x622f7967
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     29e:	625f6773          	csrrsi	x14,0x625,30
  asm volatile("flw     %0,   40(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     2a2:	616c                	flw	f11,68(x10)
  asm volatile("flw     %0,   40(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     2a4:	6564                	flw	f9,76(x10)
     2a6:	7572                	flw	f10,60(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     2a8:	6e6e                	flw	f28,216(x2)
     2aa:	7265                	lui	x4,0xffff9
  asm volatile("flw     %0,   44(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     2ac:	6773622f          	0x6773622f
  asm volatile("flw     %0,   44(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     2b0:	6d5f 6e61 6379      	0x63796e616d5f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     2b6:	2f65726f          	jal	x4,575ac <_bsg_elf_stack_ptr+0x565b0>
  asm volatile("flw     %0,   48(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     2ba:	74666f73          	csrrsi	x30,0x746,12
  asm volatile("flw     %0,   48(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     2be:	65726177          	0x65726177
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     2c2:	6773622f          	0x6773622f
  asm volatile("flw     %0,   52(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     2c6:	6d5f 6e61 6379      	0x63796e616d5f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     2cc:	5f65726f          	jal	x4,578c2 <_bsg_elf_stack_ptr+0x568c6>
  asm volatile("flw     %0,   56(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     2d0:	696c                	flw	f11,84(x10)
     2d2:	0062                	c.slli	x0,0x18
  asm volatile("flw     %0,   56(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     2d4:	6200                	flw	f8,0(x12)
     2d6:	735f6773          	csrrsi	x14,0x735,30
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     2da:	7465                	lui	x8,0xffff9
  asm volatile("flw     %0,   60(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     2dc:	745f 6c69 5f65      	0x5f656c69745f
  asm volatile("flw     %0,   60(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     2e2:	5f78                	lw	x14,124(x14)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     2e4:	2e79                	jal	682 <kernel_energy_fadd_demo+0x4a2>
     2e6:	00010063          	beqz	x2,2e6 <kernel_energy_fadd_demo+0x106>
  asm volatile("flw     %0,   64(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     2ea:	6200                	flw	f8,0(x12)
  asm volatile("flw     %0,   64(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     2ec:	745f6773          	csrrsi	x14,0x745,30
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     2f0:	6c69                	lui	x24,0x1a
     2f2:	5f65                	li	x30,-7
  asm volatile("flw     %0,   68(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     2f4:	666e6f63          	bltu	x28,x6,972 <_gp+0x16a>
  asm volatile("flw     %0,   68(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     2f8:	6769                	lui	x14,0x1a
     2fa:	765f 7261 2e73      	0x2e737261765f
  asm volatile("flw     %0,   72(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     300:	0068                	addi	x10,x2,12
     302:	0001                	nop
  asm volatile("flw     %0,   72(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     304:	6200                	flw	f8,0(x12)
     306:	6d5f6773          	csrrsi	x14,0x6d5,30
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     30a:	6e61                	lui	x28,0x18
  asm volatile("flw     %0,   76(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     30c:	6379                	lui	x6,0x1e
     30e:	2e65726f          	jal	x4,575f4 <_bsg_elf_stack_ptr+0x565f8>
  asm volatile("flw     %0,   76(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     312:	0068                	addi	x10,x2,12
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     314:	0001                	nop
     316:	0000                	unimp
  asm volatile("flw     %0,   80(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     318:	0105                	addi	x2,x2,1
     31a:	0500                	addi	x8,x2,640
  asm volatile("flw     %0,   80(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     31c:	2802                	fld	f16,0(x2)
     31e:	0001                	nop
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     320:	1700                	addi	x8,x2,928
     322:	0305                	addi	x6,x6,1
  asm volatile("flw     %0,   84(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     324:	00090103          	lb	x2,0(x18) # ffff8000 <_bsg_dram_end_addr+0x7eff8000>
  asm volatile("flw     %0,   84(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     328:	0100                	addi	x8,x2,128
     32a:	00090103          	lb	x2,0(x18)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     32e:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,   88(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     330:	00090203          	lb	x4,0(x18)
  asm volatile("flw     %0,   88(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     334:	0100                	addi	x8,x2,128
     336:	00090103          	lb	x2,0(x18)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     33a:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,   92(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     33c:	00090303          	lb	x6,0(x18)
  asm volatile("flw     %0,   92(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     340:	0100                	addi	x8,x2,128
     342:	00090003          	lb	x0,0(x18)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     346:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,   96(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     348:	0306                	slli	x6,x6,0x1
     34a:	0901                	addi	x18,x18,0
  asm volatile("flw     %0,   96(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     34c:	0008                	0x8
     34e:	0301                	addi	x6,x6,0
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     350:	097f                	0x97f
     352:	0000                	unimp
  asm volatile("flw     %0,  100(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     354:	0301                	addi	x6,x6,0
     356:	0901                	addi	x18,x18,0
  asm volatile("flw     %0,  100(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     358:	0004                	0x4
     35a:	0301                	addi	x6,x6,0
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     35c:	097f                	0x97f
     35e:	0004                	0x4
  asm volatile("flw     %0,  104(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     360:	0601                	addi	x12,x12,0
     362:	04090003          	lb	x0,64(x18)
  asm volatile("flw     %0,  104(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     366:	0100                	addi	x8,x2,128
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     368:	00090103          	lb	x2,0(x18)
  asm volatile("flw     %0,  108(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     36c:	0100                	addi	x8,x2,128
     36e:	00090003          	lb	x0,0(x18)
  asm volatile("flw     %0,  108(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     372:	0100                	addi	x8,x2,128
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     374:	0200                	addi	x8,x2,256
     376:	0104                	addi	x9,x2,128
  asm volatile("flw     %0,  112(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     378:	08090003          	lb	x0,128(x18)
  asm volatile("flw     %0,  112(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     37c:	0100                	addi	x8,x2,128
     37e:	0200                	addi	x8,x2,256
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     380:	0104                	addi	x9,x2,128
     382:	00090203          	lb	x4,0(x18)
  asm volatile("flw     %0,  116(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     386:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,  116(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     388:	0200                	addi	x8,x2,256
     38a:	0104                	addi	x9,x2,128
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     38c:	00090003          	lb	x0,0(x18)
  asm volatile("flw     %0,  120(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     390:	0100                	addi	x8,x2,128
     392:	0200                	addi	x8,x2,256
  asm volatile("flw     %0,  120(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     394:	0104                	addi	x9,x2,128
     396:	00090003          	lb	x0,0(x18)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     39a:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,  124(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     39c:	0200                	addi	x8,x2,256
     39e:	0104                	addi	x9,x2,128
  asm volatile("flw     %0,  124(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     3a0:	08090103          	lb	x2,128(x18)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     3a4:	0100                	addi	x8,x2,128
     3a6:	0200                	addi	x8,x2,256
  asm volatile("flw     %0,  128(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     3a8:	0104                	addi	x9,x2,128
     3aa:	00090003          	lb	x0,0(x18)
  asm volatile("flw     %0,  128(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     3ae:	0100                	addi	x8,x2,128
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     3b0:	0200                	addi	x8,x2,256
     3b2:	0104                	addi	x9,x2,128
  asm volatile("flw     %0,  132(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     3b4:	00090003          	lb	x0,0(x18)
  asm volatile("flw     %0,  132(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     3b8:	0100                	addi	x8,x2,128
     3ba:	08090203          	lb	x4,128(x18)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     3be:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,  136(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     3c0:	0805                	addi	x16,x16,1
     3c2:	0306                	slli	x6,x6,0x1
  asm volatile("flw     %0,  136(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     3c4:	0900                	addi	x8,x2,144
     3c6:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     3c8:	0501                	addi	x10,x10,0
     3ca:	0306                	slli	x6,x6,0x1
  asm volatile("flw     %0,  140(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     3cc:	0900                	addi	x8,x2,144
     3ce:	0004                	0x4
  asm volatile("flw     %0,  140(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     3d0:	0501                	addi	x10,x10,0
     3d2:	0015                	c.nop	5
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     3d4:	0402                	c.slli64	x8
     3d6:	0301                	addi	x6,x6,0
  asm volatile("flw     %0,  144(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     3d8:	0900                	addi	x8,x2,144
     3da:	0004                	0x4
  asm volatile("flw     %0,  144(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     3dc:	0501                	addi	x10,x10,0
     3de:	0011                	c.nop	4
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     3e0:	0402                	c.slli64	x8
     3e2:	0301                	addi	x6,x6,0
  asm volatile("flw     %0,  148(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     3e4:	0900                	addi	x8,x2,144
     3e6:	0004                	0x4
  asm volatile("flw     %0,  148(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     3e8:	0501                	addi	x10,x10,0
     3ea:	0015                	c.nop	5
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     3ec:	0402                	c.slli64	x8
     3ee:	0601                	addi	x12,x12,0
  asm volatile("flw     %0,  152(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     3f0:	04090103          	lb	x2,64(x18)
  asm volatile("flw     %0,  152(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     3f4:	0100                	addi	x8,x2,128
     3f6:	1705                	addi	x14,x14,-31
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     3f8:	0200                	addi	x8,x2,256
     3fa:	0104                	addi	x9,x2,128
  asm volatile("flw     %0,  156(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     3fc:	00090103          	lb	x2,0(x18)
  asm volatile("flw     %0,  156(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     400:	0100                	addi	x8,x2,128
     402:	0905                	addi	x18,x18,1
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     404:	0200                	addi	x8,x2,256
     406:	0104                	addi	x9,x2,128
  asm volatile("flw     %0,  160(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     408:	00090203          	lb	x4,0(x18)
  asm volatile("flw     %0,  160(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     40c:	0100                	addi	x8,x2,128
     40e:	0200                	addi	x8,x2,256
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     410:	0104                	addi	x9,x2,128
     412:	00090003          	lb	x0,0(x18)
  asm volatile("flw     %0,  164(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     416:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,  164(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     418:	0200                	addi	x8,x2,256
     41a:	0104                	addi	x9,x2,128
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     41c:	04090003          	lb	x0,64(x18)
  asm volatile("flw     %0,  168(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     420:	0100                	addi	x8,x2,128
     422:	0200                	addi	x8,x2,256
  asm volatile("flw     %0,  168(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     424:	0104                	addi	x9,x2,128
     426:	00090103          	lb	x2,0(x18)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     42a:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,  172(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     42c:	0200                	addi	x8,x2,256
     42e:	0104                	addi	x9,x2,128
  asm volatile("flw     %0,  172(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     430:	00090003          	lb	x0,0(x18)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     434:	0100                	addi	x8,x2,128
     436:	0200                	addi	x8,x2,256
  asm volatile("flw     %0,  176(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     438:	0104                	addi	x9,x2,128
     43a:	04090003          	lb	x0,64(x18)
  asm volatile("flw     %0,  176(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     43e:	0100                	addi	x8,x2,128
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     440:	2805                	jal	470 <kernel_energy_fadd_demo+0x290>
     442:	0200                	addi	x8,x2,256
  asm volatile("flw     %0,  180(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     444:	0104                	addi	x9,x2,128
     446:	00097d03          	0x97d03
  asm volatile("flw     %0,  180(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     44a:	0100                	addi	x8,x2,128
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     44c:	1705                	addi	x14,x14,-31
     44e:	0200                	addi	x8,x2,256
  asm volatile("flw     %0,  184(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     450:	0104                	addi	x9,x2,128
     452:	00090003          	lb	x0,0(x18)
  asm volatile("flw     %0,  184(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     456:	0100                	addi	x8,x2,128
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     458:	1505                	addi	x10,x10,-31
     45a:	0200                	addi	x8,x2,256
  asm volatile("flw     %0,  188(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     45c:	0104                	addi	x9,x2,128
     45e:	00097f03          	0x97f03
  asm volatile("flw     %0,  188(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     462:	0100                	addi	x8,x2,128
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     464:	0305                	addi	x6,x6,1
     466:	00090703          	lb	x14,0(x18)
  asm volatile("flw     %0,  192(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     46a:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,  192(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     46c:	1105                	addi	x2,x2,-31
     46e:	0306                	slli	x6,x6,0x1
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     470:	0900                	addi	x8,x2,144
     472:	0000                	unimp
  asm volatile("flw     %0,  196(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     474:	0501                	addi	x10,x10,0
     476:	01030603          	lb	x12,16(x6) # 1e010 <_bsg_elf_stack_ptr+0x1d014>
  asm volatile("flw     %0,  196(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     47a:	2009                	jal	47c <kernel_energy_fadd_demo+0x29c>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     47c:	0100                	addi	x8,x2,128
     47e:	1605                	addi	x12,x12,-31
  asm volatile("flw     %0,  200(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     480:	0306                	slli	x6,x6,0x1
     482:	0902                	c.slli64	x18
  asm volatile("flw     %0,  200(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     484:	0000                	unimp
     486:	0501                	addi	x10,x10,0
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     488:	0311                	addi	x6,x6,4
     48a:	097e                	slli	x18,x18,0x1f
  asm volatile("flw     %0,  204(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     48c:	0004                	0x4
     48e:	0501                	addi	x10,x10,0
  asm volatile("flw     %0,  204(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     490:	0314                	addi	x13,x2,384
     492:	0902                	c.slli64	x18
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     494:	0004                	0x4
     496:	0501                	addi	x10,x10,0
  asm volatile("flw     %0,  208(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     498:	0311                	addi	x6,x6,4
     49a:	097e                	slli	x18,x18,0x1f
  asm volatile("flw     %0,  208(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     49c:	0000                	unimp
     49e:	0501                	addi	x10,x10,0
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     4a0:	02030603          	lb	x12,32(x6)
  asm volatile("flw     %0,  212(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     4a4:	0409                	addi	x8,x8,2
     4a6:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,  212(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     4a8:	1405                	addi	x8,x8,-31
     4aa:	0306                	slli	x6,x6,0x1
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     4ac:	0900                	addi	x8,x2,144
     4ae:	0000                	unimp
  asm volatile("flw     %0,  216(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     4b0:	0501                	addi	x10,x10,0
     4b2:	01030603          	lb	x12,16(x6)
  asm volatile("flw     %0,  216(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     4b6:	0409                	addi	x8,x8,2
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     4b8:	0100                	addi	x8,x2,128
     4ba:	1605                	addi	x12,x12,-31
  asm volatile("flw     %0,  220(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     4bc:	0306                	slli	x6,x6,0x1
     4be:	0900                	addi	x8,x2,144
  asm volatile("flw     %0,  220(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     4c0:	0000                	unimp
     4c2:	0501                	addi	x10,x10,0
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     4c4:	0324                	addi	x9,x2,392
     4c6:	0901                	addi	x18,x18,0
  asm volatile("flw     %0,  224(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     4c8:	0004                	0x4
     4ca:	0501                	addi	x10,x10,0
  asm volatile("flw     %0,  224(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     4cc:	0314                	addi	x13,x2,384
     4ce:	0901                	addi	x18,x18,0
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     4d0:	0004                	0x4
     4d2:	0301                	addi	x6,x6,0
  asm volatile("flw     %0,  228(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     4d4:	097e                	slli	x18,x18,0x1f
     4d6:	0004                	0x4
  asm volatile("flw     %0,  228(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     4d8:	0501                	addi	x10,x10,0
     4da:	030c                	addi	x11,x2,384
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     4dc:	0901                	addi	x18,x18,0
     4de:	0000                	unimp
  asm volatile("flw     %0,  232(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     4e0:	0501                	addi	x10,x10,0
     4e2:	0314                	addi	x13,x2,384
  asm volatile("flw     %0,  232(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     4e4:	0901                	addi	x18,x18,0
     4e6:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     4e8:	0301                	addi	x6,x6,0
     4ea:	0901                	addi	x18,x18,0
  asm volatile("flw     %0,  236(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     4ec:	0000                	unimp
     4ee:	0501                	addi	x10,x10,0
  asm volatile("flw     %0,  236(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     4f0:	0319                	addi	x6,x6,6
     4f2:	0901                	addi	x18,x18,0
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     4f4:	0000                	unimp
     4f6:	0301                	addi	x6,x6,0
  asm volatile("flw     %0,  240(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     4f8:	0901                	addi	x18,x18,0
     4fa:	0000                	unimp
  asm volatile("flw     %0,  240(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     4fc:	0501                	addi	x10,x10,0
     4fe:	09010317          	auipc	x6,0x9010
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     502:	0000                	unimp
  asm volatile("flw     %0,  244(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     504:	0501                	addi	x10,x10,0
     506:	0314                	addi	x13,x2,384
  asm volatile("flw     %0,  244(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     508:	097a                	slli	x18,x18,0x1e
     50a:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     50c:	0501                	addi	x10,x10,0
     50e:	01030603          	lb	x12,16(x6) # 901050e <_bsg_elf_vcache_size+0x8f1050e>
  asm volatile("flw     %0,  248(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     512:	0409                	addi	x8,x8,2
  asm volatile("flw     %0,  248(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     514:	0100                	addi	x8,x2,128
     516:	0c05                	addi	x24,x24,1
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     518:	0306                	slli	x6,x6,0x1
     51a:	0900                	addi	x8,x2,144
  asm volatile("flw     %0,  252(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     51c:	0000                	unimp
     51e:	0501                	addi	x10,x10,0
  asm volatile("flw     %0,  252(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     520:	01030603          	lb	x12,16(x6)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     524:	0409                	addi	x8,x8,2
     526:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,  256(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     528:	1405                	addi	x8,x8,-31
     52a:	0306                	slli	x6,x6,0x1
  asm volatile("flw     %0,  256(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     52c:	0900                	addi	x8,x2,144
     52e:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     530:	0501                	addi	x10,x10,0
     532:	01030603          	lb	x12,16(x6)
  asm volatile("flw     %0,  260(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     536:	0409                	addi	x8,x8,2
  asm volatile("flw     %0,  260(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     538:	0100                	addi	x8,x2,128
     53a:	1405                	addi	x8,x8,-31
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     53c:	0306                	slli	x6,x6,0x1
     53e:	0900                	addi	x8,x2,144
  asm volatile("flw     %0,  264(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     540:	0000                	unimp
     542:	0501                	addi	x10,x10,0
  asm volatile("flw     %0,  264(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     544:	01030603          	lb	x12,16(x6)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     548:	0409                	addi	x8,x8,2
     54a:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,  268(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     54c:	1905                	addi	x18,x18,-31
     54e:	0306                	slli	x6,x6,0x1
  asm volatile("flw     %0,  268(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     550:	0900                	addi	x8,x2,144
     552:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     554:	0501                	addi	x10,x10,0
     556:	01030603          	lb	x12,16(x6)
  asm volatile("flw     %0,  272(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     55a:	0409                	addi	x8,x8,2
  asm volatile("flw     %0,  272(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     55c:	0100                	addi	x8,x2,128
     55e:	1905                	addi	x18,x18,-31
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     560:	0306                	slli	x6,x6,0x1
     562:	0900                	addi	x8,x2,144
  asm volatile("flw     %0,  276(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     564:	0000                	unimp
     566:	0501                	addi	x10,x10,0
  asm volatile("flw     %0,  276(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     568:	01030603          	lb	x12,16(x6)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     56c:	0409                	addi	x8,x8,2
     56e:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,  280(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     570:	1705                	addi	x14,x14,-31
     572:	0306                	slli	x6,x6,0x1
  asm volatile("flw     %0,  280(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     574:	0900                	addi	x8,x2,144
     576:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     578:	0501                	addi	x10,x10,0
     57a:	0301                	addi	x6,x6,0
  asm volatile("flw     %0,  284(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     57c:	0901                	addi	x18,x18,0
     57e:	0004                	0x4
  asm volatile("flw     %0,  284(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     580:	0901                	addi	x18,x18,0
     582:	0004                	0x4
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     584:	0100                	addi	x8,x2,128
     586:	a101                	j	986 <_gp+0x17e>
  asm volatile("flw     %0,  288(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     588:	0000                	unimp
     58a:	0300                	addi	x8,x2,384
  asm volatile("flw     %0,  288(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     58c:	9b00                	0x9b00
     58e:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     590:	0100                	addi	x8,x2,128
     592:	fb01                	bnez	x14,4a2 <kernel_energy_fadd_demo+0x2c2>
  asm volatile("flw     %0,  292(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     594:	0d0e                	slli	x26,x26,0x3
     596:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,  292(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     598:	0101                	addi	x2,x2,0
     59a:	0001                	nop
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     59c:	0000                	unimp
     59e:	0001                	nop
  asm volatile("flw     %0,  296(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     5a0:	0100                	addi	x8,x2,128
     5a2:	726f772f          	0x726f772f
  asm volatile("flw     %0,  296(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     5a6:	6c672f6b          	0x6c672f6b
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     5aa:	6c61626f          	jal	x4,16c70 <_bsg_elf_stack_ptr+0x15c74>
  asm volatile("flw     %0,  300(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     5ae:	38636c2f          	0x38636c2f
  asm volatile("flw     %0,  300(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     5b2:	772f3337          	lui	x6,0x772f3
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     5b6:	2f6b726f          	jal	x4,b78ac <_bsg_elf_stack_ptr+0xb68b0>
  asm volatile("flw     %0,  304(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     5ba:	2f686473          	csrrsi	x8,0x2f6,16
  asm volatile("flw     %0,  304(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     5be:	6c70                	flw	f12,92(x8)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     5c0:	7961                	lui	x18,0xffff8
     5c2:	756f7267          	0x756f7267
  asm volatile("flw     %0,  308(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     5c6:	646e                	flw	f8,216(x2)
  asm volatile("flw     %0,  308(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     5c8:	6769622f          	0x6769622f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     5cc:	6c62                	flw	f24,24(x2)
     5ce:	6461                	lui	x8,0x18
  asm volatile("flw     %0,  312(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     5d0:	2d65                	jal	c88 <_gp+0x480>
     5d2:	6e65                	lui	x28,0x19
  asm volatile("flw     %0,  312(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     5d4:	7265                	lui	x4,0xffff9
     5d6:	622f7967          	0x622f7967
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     5da:	625f6773          	csrrsi	x14,0x625,30
  asm volatile("flw     %0,  316(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     5de:	616c                	flw	f11,68(x10)
  asm volatile("flw     %0,  316(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     5e0:	6564                	flw	f9,76(x10)
     5e2:	7572                	flw	f10,60(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     5e4:	6e6e                	flw	f28,216(x2)
     5e6:	7265                	lui	x4,0xffff9
  asm volatile("flw     %0,  320(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     5e8:	6773622f          	0x6773622f
  asm volatile("flw     %0,  320(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     5ec:	6d5f 6e61 6379      	0x63796e616d5f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     5f2:	2f65726f          	jal	x4,578e8 <_bsg_elf_stack_ptr+0x568ec>
  asm volatile("flw     %0,  324(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     5f6:	74666f73          	csrrsi	x30,0x746,12
  asm volatile("flw     %0,  324(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     5fa:	65726177          	0x65726177
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     5fe:	6773622f          	0x6773622f
  asm volatile("flw     %0,  328(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     602:	6d5f 6e61 6379      	0x63796e616d5f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     608:	5f65726f          	jal	x4,57bfe <_bsg_elf_stack_ptr+0x56c02>
  asm volatile("flw     %0,  332(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     60c:	696c                	flw	f11,84(x10)
     60e:	0062                	c.slli	x0,0x18
  asm volatile("flw     %0,  332(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     610:	6200                	flw	f8,0(x12)
     612:	745f6773          	csrrsi	x14,0x745,30
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     616:	6c69                	lui	x24,0x1a
  asm volatile("flw     %0,  336(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     618:	5f65                	li	x30,-7
     61a:	666e6f63          	bltu	x28,x6,c98 <_gp+0x490>
  asm volatile("flw     %0,  336(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     61e:	6769                	lui	x14,0x1a
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     620:	765f 7261 2e73      	0x2e737261765f
  asm volatile("flw     %0,  340(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     626:	00010063          	beqz	x2,626 <kernel_energy_fadd_demo+0x446>
  asm volatile("flw     %0,  340(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     62a:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     62c:	035e                	slli	x6,x6,0x17
     62e:	0000                	unimp
  asm volatile("flw     %0,  344(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     630:	029a0003          	lb	x0,41(x20)
  asm volatile("flw     %0,  344(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     634:	0000                	unimp
     636:	0101                	addi	x2,x2,0
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     638:	000d0efb          	0xd0efb
  asm volatile("flw     %0,  348(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     63c:	0101                	addi	x2,x2,0
     63e:	0101                	addi	x2,x2,0
  asm volatile("flw     %0,  348(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     640:	0000                	unimp
     642:	0100                	addi	x8,x2,128
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     644:	0000                	unimp
     646:	2f01                	jal	d56 <_gp+0x54e>
  asm volatile("flw     %0,  352(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     648:	6b726f77          	0x6b726f77
  asm volatile("flw     %0,  352(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     64c:	6f6c672f          	0x6f6c672f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     650:	6162                	flw	f2,24(x2)
     652:	2f6c                	fld	f11,216(x14)
  asm volatile("flw     %0,  356(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     654:	636c                	flw	f11,68(x14)
     656:	3738                	fld	f14,104(x14)
  asm volatile("flw     %0,  356(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     658:	6f772f33          	0x6f772f33
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     65c:	6b72                	flw	f22,28(x2)
     65e:	6864732f          	0x6864732f
  asm volatile("flw     %0,  360(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     662:	616c702f          	0x616c702f
  asm volatile("flw     %0,  360(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     666:	6779                	lui	x14,0x1e
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     668:	6f72                	flw	f30,28(x2)
     66a:	6e75                	lui	x28,0x1d
  asm volatile("flw     %0,  364(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     66c:	2f64                	fld	f9,216(x14)
     66e:	6962                	flw	f18,24(x2)
  asm volatile("flw     %0,  364(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     670:	616c6267          	0x616c6267
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     674:	6564                	flw	f9,76(x10)
     676:	652d                	lui	x10,0xb
  asm volatile("flw     %0,  368(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     678:	656e                	flw	f10,216(x2)
     67a:	6772                	flw	f14,28(x2)
  asm volatile("flw     %0,  368(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     67c:	2f79                	jal	e1a <_gp+0x612>
     67e:	7362                	flw	f6,56(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     680:	6c625f67          	0x6c625f67
  asm volatile("flw     %0,  372(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     684:	6461                	lui	x8,0x18
     686:	7265                	lui	x4,0xffff9
  asm volatile("flw     %0,  372(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     688:	6e75                	lui	x28,0x1d
     68a:	656e                	flw	f10,216(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     68c:	2f72                	fld	f30,280(x2)
     68e:	7362                	flw	f6,56(x2)
  asm volatile("flw     %0,  376(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     690:	616d5f67          	0x616d5f67
  asm volatile("flw     %0,  376(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     694:	796e                	flw	f18,248(x2)
     696:	65726f63          	bltu	x4,x23,cf4 <_gp+0x4ec>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     69a:	666f732f          	0x666f732f
  asm volatile("flw     %0,  380(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     69e:	7774                	flw	f13,108(x14)
  asm volatile("flw     %0,  380(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     6a0:	7261                	lui	x4,0xffff8
     6a2:	2f65                	jal	e5a <_GLOBAL__sub_I_kernel.cpp+0x22>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     6a4:	7362                	flw	f6,56(x2)
     6a6:	616d5f67          	0x616d5f67
  asm volatile("flw     %0,  384(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     6aa:	796e                	flw	f18,248(x2)
  asm volatile("flw     %0,  384(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     6ac:	65726f63          	bltu	x4,x23,d0a <_gp+0x502>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     6b0:	6c5f 6269 2f00      	0x2f0062696c5f
  asm volatile("flw     %0,  388(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     6b6:	6b726f77          	0x6b726f77
  asm volatile("flw     %0,  388(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     6ba:	6f6c672f          	0x6f6c672f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     6be:	6162                	flw	f2,24(x2)
  asm volatile("flw     %0,  392(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     6c0:	2f6c                	fld	f11,216(x14)
     6c2:	636c                	flw	f11,68(x14)
  asm volatile("flw     %0,  392(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     6c4:	3738                	fld	f14,104(x14)
     6c6:	6f772f33          	0x6f772f33
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     6ca:	6b72                	flw	f22,28(x2)
  asm volatile("flw     %0,  396(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     6cc:	6864732f          	0x6864732f
  asm volatile("flw     %0,  396(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     6d0:	616c702f          	0x616c702f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     6d4:	6779                	lui	x14,0x1e
     6d6:	6f72                	flw	f30,28(x2)
  asm volatile("flw     %0,  400(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     6d8:	6e75                	lui	x28,0x1d
     6da:	2f64                	fld	f9,216(x14)
  asm volatile("flw     %0,  400(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     6dc:	6962                	flw	f18,24(x2)
     6de:	616c6267          	0x616c6267
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     6e2:	6564                	flw	f9,76(x10)
  asm volatile("flw     %0,  404(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     6e4:	652d                	lui	x10,0xb
     6e6:	656e                	flw	f10,216(x2)
  asm volatile("flw     %0,  404(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     6e8:	6772                	flw	f14,28(x2)
     6ea:	2f79                	jal	e88 <__init_param+0x4>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     6ec:	7362                	flw	f6,56(x2)
     6ee:	6c625f67          	0x6c625f67
  asm volatile("flw     %0,  408(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     6f2:	6461                	lui	x8,0x18
  asm volatile("flw     %0,  408(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     6f4:	7265                	lui	x4,0xffff9
     6f6:	6e75                	lui	x28,0x1d
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     6f8:	656e                	flw	f10,216(x2)
     6fa:	2f72                	fld	f30,280(x2)
  asm volatile("flw     %0,  412(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     6fc:	7362                	flw	f6,56(x2)
     6fe:	616d5f67          	0x616d5f67
  asm volatile("flw     %0,  412(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     702:	796e                	flw	f18,248(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     704:	65726f63          	bltu	x4,x23,d62 <_gp+0x55a>
  asm volatile("flw     %0,  416(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     708:	666f732f          	0x666f732f
  asm volatile("flw     %0,  416(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     70c:	7774                	flw	f13,108(x14)
     70e:	7261                	lui	x4,0xffff8
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     710:	2f65                	jal	ec8 <__load_argument+0x24>
     712:	646d7073          	csrci	0x646,26
  asm volatile("flw     %0,  420(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     716:	73622f2f          	0x73622f2f
  asm volatile("flw     %0,  420(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     71a:	75635f67          	0x75635f67
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     71e:	6164                	flw	f9,68(x10)
  asm volatile("flw     %0,  424(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     720:	6c5f 7469 5f65      	0x5f6574696c5f
  asm volatile("flw     %0,  424(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     726:	7572                	flw	f10,60(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     728:	746e                	flw	f8,248(x2)
     72a:	6d69                	lui	x26,0x1a
  asm volatile("flw     %0,  428(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     72c:	2f65                	jal	ee4 <__load_stack>
     72e:	69616d2f          	0x69616d2f
  asm volatile("flw     %0,  428(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     732:	006e                	c.slli	x0,0x1b
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     734:	726f772f          	0x726f772f
  asm volatile("flw     %0,  432(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     738:	6c672f6b          	0x6c672f6b
  asm volatile("flw     %0,  432(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     73c:	6c61626f          	jal	x4,16e02 <_bsg_elf_stack_ptr+0x15e06>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     740:	6772622f          	0x6772622f
  asm volatile("flw     %0,  436(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     744:	736e692f          	0x736e692f
  asm volatile("flw     %0,  436(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     748:	6174                	flw	f13,68(x10)
     74a:	6c6c                	flw	f11,92(x8)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     74c:	7261622f          	0x7261622f
  asm volatile("flw     %0,  440(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     750:	2d65                	jal	e08 <_gp+0x600>
     752:	6b70                	flw	f12,84(x14)
  asm volatile("flw     %0,  440(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     754:	782f7367          	0x782f7367
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     758:	3638                	fld	f14,104(x12)
     75a:	365f 2d34 6563      	0x65632d34365f
  asm volatile("flw     %0,  444(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     760:	746e                	flw	f8,248(x2)
     762:	2f37736f          	jal	x6,78254 <_bsg_elf_stack_ptr+0x77258>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     766:	6b70                	flw	f12,84(x14)
  asm volatile("flw     %0,  448(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     768:	622f7367          	0x622f7367
  asm volatile("flw     %0,  448(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     76c:	6d5f6773          	csrrsi	x14,0x6d5,30
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     770:	6e61                	lui	x28,0x18
     772:	6379                	lui	x6,0x1e
  asm volatile("flw     %0,  452(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     774:	5f65726f          	jal	x4,57d6a <_bsg_elf_stack_ptr+0x56d6e>
  asm volatile("flw     %0,  452(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     778:	6f74                	flw	f13,92(x14)
     77a:	5f736c6f          	jal	x24,37570 <_bsg_elf_stack_ptr+0x36574>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     77e:	3476                	fld	f8,376(x2)
  asm volatile("flw     %0,  456(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     780:	332e                	fld	f6,232(x2)
     782:	302e                	fld	f0,232(x2)
  asm volatile("flw     %0,  456(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     784:	666f732f          	0x666f732f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     788:	7774                	flw	f13,108(x14)
     78a:	7261                	lui	x4,0xffff8
  asm volatile("flw     %0,  460(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     78c:	2f65                	jal	f44 <__.text.dram_end>
     78e:	6972                	flw	f18,28(x2)
  asm volatile("flw     %0,  460(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     790:	2d766373          	csrrsi	x6,0x2d7,12
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     794:	6f74                	flw	f13,92(x14)
     796:	2f736c6f          	jal	x24,3728c <_bsg_elf_stack_ptr+0x36290>
  asm volatile("flw     %0,  464(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     79a:	6972                	flw	f18,28(x2)
  asm volatile("flw     %0,  464(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     79c:	2d766373          	csrrsi	x6,0x2d7,12
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     7a0:	6e69                	lui	x28,0x1a
     7a2:	6c617473          	csrrci	x8,0x6c6,2
  asm volatile("flw     %0,  468(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     7a6:	2f6c                	fld	f11,216(x14)
  asm volatile("flw     %0,  468(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     7a8:	6972                	flw	f18,28(x2)
     7aa:	33766373          	csrrsi	x6,mhpmevent23,12
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     7ae:	2d32                	fld	f26,264(x2)
  asm volatile("flw     %0,  472(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     7b0:	6e75                	lui	x28,0x1d
     7b2:	776f6e6b          	0x776f6e6b
  asm volatile("flw     %0,  472(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     7b6:	2d6e                	fld	f26,216(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     7b8:	6c65                	lui	x24,0x19
     7ba:	2d66                	fld	f26,88(x2)
  asm volatile("flw     %0,  476(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     7bc:	7264                	flw	f9,100(x12)
     7be:	6d61                	lui	x26,0x18
  asm volatile("flw     %0,  476(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     7c0:	7366                	flw	f6,120(x2)
     7c2:	636e692f          	0x636e692f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     7c6:	756c                	flw	f11,108(x10)
  asm volatile("flw     %0,  480(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     7c8:	6564                	flw	f9,76(x10)
     7ca:	63616d2f          	0x63616d2f
  asm volatile("flw     %0,  480(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     7ce:	6968                	flw	f10,84(x10)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     7d0:	656e                	flw	f10,216(x2)
     7d2:	2f00                	fld	f8,24(x14)
  asm volatile("flw     %0,  484(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     7d4:	6b726f77          	0x6b726f77
  asm volatile("flw     %0,  484(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     7d8:	6f6c672f          	0x6f6c672f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     7dc:	6162                	flw	f2,24(x2)
     7de:	2f6c                	fld	f11,216(x14)
  asm volatile("flw     %0,  488(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     7e0:	7262                	flw	f4,56(x2)
     7e2:	6e692f67          	0x6e692f67
  asm volatile("flw     %0,  488(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     7e6:	6c617473          	csrrci	x8,0x6c6,2
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     7ea:	2f6c                	fld	f11,216(x14)
  asm volatile("flw     %0,  492(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     7ec:	6162                	flw	f2,24(x2)
     7ee:	6572                	flw	f10,28(x2)
  asm volatile("flw     %0,  492(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     7f0:	702d                	c.lui	x0,0xfffeb
     7f2:	2f73676b          	0x2f73676b
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     7f6:	3878                	fld	f14,240(x8)
  asm volatile("flw     %0,  496(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     7f8:	5f36                	lw	x30,108(x2)
     7fa:	3436                	fld	f8,360(x2)
  asm volatile("flw     %0,  496(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     7fc:	632d                	lui	x6,0xb
     7fe:	6e65                	lui	x28,0x19
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     800:	6f74                	flw	f13,92(x14)
     802:	702f3773          	csrrc	x14,0x702,x30
  asm volatile("flw     %0,  500(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     806:	2f73676b          	0x2f73676b
  asm volatile("flw     %0,  500(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     80a:	7362                	flw	f6,56(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     80c:	616d5f67          	0x616d5f67
  asm volatile("flw     %0,  504(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     810:	796e                	flw	f18,248(x2)
     812:	65726f63          	bltu	x4,x23,e70 <main>
  asm volatile("flw     %0,  504(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     816:	745f 6f6f 736c      	0x736c6f6f745f
  asm volatile("flw     %0,  508(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     81c:	765f 2e34 2e33      	0x2e332e34765f
  asm volatile("flw     %0,  508(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     822:	2f30                	fld	f12,88(x14)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     824:	74666f73          	csrrsi	x30,0x746,12
  asm volatile("flw     %0,  512(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     828:	65726177          	0x65726177
  asm volatile("flw     %0,  512(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     82c:	7369722f          	0x7369722f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     830:	742d7663          	bgeu	x26,x2,f7c <__.text.dram_end+0x38>
  asm volatile("flw     %0,  516(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     834:	736c6f6f          	jal	x30,c6f6a <_bsg_elf_stack_ptr+0xc5f6e>
  asm volatile("flw     %0,  516(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     838:	7369722f          	0x7369722f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     83c:	692d7663          	bgeu	x26,x18,ec8 <__load_argument+0x24>
  asm volatile("flw     %0,  520(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     840:	736e                	flw	f6,248(x2)
     842:	6174                	flw	f13,68(x10)
  asm volatile("flw     %0,  520(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     844:	6c6c                	flw	f11,92(x8)
     846:	7369722f          	0x7369722f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     84a:	32337663          	bgeu	x6,x3,b76 <_gp+0x36e>
  asm volatile("flw     %0,  524(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     84e:	752d                	lui	x10,0xfffeb
  asm volatile("flw     %0,  524(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     850:	6b6e                	flw	f22,216(x2)
     852:	6f6e                	flw	f30,216(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     854:	652d6e77          	0x652d6e77
  asm volatile("flw     %0,  528(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     858:	666c                	flw	f11,76(x12)
     85a:	642d                	lui	x8,0xb
  asm volatile("flw     %0,  528(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     85c:	6172                	flw	f2,28(x2)
     85e:	666d                	lui	x12,0x1b
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     860:	6e692f73          	csrrs	x30,0x6e6,x18
  asm volatile("flw     %0,  532(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     864:	64756c63          	bltu	x10,x7,ebc <__load_argument+0x18>
  asm volatile("flw     %0,  532(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     868:	2f65                	jal	1020 <_bsg_elf_stack_ptr+0x24>
     86a:	00737973          	csrrci	x18,0x7,6
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     86e:	6200                	flw	f8,0(x12)
  asm volatile("flw     %0,  536(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     870:	635f6773          	csrrsi	x14,0x635,30
  asm volatile("flw     %0,  536(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     874:	6475                	lui	x8,0x1d
     876:	5f61                	li	x30,-8
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     878:	696c                	flw	f11,84(x10)
     87a:	6574                	flw	f13,76(x10)
  asm volatile("flw     %0,  540(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     87c:	725f 6e75 6974      	0x69746e75725f
  asm volatile("flw     %0,  540(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     882:	656d                	lui	x10,0x1b
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     884:	682e                	flw	f16,200(x2)
     886:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,  544(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     888:	0000                	unimp
     88a:	616d                	addi	x2,x2,240
  asm volatile("flw     %0,  544(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     88c:	6e69                	lui	x28,0x1a
     88e:	632e                	flw	f6,200(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     890:	0200                	addi	x8,x2,256
     892:	0000                	unimp
  asm volatile("flw     %0,  548(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     894:	7362                	flw	f6,56(x2)
     896:	69745f67          	0x69745f67
  asm volatile("flw     %0,  548(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     89a:	656c                	flw	f11,76(x10)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     89c:	635f 6e6f 6966      	0x69666e6f635f
  asm volatile("flw     %0,  552(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     8a2:	61765f67          	0x61765f67
  asm volatile("flw     %0,  552(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     8a6:	7372                	flw	f6,60(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     8a8:	682e                	flw	f16,200(x2)
     8aa:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,  556(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     8ac:	0000                	unimp
     8ae:	645f 6665 7561      	0x75616665645f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     8b4:	746c                	flw	f11,108(x8)
     8b6:	745f 7079 7365      	0x73657079745f
  asm volatile("flw     %0,  560(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     8bc:	682e                	flw	f16,200(x2)
     8be:	0300                	addi	x8,x2,384
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     8c0:	0000                	unimp
     8c2:	735f 6474 6e69      	0x6e696474735f
  asm volatile("flw     %0,  564(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     8c8:	2e74                	fld	f13,216(x12)
     8ca:	0068                	addi	x10,x2,12
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     8cc:	0004                	0x4
     8ce:	0000                	unimp
  asm volatile("flw     %0,  568(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     8d0:	0105                	addi	x2,x2,1
     8d2:	0500                	addi	x8,x2,640
  asm volatile("flw     %0,  568(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     8d4:	c802                	sw	x0,16(x2)
     8d6:	0001                	nop
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     8d8:	0300                	addi	x8,x2,384
     8da:	00c4                	addi	x9,x2,68
  asm volatile("flw     %0,  572(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     8dc:	0501                	addi	x10,x10,0
     8de:	09010303          	lb	x6,144(x2)
  asm volatile("flw     %0,  572(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     8e2:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     8e4:	0501                	addi	x10,x10,0
     8e6:	0610                	addi	x12,x2,768
  asm volatile("flw     %0,  576(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     8e8:	00090003          	lb	x0,0(x18) # ffff8000 <_bsg_dram_end_addr+0x7eff8000>
  asm volatile("flw     %0,  576(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     8ec:	0100                	addi	x8,x2,128
     8ee:	0605                	addi	x12,x12,1
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     8f0:	00090003          	lb	x0,0(x18)
  asm volatile("flw     %0,  580(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     8f4:	0100                	addi	x8,x2,128
     8f6:	0306                	slli	x6,x6,0x1
  asm volatile("flw     %0,  580(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     8f8:	0902                	c.slli64	x18
     8fa:	0008                	0x8
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     8fc:	0301                	addi	x6,x6,0
     8fe:	0901                	addi	x18,x18,0
  asm volatile("flw     %0,  584(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     900:	0000                	unimp
     902:	0501                	addi	x10,x10,0
  asm volatile("flw     %0,  584(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     904:	0612                	slli	x12,x12,0x4
     906:	00090003          	lb	x0,0(x18)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     90a:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,  588(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     90c:	0105                	addi	x2,x2,1
     90e:	0c090203          	lb	x4,192(x18)
  asm volatile("flw     %0,  588(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     912:	0100                	addi	x8,x2,128
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     914:	0409                	addi	x8,x8,2
     916:	0000                	unimp
  asm volatile("flw     %0,  592(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     918:	0101                	addi	x2,x2,0
     91a:	0204                	addi	x9,x2,256
  asm volatile("flw     %0,  592(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     91c:	0105                	addi	x2,x2,1
     91e:	0500                	addi	x8,x2,640
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     920:	7002                	flw	f0,32(x2)
     922:	000e                	c.slli	x0,0x3
  asm volatile("flw     %0,  596(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     924:	1800                	addi	x8,x2,48
     926:	0905                	addi	x18,x18,1
  asm volatile("flw     %0,  596(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     928:	00090103          	lb	x2,0(x18)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     92c:	0100                	addi	x8,x2,128
     92e:	98090003          	lb	x0,-1664(x18)
  asm volatile("flw     %0,  600(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     932:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,  600(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     934:	1c090003          	lb	x0,448(x18)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     938:	0100                	addi	x8,x2,128
     93a:	0104                	addi	x9,x2,128
  asm volatile("flw     %0,  604(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     93c:	0305                	addi	x6,x6,1
     93e:	00093e03          	0x93e03
  asm volatile("flw     %0,  604(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     942:	0100                	addi	x8,x2,128
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     944:	1005                	c.nop	-31
     946:	0306                	slli	x6,x6,0x1
  asm volatile("flw     %0,  608(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     948:	0900                	addi	x8,x2,144
     94a:	0000                	unimp
  asm volatile("flw     %0,  608(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     94c:	0501                	addi	x10,x10,0
     94e:	0306                	slli	x6,x6,0x1
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     950:	0900                	addi	x8,x2,144
     952:	0000                	unimp
  asm volatile("flw     %0,  612(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     954:	0601                	addi	x12,x12,0
     956:	08090203          	lb	x4,128(x18)
  asm volatile("flw     %0,  612(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     95a:	0100                	addi	x8,x2,128
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     95c:	00090103          	lb	x2,0(x18)
  asm volatile("flw     %0,  616(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     960:	0100                	addi	x8,x2,128
     962:	1205                	addi	x4,x4,-31
  asm volatile("flw     %0,  616(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     964:	0306                	slli	x6,x6,0x1
     966:	0900                	addi	x8,x2,144
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     968:	0000                	unimp
     96a:	0401                	addi	x8,x8,0
  asm volatile("flw     %0,  620(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     96c:	0502                	c.slli64	x10
     96e:	0609                	addi	x12,x12,2
  asm volatile("flw     %0,  620(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     970:	097fbf03          	0x97fbf03
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     974:	000c                	0xc
     976:	0501                	addi	x10,x10,0
  asm volatile("flw     %0,  624(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     978:	0322                	slli	x6,x6,0x8
     97a:	0900                	addi	x8,x2,144
  asm volatile("flw     %0,  624(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     97c:	0004                	0x4
     97e:	0501                	addi	x10,x10,0
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     980:	0601                	addi	x12,x12,0
     982:	00090103          	lb	x2,0(x18)
  asm volatile("flw     %0,  628(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     986:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,  628(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     988:	0809                	addi	x16,x16,2
     98a:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     98c:	0101                	addi	x2,x2,0
     98e:	1634                	addi	x13,x2,808
  asm volatile("flw     %0,  632(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     990:	0000                	unimp
     992:	0004                	0x4
  asm volatile("flw     %0,  632(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     994:	0368                	addi	x10,x2,396
     996:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     998:	0101                	addi	x2,x2,0
     99a:	fb01                	bnez	x14,8aa <_gp+0xa2>
  asm volatile("flw     %0,  636(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     99c:	0d0e                	slli	x26,x26,0x3
     99e:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,  636(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     9a0:	0101                	addi	x2,x2,0
     9a2:	0001                	nop
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     9a4:	0000                	unimp
     9a6:	0001                	nop
  asm volatile("flw     %0,  640(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     9a8:	0100                	addi	x8,x2,128
     9aa:	726f772f          	0x726f772f
  asm volatile("flw     %0,  640(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     9ae:	6c672f6b          	0x6c672f6b
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     9b2:	6c61626f          	jal	x4,17078 <_bsg_elf_stack_ptr+0x1607c>
  asm volatile("flw     %0,  644(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     9b6:	38636c2f          	0x38636c2f
  asm volatile("flw     %0,  644(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     9ba:	772f3337          	lui	x6,0x772f3
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     9be:	2f6b726f          	jal	x4,b7cb4 <_bsg_elf_stack_ptr+0xb6cb8>
  asm volatile("flw     %0,  648(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     9c2:	2f686473          	csrrsi	x8,0x2f6,16
  asm volatile("flw     %0,  648(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     9c6:	6c70                	flw	f12,92(x8)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     9c8:	7961                	lui	x18,0xffff8
     9ca:	756f7267          	0x756f7267
  asm volatile("flw     %0,  652(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     9ce:	646e                	flw	f8,216(x2)
  asm volatile("flw     %0,  652(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     9d0:	6769622f          	0x6769622f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     9d4:	6c62                	flw	f24,24(x2)
     9d6:	6461                	lui	x8,0x18
  asm volatile("flw     %0,  656(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     9d8:	2d65                	jal	1090 <_bsg_elf_stack_ptr+0x94>
     9da:	6e65                	lui	x28,0x19
  asm volatile("flw     %0,  656(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     9dc:	7265                	lui	x4,0xffff9
     9de:	622f7967          	0x622f7967
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     9e2:	625f6773          	csrrsi	x14,0x625,30
  asm volatile("flw     %0,  660(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     9e6:	616c                	flw	f11,68(x10)
  asm volatile("flw     %0,  660(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     9e8:	6564                	flw	f9,76(x10)
     9ea:	7572                	flw	f10,60(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     9ec:	6e6e                	flw	f28,216(x2)
     9ee:	7265                	lui	x4,0xffff9
  asm volatile("flw     %0,  664(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     9f0:	6773622f          	0x6773622f
  asm volatile("flw     %0,  664(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     9f4:	6d5f 6e61 6379      	0x63796e616d5f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     9fa:	2f65726f          	jal	x4,57cf0 <_bsg_elf_stack_ptr+0x56cf4>
  asm volatile("flw     %0,  668(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     9fe:	74666f73          	csrrsi	x30,0x746,12
  asm volatile("flw     %0,  668(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     a02:	65726177          	0x65726177
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     a06:	6773622f          	0x6773622f
  asm volatile("flw     %0,  672(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     a0a:	6d5f 6e61 6379      	0x63796e616d5f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     a10:	5f65726f          	jal	x4,58006 <_bsg_elf_stack_ptr+0x5700a>
  asm volatile("flw     %0,  676(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     a14:	696c                	flw	f11,84(x10)
     a16:	0062                	c.slli	x0,0x18
  asm volatile("flw     %0,  676(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     a18:	726f772f          	0x726f772f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     a1c:	6c672f6b          	0x6c672f6b
  asm volatile("flw     %0,  680(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     a20:	6c61626f          	jal	x4,170e6 <_bsg_elf_stack_ptr+0x160ea>
  asm volatile("flw     %0,  680(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     a24:	38636c2f          	0x38636c2f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     a28:	772f3337          	lui	x6,0x772f3
  asm volatile("flw     %0,  684(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     a2c:	2f6b726f          	jal	x4,b7d22 <_bsg_elf_stack_ptr+0xb6d26>
  asm volatile("flw     %0,  684(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     a30:	2f686473          	csrrsi	x8,0x2f6,16
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     a34:	6c70                	flw	f12,92(x8)
     a36:	7961                	lui	x18,0xffff8
  asm volatile("flw     %0,  688(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     a38:	756f7267          	0x756f7267
  asm volatile("flw     %0,  688(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     a3c:	646e                	flw	f8,216(x2)
     a3e:	6769622f          	0x6769622f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     a42:	6c62                	flw	f24,24(x2)
  asm volatile("flw     %0,  692(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     a44:	6461                	lui	x8,0x18
     a46:	2d65                	jal	10fe <_bsg_elf_stack_ptr+0x102>
  asm volatile("flw     %0,  692(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     a48:	6e65                	lui	x28,0x19
     a4a:	7265                	lui	x4,0xffff9
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     a4c:	622f7967          	0x622f7967
  asm volatile("flw     %0,  696(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     a50:	625f6773          	csrrsi	x14,0x625,30
  asm volatile("flw     %0,  696(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     a54:	616c                	flw	f11,68(x10)
     a56:	6564                	flw	f9,76(x10)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     a58:	7572                	flw	f10,60(x2)
     a5a:	6e6e                	flw	f28,216(x2)
  asm volatile("flw     %0,  700(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     a5c:	7265                	lui	x4,0xffff9
     a5e:	6773622f          	0x6773622f
  asm volatile("flw     %0,  700(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     a62:	6d5f 6e61 6379      	0x63796e616d5f
  asm volatile("flw     %0,  704(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     a68:	2f65726f          	jal	x4,57d5e <_bsg_elf_stack_ptr+0x56d62>
  asm volatile("flw     %0,  704(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     a6c:	74666f73          	csrrsi	x30,0x746,12
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     a70:	65726177          	0x65726177
  asm volatile("flw     %0,  708(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     a74:	7369722f          	0x7369722f
  asm volatile("flw     %0,  708(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     a78:	742d7663          	bgeu	x26,x2,11c4 <_bsg_elf_stack_ptr+0x1c8>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     a7c:	736c6f6f          	jal	x30,c71b2 <_bsg_elf_stack_ptr+0xc61b6>
  asm volatile("flw     %0,  712(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     a80:	69722f2f          	0x69722f2f
  asm volatile("flw     %0,  712(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     a84:	2d766373          	csrrsi	x6,0x2d7,12
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     a88:	6e69                	lui	x28,0x1a
     a8a:	6c617473          	csrrci	x8,0x6c6,2
  asm volatile("flw     %0,  716(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     a8e:	2f6c                	fld	f11,216(x14)
  asm volatile("flw     %0,  716(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     a90:	6972                	flw	f18,28(x2)
     a92:	33766373          	csrrsi	x6,mhpmevent23,12
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     a96:	2d32                	fld	f26,264(x2)
  asm volatile("flw     %0,  720(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     a98:	6e75                	lui	x28,0x1d
     a9a:	776f6e6b          	0x776f6e6b
  asm volatile("flw     %0,  720(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     a9e:	2d6e                	fld	f26,216(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     aa0:	6c65                	lui	x24,0x19
     aa2:	2d66                	fld	f26,88(x2)
  asm volatile("flw     %0,  724(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     aa4:	7264                	flw	f9,100(x12)
     aa6:	6d61                	lui	x26,0x18
  asm volatile("flw     %0,  724(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     aa8:	7366                	flw	f6,120(x2)
     aaa:	636e692f          	0x636e692f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     aae:	756c                	flw	f11,108(x10)
  asm volatile("flw     %0,  728(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     ab0:	6564                	flw	f9,76(x10)
     ab2:	63616d2f          	0x63616d2f
  asm volatile("flw     %0,  728(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     ab6:	6968                	flw	f10,84(x10)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     ab8:	656e                	flw	f10,216(x2)
     aba:	2f00                	fld	f8,24(x14)
  asm volatile("flw     %0,  732(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     abc:	6b726f77          	0x6b726f77
  asm volatile("flw     %0,  732(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     ac0:	6f6c672f          	0x6f6c672f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     ac4:	6162                	flw	f2,24(x2)
     ac6:	2f6c                	fld	f11,216(x14)
  asm volatile("flw     %0,  736(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     ac8:	636c                	flw	f11,68(x14)
     aca:	3738                	fld	f14,104(x14)
  asm volatile("flw     %0,  736(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     acc:	6f772f33          	0x6f772f33
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     ad0:	6b72                	flw	f22,28(x2)
     ad2:	6864732f          	0x6864732f
  asm volatile("flw     %0,  740(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     ad6:	616c702f          	0x616c702f
  asm volatile("flw     %0,  740(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     ada:	6779                	lui	x14,0x1e
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     adc:	6f72                	flw	f30,28(x2)
     ade:	6e75                	lui	x28,0x1d
  asm volatile("flw     %0,  744(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     ae0:	2f64                	fld	f9,216(x14)
     ae2:	6962                	flw	f18,24(x2)
  asm volatile("flw     %0,  744(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     ae4:	616c6267          	0x616c6267
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     ae8:	6564                	flw	f9,76(x10)
     aea:	652d                	lui	x10,0xb
  asm volatile("flw     %0,  748(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     aec:	656e                	flw	f10,216(x2)
     aee:	6772                	flw	f14,28(x2)
  asm volatile("flw     %0,  748(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     af0:	2f79                	jal	128e <_bsg_elf_stack_ptr+0x292>
     af2:	7362                	flw	f6,56(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     af4:	6c625f67          	0x6c625f67
  asm volatile("flw     %0,  752(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     af8:	6461                	lui	x8,0x18
     afa:	7265                	lui	x4,0xffff9
  asm volatile("flw     %0,  752(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     afc:	6e75                	lui	x28,0x1d
     afe:	656e                	flw	f10,216(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     b00:	2f72                	fld	f30,280(x2)
     b02:	7362                	flw	f6,56(x2)
  asm volatile("flw     %0,  756(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     b04:	616d5f67          	0x616d5f67
  asm volatile("flw     %0,  756(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     b08:	796e                	flw	f18,248(x2)
     b0a:	65726f63          	bltu	x4,x23,1168 <_bsg_elf_stack_ptr+0x16c>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     b0e:	666f732f          	0x666f732f
  asm volatile("flw     %0,  760(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     b12:	7774                	flw	f13,108(x14)
  asm volatile("flw     %0,  760(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     b14:	7261                	lui	x4,0xffff8
     b16:	2f65                	jal	12ce <_bsg_elf_stack_ptr+0x2d2>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     b18:	6972                	flw	f18,28(x2)
     b1a:	2d766373          	csrrsi	x6,0x2d7,12
  asm volatile("flw     %0,  764(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     b1e:	6f74                	flw	f13,92(x14)
  asm volatile("flw     %0,  764(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     b20:	2f736c6f          	jal	x24,37616 <_bsg_elf_stack_ptr+0x3661a>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     b24:	7369722f          	0x7369722f
  asm volatile("flw     %0,  768(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     b28:	692d7663          	bgeu	x26,x18,11b4 <_bsg_elf_stack_ptr+0x1b8>
  asm volatile("flw     %0,  768(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     b2c:	736e                	flw	f6,248(x2)
     b2e:	6174                	flw	f13,68(x10)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     b30:	6c6c                	flw	f11,92(x8)
     b32:	7369722f          	0x7369722f
  asm volatile("flw     %0,  772(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     b36:	32337663          	bgeu	x6,x3,e62 <_GLOBAL__sub_I_kernel.cpp+0x2a>
  asm volatile("flw     %0,  772(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     b3a:	752d                	lui	x10,0xfffeb
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     b3c:	6b6e                	flw	f22,216(x2)
     b3e:	6f6e                	flw	f30,216(x2)
  asm volatile("flw     %0,  776(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     b40:	652d6e77          	0x652d6e77
  asm volatile("flw     %0,  776(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     b44:	666c                	flw	f11,76(x12)
     b46:	642d                	lui	x8,0xb
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     b48:	6172                	flw	f2,28(x2)
     b4a:	666d                	lui	x12,0x1b
  asm volatile("flw     %0,  780(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     b4c:	6e692f73          	csrrs	x30,0x6e6,x18
  asm volatile("flw     %0,  780(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     b50:	64756c63          	bltu	x10,x7,11a8 <_bsg_elf_stack_ptr+0x1ac>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     b54:	2f65                	jal	130c <_bsg_elf_stack_ptr+0x310>
     b56:	00737973          	csrrci	x18,0x7,6
  asm volatile("flw     %0,  784(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     b5a:	726f772f          	0x726f772f
  asm volatile("flw     %0,  784(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     b5e:	6c672f6b          	0x6c672f6b
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     b62:	6c61626f          	jal	x4,17228 <_bsg_elf_stack_ptr+0x1622c>
  asm volatile("flw     %0,  788(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     b66:	38636c2f          	0x38636c2f
  asm volatile("flw     %0,  788(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     b6a:	772f3337          	lui	x6,0x772f3
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     b6e:	2f6b726f          	jal	x4,b7e64 <_bsg_elf_stack_ptr+0xb6e68>
  asm volatile("flw     %0,  792(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     b72:	2f686473          	csrrsi	x8,0x2f6,16
  asm volatile("flw     %0,  792(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     b76:	6c70                	flw	f12,92(x8)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     b78:	7961                	lui	x18,0xffff8
     b7a:	756f7267          	0x756f7267
  asm volatile("flw     %0,  796(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     b7e:	646e                	flw	f8,216(x2)
  asm volatile("flw     %0,  796(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     b80:	6769622f          	0x6769622f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     b84:	6c62                	flw	f24,24(x2)
     b86:	6461                	lui	x8,0x18
  asm volatile("flw     %0,  800(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     b88:	2d65                	jal	1240 <_bsg_elf_stack_ptr+0x244>
     b8a:	6e65                	lui	x28,0x19
  asm volatile("flw     %0,  800(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     b8c:	7265                	lui	x4,0xffff9
     b8e:	622f7967          	0x622f7967
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     b92:	625f6773          	csrrsi	x14,0x625,30
  asm volatile("flw     %0,  804(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     b96:	616c                	flw	f11,68(x10)
  asm volatile("flw     %0,  804(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     b98:	6564                	flw	f9,76(x10)
     b9a:	7572                	flw	f10,60(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     b9c:	6e6e                	flw	f28,216(x2)
     b9e:	7265                	lui	x4,0xffff9
  asm volatile("flw     %0,  808(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     ba0:	6773622f          	0x6773622f
  asm volatile("flw     %0,  808(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     ba4:	6d5f 6e61 6379      	0x63796e616d5f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     baa:	2f65726f          	jal	x4,57ea0 <_bsg_elf_stack_ptr+0x56ea4>
  asm volatile("flw     %0,  812(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     bae:	74666f73          	csrrsi	x30,0x746,12
  asm volatile("flw     %0,  812(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     bb2:	65726177          	0x65726177
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     bb6:	7369722f          	0x7369722f
  asm volatile("flw     %0,  816(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     bba:	742d7663          	bgeu	x26,x2,1306 <_bsg_elf_stack_ptr+0x30a>
  asm volatile("flw     %0,  816(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     bbe:	736c6f6f          	jal	x30,c72f4 <_bsg_elf_stack_ptr+0xc62f8>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     bc2:	69722f2f          	0x69722f2f
  asm volatile("flw     %0,  820(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     bc6:	2d766373          	csrrsi	x6,0x2d7,12
  asm volatile("flw     %0,  820(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     bca:	6e69                	lui	x28,0x1a
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     bcc:	6c617473          	csrrci	x8,0x6c6,2
  asm volatile("flw     %0,  824(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     bd0:	2f6c                	fld	f11,216(x14)
     bd2:	6972                	flw	f18,28(x2)
  asm volatile("flw     %0,  824(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     bd4:	33766373          	csrrsi	x6,mhpmevent23,12
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     bd8:	2d32                	fld	f26,264(x2)
     bda:	6e75                	lui	x28,0x1d
  asm volatile("flw     %0,  828(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     bdc:	776f6e6b          	0x776f6e6b
  asm volatile("flw     %0,  828(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     be0:	2d6e                	fld	f26,216(x2)
     be2:	6c65                	lui	x24,0x19
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     be4:	2d66                	fld	f26,88(x2)
     be6:	7264                	flw	f9,100(x12)
  asm volatile("flw     %0,  832(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     be8:	6d61                	lui	x26,0x18
     bea:	7366                	flw	f6,120(x2)
  asm volatile("flw     %0,  832(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     bec:	636e692f          	0x636e692f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     bf0:	756c                	flw	f11,108(x10)
     bf2:	6564                	flw	f9,76(x10)
  asm volatile("flw     %0,  836(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     bf4:	2b2b632f          	0x2b2b632f
  asm volatile("flw     %0,  836(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     bf8:	322e392f          	0x322e392f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     bfc:	302e                	fld	f0,232(x2)
     bfe:	2f00                	fld	f8,24(x14)
  asm volatile("flw     %0,  840(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     c00:	6b726f77          	0x6b726f77
  asm volatile("flw     %0,  840(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     c04:	6f6c672f          	0x6f6c672f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     c08:	6162                	flw	f2,24(x2)
     c0a:	2f6c                	fld	f11,216(x14)
  asm volatile("flw     %0,  844(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     c0c:	636c                	flw	f11,68(x14)
     c0e:	3738                	fld	f14,104(x14)
  asm volatile("flw     %0,  844(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     c10:	6f772f33          	0x6f772f33
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     c14:	6b72                	flw	f22,28(x2)
     c16:	6864732f          	0x6864732f
  asm volatile("flw     %0,  848(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     c1a:	616c702f          	0x616c702f
  asm volatile("flw     %0,  848(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     c1e:	6779                	lui	x14,0x1e
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     c20:	6f72                	flw	f30,28(x2)
     c22:	6e75                	lui	x28,0x1d
  asm volatile("flw     %0,  852(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     c24:	2f64                	fld	f9,216(x14)
     c26:	6962                	flw	f18,24(x2)
  asm volatile("flw     %0,  852(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     c28:	616c6267          	0x616c6267
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     c2c:	6564                	flw	f9,76(x10)
     c2e:	652d                	lui	x10,0xb
  asm volatile("flw     %0,  856(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     c30:	656e                	flw	f10,216(x2)
     c32:	6772                	flw	f14,28(x2)
  asm volatile("flw     %0,  856(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     c34:	2f79                	jal	13d2 <_bsg_elf_stack_ptr+0x3d6>
     c36:	7362                	flw	f6,56(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     c38:	6c625f67          	0x6c625f67
  asm volatile("flw     %0,  860(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     c3c:	6461                	lui	x8,0x18
     c3e:	7265                	lui	x4,0xffff9
  asm volatile("flw     %0,  860(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     c40:	6e75                	lui	x28,0x1d
     c42:	656e                	flw	f10,216(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     c44:	2f72                	fld	f30,280(x2)
     c46:	7362                	flw	f6,56(x2)
  asm volatile("flw     %0,  864(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     c48:	616d5f67          	0x616d5f67
  asm volatile("flw     %0,  864(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     c4c:	796e                	flw	f18,248(x2)
     c4e:	65726f63          	bltu	x4,x23,12ac <_bsg_elf_stack_ptr+0x2b0>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     c52:	666f732f          	0x666f732f
  asm volatile("flw     %0,  868(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     c56:	7774                	flw	f13,108(x14)
  asm volatile("flw     %0,  868(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     c58:	7261                	lui	x4,0xffff8
     c5a:	2f65                	jal	1412 <_bsg_elf_stack_ptr+0x416>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     c5c:	6972                	flw	f18,28(x2)
     c5e:	2d766373          	csrrsi	x6,0x2d7,12
  asm volatile("flw     %0,  872(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     c62:	6f74                	flw	f13,92(x14)
  asm volatile("flw     %0,  872(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     c64:	2f736c6f          	jal	x24,3775a <_bsg_elf_stack_ptr+0x3675e>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     c68:	7369722f          	0x7369722f
  asm volatile("flw     %0,  876(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     c6c:	692d7663          	bgeu	x26,x18,12f8 <_bsg_elf_stack_ptr+0x2fc>
  asm volatile("flw     %0,  876(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     c70:	736e                	flw	f6,248(x2)
     c72:	6174                	flw	f13,68(x10)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     c74:	6c6c                	flw	f11,92(x8)
     c76:	7369722f          	0x7369722f
  asm volatile("flw     %0,  880(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     c7a:	32337663          	bgeu	x6,x3,fa6 <__.text.dram_end+0x62>
  asm volatile("flw     %0,  880(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     c7e:	752d                	lui	x10,0xfffeb
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     c80:	6b6e                	flw	f22,216(x2)
     c82:	6f6e                	flw	f30,216(x2)
  asm volatile("flw     %0,  884(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     c84:	652d6e77          	0x652d6e77
  asm volatile("flw     %0,  884(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     c88:	666c                	flw	f11,76(x12)
     c8a:	642d                	lui	x8,0xb
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     c8c:	6172                	flw	f2,28(x2)
     c8e:	666d                	lui	x12,0x1b
  asm volatile("flw     %0,  888(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     c90:	6e692f73          	csrrs	x30,0x6e6,x18
  asm volatile("flw     %0,  888(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     c94:	64756c63          	bltu	x10,x7,12ec <_bsg_elf_stack_ptr+0x2f0>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     c98:	0065                	c.nop	25
     c9a:	6200                	flw	f8,0(x12)
  asm volatile("flw     %0,  892(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     c9c:	745f6773          	csrrsi	x14,0x745,30
  asm volatile("flw     %0,  892(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     ca0:	6c69                	lui	x24,0x1a
     ca2:	5f65                	li	x30,-7
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     ca4:	756f7267          	0x756f7267
  asm volatile("flw     %0,  896(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     ca8:	5f70                	lw	x12,124(x14)
     caa:	6162                	flw	f2,24(x2)
  asm volatile("flw     %0,  896(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     cac:	7272                	flw	f4,60(x2)
     cae:	6569                	lui	x10,0x1a
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     cb0:	2e72                	fld	f28,280(x2)
     cb2:	7068                	flw	f10,100(x8)
  asm volatile("flw     %0,  900(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     cb4:	0070                	addi	x12,x2,12
     cb6:	0001                	nop
  asm volatile("flw     %0,  900(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     cb8:	6b00                	flw	f8,16(x14)
     cba:	7265                	lui	x4,0xffff9
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     cbc:	656e                	flw	f10,216(x2)
     cbe:	2e6c                	fld	f11,216(x12)
  asm volatile("flw     %0,  904(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     cc0:	00707063          	bgeu	x0,x7,cc0 <_gp+0x4b8>
  asm volatile("flw     %0,  904(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     cc4:	0000                	unimp
     cc6:	5f00                	lw	x8,56(x14)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     cc8:	6564                	flw	f9,76(x10)
     cca:	6166                	flw	f2,88(x2)
  asm volatile("flw     %0,  908(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     ccc:	6c75                	lui	x24,0x1d
     cce:	5f74                	lw	x13,124(x14)
  asm volatile("flw     %0,  908(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     cd0:	7974                	flw	f13,116(x10)
     cd2:	6570                	flw	f12,76(x10)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     cd4:	00682e73          	csrrs	x28,0x6,x16
  asm volatile("flw     %0,  912(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     cd8:	0002                	c.slli64	x0
     cda:	5f00                	lw	x8,56(x14)
  asm volatile("flw     %0,  912(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     cdc:	69647473          	csrrci	x8,0x696,8
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     ce0:	746e                	flw	f8,248(x2)
     ce2:	682e                	flw	f16,200(x2)
  asm volatile("flw     %0,  916(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     ce4:	0300                	addi	x8,x2,384
     ce6:	0000                	unimp
  asm volatile("flw     %0,  916(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     ce8:	64747363          	bgeu	x8,x7,132e <_bsg_elf_stack_ptr+0x332>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     cec:	6e69                	lui	x28,0x1a
     cee:	0074                	addi	x13,x2,12
  asm volatile("flw     %0,  920(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     cf0:	0004                	0x4
     cf2:	7300                	flw	f8,32(x14)
  asm volatile("flw     %0,  920(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     cf4:	6474                	flw	f13,76(x8)
     cf6:	6e69                	lui	x28,0x1a
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     cf8:	2e74                	fld	f13,216(x12)
     cfa:	0068                	addi	x10,x2,12
  asm volatile("flw     %0,  924(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     cfc:	0005                	c.nop	1
     cfe:	0000                	unimp
  asm volatile("flw     %0,  924(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     d00:	0204                	addi	x9,x2,256
     d02:	0500                	addi	x8,x2,640
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     d04:	e002                	fsw	f0,0(x2)
     d06:	0001                	nop
  asm volatile("flw     %0,  928(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     d08:	0300                	addi	x8,x2,384
     d0a:	0109                	addi	x2,x2,2
  asm volatile("flw     %0,  928(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     d0c:	0505                	addi	x10,x10,1
     d0e:	030a                	slli	x6,x6,0x2
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     d10:	0909                	addi	x18,x18,2
     d12:	0014                	0x14
  asm volatile("flw     %0,  932(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     d14:	0301                	addi	x6,x6,0
     d16:	0901                	addi	x18,x18,0
  asm volatile("flw     %0,  932(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     d18:	0010                	0x10
     d1a:	0301                	addi	x6,x6,0
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     d1c:	0901                	addi	x18,x18,0
     d1e:	0004                	0x4
  asm volatile("flw     %0,  936(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     d20:	0301                	addi	x6,x6,0
     d22:	097e                	slli	x18,x18,0x1f
  asm volatile("flw     %0,  936(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     d24:	0004                	0x4
     d26:	0301                	addi	x6,x6,0
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     d28:	00040903          	lb	x18,0(x8) # b000 <_bsg_elf_stack_ptr+0xa004>
  asm volatile("flw     %0,  940(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     d2c:	0501                	addi	x10,x10,0
     d2e:	0319                	addi	x6,x6,6
  asm volatile("flw     %0,  940(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     d30:	097c                	addi	x15,x2,156
     d32:	0004                	0x4
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     d34:	0501                	addi	x10,x10,0
     d36:	00030603          	lb	x12,0(x6) # 772f3000 <_bsg_elf_dram_size+0x372f3000>
  asm volatile("flw     %0,  944(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     d3a:	0409                	addi	x8,x8,2
  asm volatile("flw     %0,  944(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     d3c:	0100                	addi	x8,x2,128
     d3e:	0306                	slli	x6,x6,0x1
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     d40:	090d                	addi	x18,x18,3
     d42:	0004                	0x4
  asm volatile("flw     %0,  948(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     d44:	0301                	addi	x6,x6,0
     d46:	0902                	c.slli64	x18
  asm volatile("flw     %0,  948(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     d48:	0004                	0x4
     d4a:	0301                	addi	x6,x6,0
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     d4c:	0901                	addi	x18,x18,0
     d4e:	0004                	0x4
  asm volatile("flw     %0,  952(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     d50:	0601                	addi	x12,x12,0
     d52:	04095e03          	lhu	x28,64(x18) # ffff8040 <_bsg_dram_end_addr+0x7eff8040>
  asm volatile("flw     %0,  952(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     d56:	0100                	addi	x8,x2,128
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     d58:	0306                	slli	x6,x6,0x1
     d5a:	00080923          	sb	x0,18(x16)
  asm volatile("flw     %0,  956(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     d5e:	0301                	addi	x6,x6,0
  asm volatile("flw     %0,  956(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     d60:	0902                	c.slli64	x18
     d62:	0004                	0x4
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     d64:	0301                	addi	x6,x6,0
     d66:	0901                	addi	x18,x18,0
  asm volatile("flw     %0,  960(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     d68:	0004                	0x4
     d6a:	0301                	addi	x6,x6,0
  asm volatile("flw     %0,  960(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     d6c:	0901                	addi	x18,x18,0
     d6e:	0004                	0x4
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     d70:	0301                	addi	x6,x6,0
     d72:	0902                	c.slli64	x18
  asm volatile("flw     %0,  964(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     d74:	0004                	0x4
     d76:	0301                	addi	x6,x6,0
  asm volatile("flw     %0,  964(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     d78:	0901                	addi	x18,x18,0
     d7a:	0004                	0x4
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     d7c:	0301                	addi	x6,x6,0
     d7e:	0901                	addi	x18,x18,0
  asm volatile("flw     %0,  968(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     d80:	0004                	0x4
     d82:	0301                	addi	x6,x6,0
  asm volatile("flw     %0,  968(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     d84:	0902                	c.slli64	x18
     d86:	0004                	0x4
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     d88:	0301                	addi	x6,x6,0
     d8a:	0901                	addi	x18,x18,0
  asm volatile("flw     %0,  972(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     d8c:	0004                	0x4
     d8e:	0301                	addi	x6,x6,0
  asm volatile("flw     %0,  972(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     d90:	0901                	addi	x18,x18,0
     d92:	0004                	0x4
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     d94:	0301                	addi	x6,x6,0
     d96:	0902                	c.slli64	x18
  asm volatile("flw     %0,  976(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     d98:	0004                	0x4
     d9a:	0301                	addi	x6,x6,0
  asm volatile("flw     %0,  976(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     d9c:	0901                	addi	x18,x18,0
     d9e:	0004                	0x4
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     da0:	0301                	addi	x6,x6,0
     da2:	0901                	addi	x18,x18,0
  asm volatile("flw     %0,  980(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     da4:	0004                	0x4
     da6:	0301                	addi	x6,x6,0
  asm volatile("flw     %0,  980(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     da8:	0902                	c.slli64	x18
     daa:	0004                	0x4
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     dac:	0301                	addi	x6,x6,0
     dae:	0901                	addi	x18,x18,0
  asm volatile("flw     %0,  984(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     db0:	0004                	0x4
     db2:	0301                	addi	x6,x6,0
  asm volatile("flw     %0,  984(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     db4:	0901                	addi	x18,x18,0
     db6:	0004                	0x4
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     db8:	0301                	addi	x6,x6,0
     dba:	0902                	c.slli64	x18
  asm volatile("flw     %0,  988(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     dbc:	0004                	0x4
     dbe:	0301                	addi	x6,x6,0
  asm volatile("flw     %0,  988(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     dc0:	0901                	addi	x18,x18,0
     dc2:	0004                	0x4
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     dc4:	0301                	addi	x6,x6,0
     dc6:	0901                	addi	x18,x18,0
  asm volatile("flw     %0,  992(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     dc8:	0004                	0x4
     dca:	0301                	addi	x6,x6,0
  asm volatile("flw     %0,  992(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     dcc:	0902                	c.slli64	x18
     dce:	0004                	0x4
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     dd0:	0301                	addi	x6,x6,0
     dd2:	0901                	addi	x18,x18,0
  asm volatile("flw     %0,  996(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     dd4:	0004                	0x4
     dd6:	0301                	addi	x6,x6,0
  asm volatile("flw     %0,  996(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     dd8:	0901                	addi	x18,x18,0
     dda:	0004                	0x4
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     ddc:	0301                	addi	x6,x6,0
     dde:	0902                	c.slli64	x18
  asm volatile("flw     %0, 1000(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     de0:	0004                	0x4
     de2:	0301                	addi	x6,x6,0
  asm volatile("flw     %0, 1000(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     de4:	0901                	addi	x18,x18,0
     de6:	0004                	0x4
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     de8:	0301                	addi	x6,x6,0
     dea:	0901                	addi	x18,x18,0
  asm volatile("flw     %0, 1004(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     dec:	0004                	0x4
     dee:	0301                	addi	x6,x6,0
  asm volatile("flw     %0, 1004(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     df0:	0902                	c.slli64	x18
     df2:	0004                	0x4
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     df4:	0301                	addi	x6,x6,0
     df6:	0901                	addi	x18,x18,0
  asm volatile("flw     %0, 1008(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     df8:	0004                	0x4
     dfa:	0301                	addi	x6,x6,0
  asm volatile("flw     %0, 1008(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     dfc:	0901                	addi	x18,x18,0
     dfe:	0004                	0x4
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     e00:	0301                	addi	x6,x6,0
     e02:	0902                	c.slli64	x18
  asm volatile("flw     %0, 1012(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     e04:	0004                	0x4
     e06:	0301                	addi	x6,x6,0
  asm volatile("flw     %0, 1012(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     e08:	0901                	addi	x18,x18,0
     e0a:	0004                	0x4
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     e0c:	0301                	addi	x6,x6,0
     e0e:	0901                	addi	x18,x18,0
  asm volatile("flw     %0, 1016(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
     e10:	0004                	0x4
     e12:	0301                	addi	x6,x6,0
  asm volatile("flw     %0, 1016(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
     e14:	0902                	c.slli64	x18
     e16:	0004                	0x4
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
     e18:	0301                	addi	x6,x6,0
     e1a:	0901                	addi	x18,x18,0
  bsg_saif_end();
     e1c:	0004                	0x4
     e1e:	0301                	addi	x6,x6,0
  C[0] = C_tmp;
     e20:	0901                	addi	x18,x18,0
     e22:	0004                	0x4
	return 0;
     e24:	0301                	addi	x6,x6,0
     e26:	0902                	c.slli64	x18
     e28:	0004                	0x4
     e2a:	0301                	addi	x6,x6,0
     e2c:	0901                	addi	x18,x18,0
     e2e:	0004                	0x4
     e30:	0301                	addi	x6,x6,0
     e32:	0901                	addi	x18,x18,0
     e34:	0004                	0x4
     e36:	0301                	addi	x6,x6,0
    volatile unsigned int  _local_alert = 0;
     e38:	0902                	c.slli64	x18
     e3a:	0004                	0x4
     e3c:	0301                	addi	x6,x6,0
     e3e:	0901                	addi	x18,x18,0
    volatile unsigned char _done_list[ BARRIER_X_DIM ] = {0};
     e40:	0004                	0x4
     e42:	0301                	addi	x6,x6,0
            this->_done_list[i] = 0;
     e44:	0901                	addi	x18,x18,0
     e46:	0004                	0x4
        _local_alert = 0;
     e48:	0301                	addi	x6,x6,0
     e4a:	0902                	c.slli64	x18
    volatile unsigned int  _local_alert = 0;
     e4c:	0004                	0x4
     e4e:	0301                	addi	x6,x6,0
    volatile unsigned char _done_list[ BARRIER_Y_DIM ] = {0};
     e50:	0901                	addi	x18,x18,0
     e52:	0004                	0x4
            this->_done_list[i] = 0;
     e54:	0301                	addi	x6,x6,0
     e56:	0901                	addi	x18,x18,0
        _local_alert = 0;
     e58:	0004                	0x4
     e5a:	0301                	addi	x6,x6,0
            this->_done_list[i] = 0;
     e5c:	0902                	c.slli64	x18
     e5e:	0004                	0x4
        _local_alert = 0;
     e60:	0301                	addi	x6,x6,0
     e62:	0901                	addi	x18,x18,0
            this->_done_list[i] = 0;
     e64:	0004                	0x4
     e66:	0301                	addi	x6,x6,0
        _local_alert = 0;
     e68:	0901                	addi	x18,x18,0
     e6a:	0004                	0x4
     e6c:	0301                	addi	x6,x6,0
     e6e:	0902                	c.slli64	x18
        __wait_until_valid_func();
     e70:	0004                	0x4
     e72:	0301                	addi	x6,x6,0
     e74:	0901                	addi	x18,x18,0
     e76:	0004                	0x4
     e78:	0301                	addi	x6,x6,0
     e7a:	0901                	addi	x18,x18,0
     e7c:	0004                	0x4
     e7e:	0301                	addi	x6,x6,0
     e80:	0902                	c.slli64	x18
     e82:	0004                	0x4
     e84:	0301                	addi	x6,x6,0
     e86:	0901                	addi	x18,x18,0
     e88:	0004                	0x4
     e8a:	0301                	addi	x6,x6,0
     e8c:	0901                	addi	x18,x18,0
     e8e:	0004                	0x4
     e90:	0301                	addi	x6,x6,0
     e92:	0902                	c.slli64	x18
     e94:	0004                	0x4
     e96:	0301                	addi	x6,x6,0
     e98:	0901                	addi	x18,x18,0
     e9a:	0004                	0x4
     e9c:	0301                	addi	x6,x6,0
     e9e:	0901                	addi	x18,x18,0
     ea0:	0004                	0x4
     ea2:	0301                	addi	x6,x6,0
     ea4:	0902                	c.slli64	x18
     ea6:	0004                	0x4
     ea8:	0301                	addi	x6,x6,0
     eaa:	0901                	addi	x18,x18,0
     eac:	0004                	0x4
     eae:	0301                	addi	x6,x6,0
     eb0:	0901                	addi	x18,x18,0
     eb2:	0004                	0x4
     eb4:	0301                	addi	x6,x6,0
     eb6:	0902                	c.slli64	x18
     eb8:	0004                	0x4
     eba:	0301                	addi	x6,x6,0
     ebc:	0901                	addi	x18,x18,0
     ebe:	0004                	0x4
     ec0:	0301                	addi	x6,x6,0
     ec2:	0901                	addi	x18,x18,0
     ec4:	0004                	0x4
     ec6:	0301                	addi	x6,x6,0
     ec8:	0902                	c.slli64	x18
     eca:	0004                	0x4
     ecc:	0301                	addi	x6,x6,0
     ece:	0901                	addi	x18,x18,0
     ed0:	0004                	0x4
     ed2:	0301                	addi	x6,x6,0
     ed4:	0901                	addi	x18,x18,0
     ed6:	0004                	0x4
     ed8:	0301                	addi	x6,x6,0
     eda:	0902                	c.slli64	x18
     edc:	0004                	0x4
     ede:	0301                	addi	x6,x6,0
     ee0:	0901                	addi	x18,x18,0
     ee2:	0004                	0x4
     ee4:	0301                	addi	x6,x6,0
     ee6:	0901                	addi	x18,x18,0
     ee8:	0004                	0x4
     eea:	0301                	addi	x6,x6,0
     eec:	0902                	c.slli64	x18
     eee:	0004                	0x4
     ef0:	0301                	addi	x6,x6,0
     ef2:	0901                	addi	x18,x18,0
     ef4:	0004                	0x4
     ef6:	0301                	addi	x6,x6,0
     ef8:	0901                	addi	x18,x18,0
     efa:	0004                	0x4
     efc:	0301                	addi	x6,x6,0
     efe:	0902                	c.slli64	x18
     f00:	0004                	0x4
     f02:	0301                	addi	x6,x6,0
     f04:	0901                	addi	x18,x18,0
     f06:	0004                	0x4
     f08:	0301                	addi	x6,x6,0
     f0a:	0901                	addi	x18,x18,0
     f0c:	0004                	0x4
     f0e:	0301                	addi	x6,x6,0
     f10:	0902                	c.slli64	x18
     f12:	0004                	0x4
     f14:	0301                	addi	x6,x6,0
     f16:	0901                	addi	x18,x18,0
     f18:	0004                	0x4
     f1a:	0301                	addi	x6,x6,0
     f1c:	0901                	addi	x18,x18,0
     f1e:	0004                	0x4
     f20:	0301                	addi	x6,x6,0
     f22:	0902                	c.slli64	x18
  if (__bsg_id == 0) 
     f24:	0004                	0x4
     f26:	0301                	addi	x6,x6,0
     f28:	0901                	addi	x18,x18,0
     f2a:	0004                	0x4
     *signal_ptr = cuda_finish_signal_val;     
     f2c:	0301                	addi	x6,x6,0
     f2e:	0901                	addi	x18,x18,0
     f30:	0004                	0x4
     f32:	0301                	addi	x6,x6,0
     f34:	0902                	c.slli64	x18
     f36:	0004                	0x4
     f38:	0301                	addi	x6,x6,0
     f3a:	0901                	addi	x18,x18,0
}
     f3c:	0004                	0x4
     f3e:	0301                	addi	x6,x6,0
     f40:	0901                	addi	x18,x18,0
     f42:	0004                	0x4
     f44:	0301                	addi	x6,x6,0
     f46:	0902                	c.slli64	x18
     f48:	0004                	0x4
     f4a:	0301                	addi	x6,x6,0
     f4c:	0901                	addi	x18,x18,0
     f4e:	0004                	0x4
     f50:	0301                	addi	x6,x6,0
     f52:	0901                	addi	x18,x18,0
     f54:	0004                	0x4
     f56:	0301                	addi	x6,x6,0
     f58:	0902                	c.slli64	x18
     f5a:	0004                	0x4
     f5c:	0301                	addi	x6,x6,0
     f5e:	0901                	addi	x18,x18,0
     f60:	0004                	0x4
     f62:	0301                	addi	x6,x6,0
     f64:	0901                	addi	x18,x18,0
     f66:	0004                	0x4
     f68:	0301                	addi	x6,x6,0
     f6a:	0902                	c.slli64	x18
     f6c:	0004                	0x4
     f6e:	0301                	addi	x6,x6,0
     f70:	0901                	addi	x18,x18,0
     f72:	0004                	0x4
     f74:	0301                	addi	x6,x6,0
     f76:	0901                	addi	x18,x18,0
     f78:	0004                	0x4
     f7a:	0301                	addi	x6,x6,0
     f7c:	0902                	c.slli64	x18
     f7e:	0004                	0x4
     f80:	0301                	addi	x6,x6,0
     f82:	0901                	addi	x18,x18,0
     f84:	0004                	0x4
     f86:	0301                	addi	x6,x6,0
     f88:	0901                	addi	x18,x18,0
     f8a:	0004                	0x4
     f8c:	0301                	addi	x6,x6,0
     f8e:	0902                	c.slli64	x18
     f90:	0004                	0x4
     f92:	0301                	addi	x6,x6,0
     f94:	0901                	addi	x18,x18,0
     f96:	0004                	0x4
     f98:	0301                	addi	x6,x6,0
     f9a:	0901                	addi	x18,x18,0
     f9c:	0004                	0x4
     f9e:	0301                	addi	x6,x6,0
     fa0:	0902                	c.slli64	x18
     fa2:	0004                	0x4
     fa4:	0301                	addi	x6,x6,0
     fa6:	0901                	addi	x18,x18,0
     fa8:	0004                	0x4
     faa:	0301                	addi	x6,x6,0
     fac:	0901                	addi	x18,x18,0
     fae:	0004                	0x4
     fb0:	0301                	addi	x6,x6,0
     fb2:	0902                	c.slli64	x18
     fb4:	0004                	0x4
     fb6:	0301                	addi	x6,x6,0
     fb8:	0901                	addi	x18,x18,0
     fba:	0004                	0x4
     fbc:	0301                	addi	x6,x6,0
     fbe:	0901                	addi	x18,x18,0
     fc0:	0004                	0x4
     fc2:	0301                	addi	x6,x6,0
     fc4:	0902                	c.slli64	x18
     fc6:	0004                	0x4
     fc8:	0301                	addi	x6,x6,0
     fca:	0901                	addi	x18,x18,0
     fcc:	0004                	0x4
     fce:	0301                	addi	x6,x6,0
     fd0:	0901                	addi	x18,x18,0
     fd2:	0004                	0x4
     fd4:	0301                	addi	x6,x6,0
     fd6:	0902                	c.slli64	x18
     fd8:	0004                	0x4
     fda:	0301                	addi	x6,x6,0
     fdc:	0901                	addi	x18,x18,0
     fde:	0004                	0x4
     fe0:	0301                	addi	x6,x6,0
     fe2:	0901                	addi	x18,x18,0
     fe4:	0004                	0x4
     fe6:	0301                	addi	x6,x6,0
     fe8:	0902                	c.slli64	x18
     fea:	0004                	0x4
     fec:	0301                	addi	x6,x6,0
     fee:	0901                	addi	x18,x18,0
     ff0:	0004                	0x4
     ff2:	0301                	addi	x6,x6,0
     ff4:	0901                	addi	x18,x18,0
     ff6:	0004                	0x4
     ff8:	0301                	addi	x6,x6,0
     ffa:	0902                	c.slli64	x18
     ffc:	0004                	0x4
     ffe:	0301                	addi	x6,x6,0
    1000:	0901                	addi	x18,x18,0
    1002:	0004                	0x4
    1004:	0301                	addi	x6,x6,0
    1006:	0901                	addi	x18,x18,0
    1008:	0004                	0x4
    100a:	0301                	addi	x6,x6,0
    100c:	0902                	c.slli64	x18
    100e:	0004                	0x4
    1010:	0301                	addi	x6,x6,0
    1012:	0901                	addi	x18,x18,0
    1014:	0004                	0x4
    1016:	0301                	addi	x6,x6,0
    1018:	0901                	addi	x18,x18,0
    101a:	0004                	0x4
    101c:	0301                	addi	x6,x6,0
    101e:	0902                	c.slli64	x18
    1020:	0004                	0x4
    1022:	0301                	addi	x6,x6,0
    1024:	0901                	addi	x18,x18,0
    1026:	0004                	0x4
    1028:	0301                	addi	x6,x6,0
    102a:	0901                	addi	x18,x18,0
    102c:	0004                	0x4
    102e:	0301                	addi	x6,x6,0
    1030:	0902                	c.slli64	x18
    1032:	0004                	0x4
    1034:	0301                	addi	x6,x6,0
    1036:	0901                	addi	x18,x18,0
    1038:	0004                	0x4
    103a:	0301                	addi	x6,x6,0
    103c:	0901                	addi	x18,x18,0
    103e:	0004                	0x4
    1040:	0301                	addi	x6,x6,0
    1042:	0902                	c.slli64	x18
    1044:	0004                	0x4
    1046:	0301                	addi	x6,x6,0
    1048:	0901                	addi	x18,x18,0
    104a:	0004                	0x4
    104c:	0301                	addi	x6,x6,0
    104e:	0901                	addi	x18,x18,0
    1050:	0004                	0x4
    1052:	0301                	addi	x6,x6,0
    1054:	0902                	c.slli64	x18
    1056:	0004                	0x4
    1058:	0301                	addi	x6,x6,0
    105a:	0901                	addi	x18,x18,0
    105c:	0004                	0x4
    105e:	0301                	addi	x6,x6,0
    1060:	0901                	addi	x18,x18,0
    1062:	0004                	0x4
    1064:	0301                	addi	x6,x6,0
    1066:	0902                	c.slli64	x18
    1068:	0004                	0x4
    106a:	0301                	addi	x6,x6,0
    106c:	0901                	addi	x18,x18,0
    106e:	0004                	0x4
    1070:	0301                	addi	x6,x6,0
    1072:	0901                	addi	x18,x18,0
    1074:	0004                	0x4
    1076:	0301                	addi	x6,x6,0
    1078:	0902                	c.slli64	x18
    107a:	0004                	0x4
    107c:	0301                	addi	x6,x6,0
    107e:	0901                	addi	x18,x18,0
    1080:	0004                	0x4
    1082:	0301                	addi	x6,x6,0
    1084:	0901                	addi	x18,x18,0
    1086:	0004                	0x4
    1088:	0301                	addi	x6,x6,0
    108a:	0902                	c.slli64	x18
    108c:	0004                	0x4
    108e:	0301                	addi	x6,x6,0
    1090:	0901                	addi	x18,x18,0
    1092:	0004                	0x4
    1094:	0301                	addi	x6,x6,0
    1096:	0901                	addi	x18,x18,0
    1098:	0004                	0x4
    109a:	0301                	addi	x6,x6,0
    109c:	0902                	c.slli64	x18
    109e:	0004                	0x4
    10a0:	0301                	addi	x6,x6,0
    10a2:	0901                	addi	x18,x18,0
    10a4:	0004                	0x4
    10a6:	0301                	addi	x6,x6,0
    10a8:	0901                	addi	x18,x18,0
    10aa:	0004                	0x4
    10ac:	0301                	addi	x6,x6,0
    10ae:	0902                	c.slli64	x18
    10b0:	0004                	0x4
    10b2:	0301                	addi	x6,x6,0
    10b4:	0901                	addi	x18,x18,0
    10b6:	0004                	0x4
    10b8:	0301                	addi	x6,x6,0
    10ba:	0901                	addi	x18,x18,0
    10bc:	0004                	0x4
    10be:	0301                	addi	x6,x6,0
    10c0:	0902                	c.slli64	x18
    10c2:	0004                	0x4
    10c4:	0301                	addi	x6,x6,0
    10c6:	0901                	addi	x18,x18,0
    10c8:	0004                	0x4
    10ca:	0301                	addi	x6,x6,0
    10cc:	0901                	addi	x18,x18,0
    10ce:	0004                	0x4
    10d0:	0301                	addi	x6,x6,0
    10d2:	0902                	c.slli64	x18
    10d4:	0004                	0x4
    10d6:	0301                	addi	x6,x6,0
    10d8:	0901                	addi	x18,x18,0
    10da:	0004                	0x4
    10dc:	0301                	addi	x6,x6,0
    10de:	0901                	addi	x18,x18,0
    10e0:	0004                	0x4
    10e2:	0301                	addi	x6,x6,0
    10e4:	0902                	c.slli64	x18
    10e6:	0004                	0x4
    10e8:	0301                	addi	x6,x6,0
    10ea:	0901                	addi	x18,x18,0
    10ec:	0004                	0x4
    10ee:	0301                	addi	x6,x6,0
    10f0:	0901                	addi	x18,x18,0
    10f2:	0004                	0x4
    10f4:	0301                	addi	x6,x6,0
    10f6:	0902                	c.slli64	x18
    10f8:	0004                	0x4
    10fa:	0301                	addi	x6,x6,0
    10fc:	0901                	addi	x18,x18,0
    10fe:	0004                	0x4
    1100:	0301                	addi	x6,x6,0
    1102:	0901                	addi	x18,x18,0
    1104:	0004                	0x4
    1106:	0301                	addi	x6,x6,0
    1108:	0902                	c.slli64	x18
    110a:	0004                	0x4
    110c:	0301                	addi	x6,x6,0
    110e:	0901                	addi	x18,x18,0
    1110:	0004                	0x4
    1112:	0301                	addi	x6,x6,0
    1114:	0901                	addi	x18,x18,0
    1116:	0004                	0x4
    1118:	0301                	addi	x6,x6,0
    111a:	0902                	c.slli64	x18
    111c:	0004                	0x4
    111e:	0301                	addi	x6,x6,0
    1120:	0901                	addi	x18,x18,0
    1122:	0004                	0x4
    1124:	0301                	addi	x6,x6,0
    1126:	0901                	addi	x18,x18,0
    1128:	0004                	0x4
    112a:	0301                	addi	x6,x6,0
    112c:	0902                	c.slli64	x18
    112e:	0004                	0x4
    1130:	0301                	addi	x6,x6,0
    1132:	0901                	addi	x18,x18,0
    1134:	0004                	0x4
    1136:	0301                	addi	x6,x6,0
    1138:	0901                	addi	x18,x18,0
    113a:	0004                	0x4
    113c:	0301                	addi	x6,x6,0
    113e:	0902                	c.slli64	x18
    1140:	0004                	0x4
    1142:	0301                	addi	x6,x6,0
    1144:	0901                	addi	x18,x18,0
    1146:	0004                	0x4
    1148:	0301                	addi	x6,x6,0
    114a:	0901                	addi	x18,x18,0
    114c:	0004                	0x4
    114e:	0301                	addi	x6,x6,0
    1150:	0902                	c.slli64	x18
    1152:	0004                	0x4
    1154:	0301                	addi	x6,x6,0
    1156:	0901                	addi	x18,x18,0
    1158:	0004                	0x4
    115a:	0301                	addi	x6,x6,0
    115c:	0901                	addi	x18,x18,0
    115e:	0004                	0x4
    1160:	0301                	addi	x6,x6,0
    1162:	0902                	c.slli64	x18
    1164:	0004                	0x4
    1166:	0301                	addi	x6,x6,0
    1168:	0901                	addi	x18,x18,0
    116a:	0004                	0x4
    116c:	0301                	addi	x6,x6,0
    116e:	0901                	addi	x18,x18,0
    1170:	0004                	0x4
    1172:	0301                	addi	x6,x6,0
    1174:	0902                	c.slli64	x18
    1176:	0004                	0x4
    1178:	0301                	addi	x6,x6,0
    117a:	0901                	addi	x18,x18,0
    117c:	0004                	0x4
    117e:	0301                	addi	x6,x6,0
    1180:	0901                	addi	x18,x18,0
    1182:	0004                	0x4
    1184:	0301                	addi	x6,x6,0
    1186:	0902                	c.slli64	x18
    1188:	0004                	0x4
    118a:	0301                	addi	x6,x6,0
    118c:	0901                	addi	x18,x18,0
    118e:	0004                	0x4
    1190:	0301                	addi	x6,x6,0
    1192:	0901                	addi	x18,x18,0
    1194:	0004                	0x4
    1196:	0301                	addi	x6,x6,0
    1198:	0902                	c.slli64	x18
    119a:	0004                	0x4
    119c:	0301                	addi	x6,x6,0
    119e:	0901                	addi	x18,x18,0
    11a0:	0004                	0x4
    11a2:	0301                	addi	x6,x6,0
    11a4:	0901                	addi	x18,x18,0
    11a6:	0004                	0x4
    11a8:	0301                	addi	x6,x6,0
    11aa:	0902                	c.slli64	x18
    11ac:	0004                	0x4
    11ae:	0301                	addi	x6,x6,0
    11b0:	0901                	addi	x18,x18,0
    11b2:	0004                	0x4
    11b4:	0301                	addi	x6,x6,0
    11b6:	0901                	addi	x18,x18,0
    11b8:	0004                	0x4
    11ba:	0301                	addi	x6,x6,0
    11bc:	0902                	c.slli64	x18
    11be:	0004                	0x4
    11c0:	0301                	addi	x6,x6,0
    11c2:	0901                	addi	x18,x18,0
    11c4:	0004                	0x4
    11c6:	0301                	addi	x6,x6,0
    11c8:	0901                	addi	x18,x18,0
    11ca:	0004                	0x4
    11cc:	0301                	addi	x6,x6,0
    11ce:	0902                	c.slli64	x18
    11d0:	0004                	0x4
    11d2:	0301                	addi	x6,x6,0
    11d4:	0901                	addi	x18,x18,0
    11d6:	0004                	0x4
    11d8:	0301                	addi	x6,x6,0
    11da:	0901                	addi	x18,x18,0
    11dc:	0004                	0x4
    11de:	0301                	addi	x6,x6,0
    11e0:	0902                	c.slli64	x18
    11e2:	0004                	0x4
    11e4:	0301                	addi	x6,x6,0
    11e6:	0901                	addi	x18,x18,0
    11e8:	0004                	0x4
    11ea:	0301                	addi	x6,x6,0
    11ec:	0901                	addi	x18,x18,0
    11ee:	0004                	0x4
    11f0:	0301                	addi	x6,x6,0
    11f2:	0902                	c.slli64	x18
    11f4:	0004                	0x4
    11f6:	0301                	addi	x6,x6,0
    11f8:	0901                	addi	x18,x18,0
    11fa:	0004                	0x4
    11fc:	0301                	addi	x6,x6,0
    11fe:	0901                	addi	x18,x18,0
    1200:	0004                	0x4
    1202:	0301                	addi	x6,x6,0
    1204:	0902                	c.slli64	x18
    1206:	0004                	0x4
    1208:	0301                	addi	x6,x6,0
    120a:	0901                	addi	x18,x18,0
    120c:	0004                	0x4
    120e:	0301                	addi	x6,x6,0
    1210:	0901                	addi	x18,x18,0
    1212:	0004                	0x4
    1214:	0301                	addi	x6,x6,0
    1216:	0902                	c.slli64	x18
    1218:	0004                	0x4
    121a:	0301                	addi	x6,x6,0
    121c:	0901                	addi	x18,x18,0
    121e:	0004                	0x4
    1220:	0301                	addi	x6,x6,0
    1222:	0901                	addi	x18,x18,0
    1224:	0004                	0x4
    1226:	0301                	addi	x6,x6,0
    1228:	0902                	c.slli64	x18
    122a:	0004                	0x4
    122c:	0301                	addi	x6,x6,0
    122e:	0901                	addi	x18,x18,0
    1230:	0004                	0x4
    1232:	0301                	addi	x6,x6,0
    1234:	0901                	addi	x18,x18,0
    1236:	0004                	0x4
    1238:	0301                	addi	x6,x6,0
    123a:	0902                	c.slli64	x18
    123c:	0004                	0x4
    123e:	0301                	addi	x6,x6,0
    1240:	0901                	addi	x18,x18,0
    1242:	0004                	0x4
    1244:	0301                	addi	x6,x6,0
    1246:	0901                	addi	x18,x18,0
    1248:	0004                	0x4
    124a:	0301                	addi	x6,x6,0
    124c:	0902                	c.slli64	x18
    124e:	0004                	0x4
    1250:	0301                	addi	x6,x6,0
    1252:	0901                	addi	x18,x18,0
    1254:	0004                	0x4
    1256:	0301                	addi	x6,x6,0
    1258:	0901                	addi	x18,x18,0
    125a:	0004                	0x4
    125c:	0301                	addi	x6,x6,0
    125e:	0902                	c.slli64	x18
    1260:	0004                	0x4
    1262:	0301                	addi	x6,x6,0
    1264:	0901                	addi	x18,x18,0
    1266:	0004                	0x4
    1268:	0301                	addi	x6,x6,0
    126a:	0901                	addi	x18,x18,0
    126c:	0004                	0x4
    126e:	0301                	addi	x6,x6,0
    1270:	0902                	c.slli64	x18
    1272:	0004                	0x4
    1274:	0301                	addi	x6,x6,0
    1276:	0901                	addi	x18,x18,0
    1278:	0004                	0x4
    127a:	0301                	addi	x6,x6,0
    127c:	0901                	addi	x18,x18,0
    127e:	0004                	0x4
    1280:	0301                	addi	x6,x6,0
    1282:	0902                	c.slli64	x18
    1284:	0004                	0x4
    1286:	0301                	addi	x6,x6,0
    1288:	0901                	addi	x18,x18,0
    128a:	0004                	0x4
    128c:	0301                	addi	x6,x6,0
    128e:	0901                	addi	x18,x18,0
    1290:	0004                	0x4
    1292:	0301                	addi	x6,x6,0
    1294:	0902                	c.slli64	x18
    1296:	0004                	0x4
    1298:	0301                	addi	x6,x6,0
    129a:	0901                	addi	x18,x18,0
    129c:	0004                	0x4
    129e:	0301                	addi	x6,x6,0
    12a0:	0901                	addi	x18,x18,0
    12a2:	0004                	0x4
    12a4:	0301                	addi	x6,x6,0
    12a6:	0902                	c.slli64	x18
    12a8:	0004                	0x4
    12aa:	0301                	addi	x6,x6,0
    12ac:	0901                	addi	x18,x18,0
    12ae:	0004                	0x4
    12b0:	0301                	addi	x6,x6,0
    12b2:	0901                	addi	x18,x18,0
    12b4:	0004                	0x4
    12b6:	0301                	addi	x6,x6,0
    12b8:	0902                	c.slli64	x18
    12ba:	0004                	0x4
    12bc:	0301                	addi	x6,x6,0
    12be:	0901                	addi	x18,x18,0
    12c0:	0004                	0x4
    12c2:	0301                	addi	x6,x6,0
    12c4:	0901                	addi	x18,x18,0
    12c6:	0004                	0x4
    12c8:	0301                	addi	x6,x6,0
    12ca:	0902                	c.slli64	x18
    12cc:	0004                	0x4
    12ce:	0301                	addi	x6,x6,0
    12d0:	0901                	addi	x18,x18,0
    12d2:	0004                	0x4
    12d4:	0301                	addi	x6,x6,0
    12d6:	0901                	addi	x18,x18,0
    12d8:	0004                	0x4
    12da:	0301                	addi	x6,x6,0
    12dc:	0902                	c.slli64	x18
    12de:	0004                	0x4
    12e0:	0301                	addi	x6,x6,0
    12e2:	0901                	addi	x18,x18,0
    12e4:	0004                	0x4
    12e6:	0301                	addi	x6,x6,0
    12e8:	0901                	addi	x18,x18,0
    12ea:	0004                	0x4
    12ec:	0301                	addi	x6,x6,0
    12ee:	0902                	c.slli64	x18
    12f0:	0004                	0x4
    12f2:	0301                	addi	x6,x6,0
    12f4:	0901                	addi	x18,x18,0
    12f6:	0004                	0x4
    12f8:	0301                	addi	x6,x6,0
    12fa:	0901                	addi	x18,x18,0
    12fc:	0004                	0x4
    12fe:	0301                	addi	x6,x6,0
    1300:	0902                	c.slli64	x18
    1302:	0004                	0x4
    1304:	0301                	addi	x6,x6,0
    1306:	0901                	addi	x18,x18,0
    1308:	0004                	0x4
    130a:	0301                	addi	x6,x6,0
    130c:	0901                	addi	x18,x18,0
    130e:	0004                	0x4
    1310:	0301                	addi	x6,x6,0
    1312:	0902                	c.slli64	x18
    1314:	0004                	0x4
    1316:	0301                	addi	x6,x6,0
    1318:	0901                	addi	x18,x18,0
    131a:	0004                	0x4
    131c:	0301                	addi	x6,x6,0
    131e:	0901                	addi	x18,x18,0
    1320:	0004                	0x4
    1322:	0301                	addi	x6,x6,0
    1324:	0902                	c.slli64	x18
    1326:	0004                	0x4
    1328:	0301                	addi	x6,x6,0
    132a:	0901                	addi	x18,x18,0
    132c:	0004                	0x4
    132e:	0301                	addi	x6,x6,0
    1330:	0901                	addi	x18,x18,0
    1332:	0004                	0x4
    1334:	0301                	addi	x6,x6,0
    1336:	0902                	c.slli64	x18
    1338:	0004                	0x4
    133a:	0301                	addi	x6,x6,0
    133c:	0901                	addi	x18,x18,0
    133e:	0004                	0x4
    1340:	0301                	addi	x6,x6,0
    1342:	0901                	addi	x18,x18,0
    1344:	0004                	0x4
    1346:	0301                	addi	x6,x6,0
    1348:	0902                	c.slli64	x18
    134a:	0004                	0x4
    134c:	0301                	addi	x6,x6,0
    134e:	0901                	addi	x18,x18,0
    1350:	0004                	0x4
    1352:	0301                	addi	x6,x6,0
    1354:	0901                	addi	x18,x18,0
    1356:	0004                	0x4
    1358:	0301                	addi	x6,x6,0
    135a:	0902                	c.slli64	x18
    135c:	0004                	0x4
    135e:	0301                	addi	x6,x6,0
    1360:	0901                	addi	x18,x18,0
    1362:	0004                	0x4
    1364:	0301                	addi	x6,x6,0
    1366:	0901                	addi	x18,x18,0
    1368:	0004                	0x4
    136a:	0301                	addi	x6,x6,0
    136c:	0902                	c.slli64	x18
    136e:	0004                	0x4
    1370:	0301                	addi	x6,x6,0
    1372:	0901                	addi	x18,x18,0
    1374:	0004                	0x4
    1376:	0301                	addi	x6,x6,0
    1378:	0901                	addi	x18,x18,0
    137a:	0004                	0x4
    137c:	0301                	addi	x6,x6,0
    137e:	0902                	c.slli64	x18
    1380:	0004                	0x4
    1382:	0301                	addi	x6,x6,0
    1384:	0901                	addi	x18,x18,0
    1386:	0004                	0x4
    1388:	0301                	addi	x6,x6,0
    138a:	0901                	addi	x18,x18,0
    138c:	0004                	0x4
    138e:	0301                	addi	x6,x6,0
    1390:	0902                	c.slli64	x18
    1392:	0004                	0x4
    1394:	0301                	addi	x6,x6,0
    1396:	0901                	addi	x18,x18,0
    1398:	0004                	0x4
    139a:	0301                	addi	x6,x6,0
    139c:	0901                	addi	x18,x18,0
    139e:	0004                	0x4
    13a0:	0301                	addi	x6,x6,0
    13a2:	0902                	c.slli64	x18
    13a4:	0004                	0x4
    13a6:	0301                	addi	x6,x6,0
    13a8:	0901                	addi	x18,x18,0
    13aa:	0004                	0x4
    13ac:	0301                	addi	x6,x6,0
    13ae:	0901                	addi	x18,x18,0
    13b0:	0004                	0x4
    13b2:	0301                	addi	x6,x6,0
    13b4:	0902                	c.slli64	x18
    13b6:	0004                	0x4
    13b8:	0301                	addi	x6,x6,0
    13ba:	0901                	addi	x18,x18,0
    13bc:	0004                	0x4
    13be:	0301                	addi	x6,x6,0
    13c0:	0901                	addi	x18,x18,0
    13c2:	0004                	0x4
    13c4:	0301                	addi	x6,x6,0
    13c6:	0902                	c.slli64	x18
    13c8:	0004                	0x4
    13ca:	0301                	addi	x6,x6,0
    13cc:	0901                	addi	x18,x18,0
    13ce:	0004                	0x4
    13d0:	0301                	addi	x6,x6,0
    13d2:	0901                	addi	x18,x18,0
    13d4:	0004                	0x4
    13d6:	0301                	addi	x6,x6,0
    13d8:	0902                	c.slli64	x18
    13da:	0004                	0x4
    13dc:	0301                	addi	x6,x6,0
    13de:	0901                	addi	x18,x18,0
    13e0:	0004                	0x4
    13e2:	0301                	addi	x6,x6,0
    13e4:	0901                	addi	x18,x18,0
    13e6:	0004                	0x4
    13e8:	0301                	addi	x6,x6,0
    13ea:	0902                	c.slli64	x18
    13ec:	0004                	0x4
    13ee:	0301                	addi	x6,x6,0
    13f0:	0901                	addi	x18,x18,0
    13f2:	0004                	0x4
    13f4:	0301                	addi	x6,x6,0
    13f6:	0901                	addi	x18,x18,0
    13f8:	0004                	0x4
    13fa:	0301                	addi	x6,x6,0
    13fc:	0902                	c.slli64	x18
    13fe:	0004                	0x4
    1400:	0301                	addi	x6,x6,0
    1402:	0901                	addi	x18,x18,0
    1404:	0004                	0x4
    1406:	0301                	addi	x6,x6,0
    1408:	0901                	addi	x18,x18,0
    140a:	0004                	0x4
    140c:	0301                	addi	x6,x6,0
    140e:	0902                	c.slli64	x18
    1410:	0004                	0x4
    1412:	0301                	addi	x6,x6,0
    1414:	0901                	addi	x18,x18,0
    1416:	0004                	0x4
    1418:	0301                	addi	x6,x6,0
    141a:	0901                	addi	x18,x18,0
    141c:	0004                	0x4
    141e:	0301                	addi	x6,x6,0
    1420:	0902                	c.slli64	x18
    1422:	0004                	0x4
    1424:	0301                	addi	x6,x6,0
    1426:	0901                	addi	x18,x18,0
    1428:	0004                	0x4
    142a:	0301                	addi	x6,x6,0
    142c:	0901                	addi	x18,x18,0
    142e:	0004                	0x4
    1430:	0301                	addi	x6,x6,0
    1432:	0902                	c.slli64	x18
    1434:	0004                	0x4
    1436:	0301                	addi	x6,x6,0
    1438:	0901                	addi	x18,x18,0
    143a:	0004                	0x4
    143c:	0301                	addi	x6,x6,0
    143e:	0901                	addi	x18,x18,0
    1440:	0004                	0x4
    1442:	0301                	addi	x6,x6,0
    1444:	0902                	c.slli64	x18
    1446:	0004                	0x4
    1448:	0301                	addi	x6,x6,0
    144a:	0901                	addi	x18,x18,0
    144c:	0004                	0x4
    144e:	0301                	addi	x6,x6,0
    1450:	0901                	addi	x18,x18,0
    1452:	0004                	0x4
    1454:	0301                	addi	x6,x6,0
    1456:	0902                	c.slli64	x18
    1458:	0004                	0x4
    145a:	0301                	addi	x6,x6,0
    145c:	0901                	addi	x18,x18,0
    145e:	0004                	0x4
    1460:	0301                	addi	x6,x6,0
    1462:	0901                	addi	x18,x18,0
    1464:	0004                	0x4
    1466:	0301                	addi	x6,x6,0
    1468:	0902                	c.slli64	x18
    146a:	0004                	0x4
    146c:	0301                	addi	x6,x6,0
    146e:	0901                	addi	x18,x18,0
    1470:	0004                	0x4
    1472:	0301                	addi	x6,x6,0
    1474:	0901                	addi	x18,x18,0
    1476:	0004                	0x4
    1478:	0301                	addi	x6,x6,0
    147a:	0902                	c.slli64	x18
    147c:	0004                	0x4
    147e:	0301                	addi	x6,x6,0
    1480:	0901                	addi	x18,x18,0
    1482:	0004                	0x4
    1484:	0301                	addi	x6,x6,0
    1486:	0901                	addi	x18,x18,0
    1488:	0004                	0x4
    148a:	0301                	addi	x6,x6,0
    148c:	0902                	c.slli64	x18
    148e:	0004                	0x4
    1490:	0301                	addi	x6,x6,0
    1492:	0901                	addi	x18,x18,0
    1494:	0004                	0x4
    1496:	0301                	addi	x6,x6,0
    1498:	0901                	addi	x18,x18,0
    149a:	0004                	0x4
    149c:	0301                	addi	x6,x6,0
    149e:	0902                	c.slli64	x18
    14a0:	0004                	0x4
    14a2:	0301                	addi	x6,x6,0
    14a4:	0901                	addi	x18,x18,0
    14a6:	0004                	0x4
    14a8:	0301                	addi	x6,x6,0
    14aa:	0901                	addi	x18,x18,0
    14ac:	0004                	0x4
    14ae:	0301                	addi	x6,x6,0
    14b0:	0902                	c.slli64	x18
    14b2:	0004                	0x4
    14b4:	0301                	addi	x6,x6,0
    14b6:	0901                	addi	x18,x18,0
    14b8:	0004                	0x4
    14ba:	0301                	addi	x6,x6,0
    14bc:	0901                	addi	x18,x18,0
    14be:	0004                	0x4
    14c0:	0301                	addi	x6,x6,0
    14c2:	0902                	c.slli64	x18
    14c4:	0004                	0x4
    14c6:	0301                	addi	x6,x6,0
    14c8:	0901                	addi	x18,x18,0
    14ca:	0004                	0x4
    14cc:	0301                	addi	x6,x6,0
    14ce:	0901                	addi	x18,x18,0
    14d0:	0004                	0x4
    14d2:	0301                	addi	x6,x6,0
    14d4:	0902                	c.slli64	x18
    14d6:	0004                	0x4
    14d8:	0301                	addi	x6,x6,0
    14da:	0901                	addi	x18,x18,0
    14dc:	0004                	0x4
    14de:	0301                	addi	x6,x6,0
    14e0:	0901                	addi	x18,x18,0
    14e2:	0004                	0x4
    14e4:	0301                	addi	x6,x6,0
    14e6:	0902                	c.slli64	x18
    14e8:	0004                	0x4
    14ea:	0301                	addi	x6,x6,0
    14ec:	0901                	addi	x18,x18,0
    14ee:	0004                	0x4
    14f0:	0301                	addi	x6,x6,0
    14f2:	0901                	addi	x18,x18,0
    14f4:	0004                	0x4
    14f6:	0301                	addi	x6,x6,0
    14f8:	0902                	c.slli64	x18
    14fa:	0004                	0x4
    14fc:	0301                	addi	x6,x6,0
    14fe:	0901                	addi	x18,x18,0
    1500:	0004                	0x4
    1502:	0301                	addi	x6,x6,0
    1504:	0901                	addi	x18,x18,0
    1506:	0004                	0x4
    1508:	0301                	addi	x6,x6,0
    150a:	0902                	c.slli64	x18
    150c:	0004                	0x4
    150e:	0301                	addi	x6,x6,0
    1510:	0901                	addi	x18,x18,0
    1512:	0004                	0x4
    1514:	0301                	addi	x6,x6,0
    1516:	0901                	addi	x18,x18,0
    1518:	0004                	0x4
    151a:	0301                	addi	x6,x6,0
    151c:	0902                	c.slli64	x18
    151e:	0004                	0x4
    1520:	0301                	addi	x6,x6,0
    1522:	0901                	addi	x18,x18,0
    1524:	0004                	0x4
    1526:	0301                	addi	x6,x6,0
    1528:	0901                	addi	x18,x18,0
    152a:	0004                	0x4
    152c:	0301                	addi	x6,x6,0
    152e:	0902                	c.slli64	x18
    1530:	0004                	0x4
    1532:	0301                	addi	x6,x6,0
    1534:	0901                	addi	x18,x18,0
    1536:	0004                	0x4
    1538:	0301                	addi	x6,x6,0
    153a:	0901                	addi	x18,x18,0
    153c:	0004                	0x4
    153e:	0301                	addi	x6,x6,0
    1540:	0902                	c.slli64	x18
    1542:	0004                	0x4
    1544:	0301                	addi	x6,x6,0
    1546:	0901                	addi	x18,x18,0
    1548:	0004                	0x4
    154a:	0301                	addi	x6,x6,0
    154c:	0901                	addi	x18,x18,0
    154e:	0004                	0x4
    1550:	0301                	addi	x6,x6,0
    1552:	0902                	c.slli64	x18
    1554:	0004                	0x4
    1556:	0301                	addi	x6,x6,0
    1558:	0901                	addi	x18,x18,0
    155a:	0004                	0x4
    155c:	0301                	addi	x6,x6,0
    155e:	0901                	addi	x18,x18,0
    1560:	0004                	0x4
    1562:	0301                	addi	x6,x6,0
    1564:	0902                	c.slli64	x18
    1566:	0004                	0x4
    1568:	0301                	addi	x6,x6,0
    156a:	0901                	addi	x18,x18,0
    156c:	0004                	0x4
    156e:	0301                	addi	x6,x6,0
    1570:	0901                	addi	x18,x18,0
    1572:	0004                	0x4
    1574:	0301                	addi	x6,x6,0
    1576:	0902                	c.slli64	x18
    1578:	0004                	0x4
    157a:	0301                	addi	x6,x6,0
    157c:	0901                	addi	x18,x18,0
    157e:	0004                	0x4
    1580:	0301                	addi	x6,x6,0
    1582:	0901                	addi	x18,x18,0
    1584:	0004                	0x4
    1586:	0301                	addi	x6,x6,0
    1588:	0902                	c.slli64	x18
    158a:	0004                	0x4
    158c:	0301                	addi	x6,x6,0
    158e:	0901                	addi	x18,x18,0
    1590:	0004                	0x4
    1592:	0301                	addi	x6,x6,0
    1594:	0901                	addi	x18,x18,0
    1596:	0004                	0x4
    1598:	0301                	addi	x6,x6,0
    159a:	0902                	c.slli64	x18
    159c:	0004                	0x4
    159e:	0301                	addi	x6,x6,0
    15a0:	0901                	addi	x18,x18,0
    15a2:	0004                	0x4
    15a4:	0301                	addi	x6,x6,0
    15a6:	0901                	addi	x18,x18,0
    15a8:	0004                	0x4
    15aa:	0301                	addi	x6,x6,0
    15ac:	0902                	c.slli64	x18
    15ae:	0004                	0x4
    15b0:	0301                	addi	x6,x6,0
    15b2:	0901                	addi	x18,x18,0
    15b4:	0004                	0x4
    15b6:	0301                	addi	x6,x6,0
    15b8:	0901                	addi	x18,x18,0
    15ba:	0004                	0x4
    15bc:	0301                	addi	x6,x6,0
    15be:	0902                	c.slli64	x18
    15c0:	0004                	0x4
    15c2:	0301                	addi	x6,x6,0
    15c4:	0901                	addi	x18,x18,0
    15c6:	0004                	0x4
    15c8:	0301                	addi	x6,x6,0
    15ca:	0901                	addi	x18,x18,0
    15cc:	0004                	0x4
    15ce:	0301                	addi	x6,x6,0
    15d0:	0902                	c.slli64	x18
    15d2:	0004                	0x4
    15d4:	0301                	addi	x6,x6,0
    15d6:	0901                	addi	x18,x18,0
    15d8:	0004                	0x4
    15da:	0301                	addi	x6,x6,0
    15dc:	0901                	addi	x18,x18,0
    15de:	0004                	0x4
    15e0:	0301                	addi	x6,x6,0
    15e2:	0902                	c.slli64	x18
    15e4:	0004                	0x4
    15e6:	0301                	addi	x6,x6,0
    15e8:	0901                	addi	x18,x18,0
    15ea:	0004                	0x4
    15ec:	0301                	addi	x6,x6,0
    15ee:	0901                	addi	x18,x18,0
    15f0:	0004                	0x4
    15f2:	0301                	addi	x6,x6,0
    15f4:	0902                	c.slli64	x18
    15f6:	0004                	0x4
    15f8:	0301                	addi	x6,x6,0
    15fa:	0901                	addi	x18,x18,0
    15fc:	0004                	0x4
    15fe:	0301                	addi	x6,x6,0
    1600:	0901                	addi	x18,x18,0
    1602:	0004                	0x4
    1604:	0301                	addi	x6,x6,0
    1606:	0902                	c.slli64	x18
    1608:	0004                	0x4
    160a:	0301                	addi	x6,x6,0
    160c:	0901                	addi	x18,x18,0
    160e:	0004                	0x4
    1610:	0301                	addi	x6,x6,0
    1612:	0901                	addi	x18,x18,0
    1614:	0004                	0x4
    1616:	0301                	addi	x6,x6,0
    1618:	0902                	c.slli64	x18
    161a:	0004                	0x4
    161c:	0301                	addi	x6,x6,0
    161e:	0901                	addi	x18,x18,0
    1620:	0004                	0x4
    1622:	0301                	addi	x6,x6,0
    1624:	0901                	addi	x18,x18,0
    1626:	0004                	0x4
    1628:	0301                	addi	x6,x6,0
    162a:	0902                	c.slli64	x18
    162c:	0004                	0x4
    162e:	0301                	addi	x6,x6,0
    1630:	0901                	addi	x18,x18,0
    1632:	0004                	0x4
    1634:	0301                	addi	x6,x6,0
    1636:	0901                	addi	x18,x18,0
    1638:	0004                	0x4
    163a:	0301                	addi	x6,x6,0
    163c:	0902                	c.slli64	x18
    163e:	0004                	0x4
    1640:	0301                	addi	x6,x6,0
    1642:	0901                	addi	x18,x18,0
    1644:	0004                	0x4
    1646:	0301                	addi	x6,x6,0
    1648:	0901                	addi	x18,x18,0
    164a:	0004                	0x4
    164c:	0301                	addi	x6,x6,0
    164e:	0902                	c.slli64	x18
    1650:	0004                	0x4
    1652:	0301                	addi	x6,x6,0
    1654:	0901                	addi	x18,x18,0
    1656:	0004                	0x4
    1658:	0301                	addi	x6,x6,0
    165a:	0901                	addi	x18,x18,0
    165c:	0004                	0x4
    165e:	0301                	addi	x6,x6,0
    1660:	0902                	c.slli64	x18
    1662:	0004                	0x4
    1664:	0301                	addi	x6,x6,0
    1666:	0901                	addi	x18,x18,0
    1668:	0004                	0x4
    166a:	0301                	addi	x6,x6,0
    166c:	0901                	addi	x18,x18,0
    166e:	0004                	0x4
    1670:	0301                	addi	x6,x6,0
    1672:	0902                	c.slli64	x18
    1674:	0004                	0x4
    1676:	0301                	addi	x6,x6,0
    1678:	0901                	addi	x18,x18,0
    167a:	0004                	0x4
    167c:	0301                	addi	x6,x6,0
    167e:	0901                	addi	x18,x18,0
    1680:	0004                	0x4
    1682:	0301                	addi	x6,x6,0
    1684:	0902                	c.slli64	x18
    1686:	0004                	0x4
    1688:	0301                	addi	x6,x6,0
    168a:	0901                	addi	x18,x18,0
    168c:	0004                	0x4
    168e:	0301                	addi	x6,x6,0
    1690:	0901                	addi	x18,x18,0
    1692:	0004                	0x4
    1694:	0301                	addi	x6,x6,0
    1696:	0902                	c.slli64	x18
    1698:	0004                	0x4
    169a:	0301                	addi	x6,x6,0
    169c:	0901                	addi	x18,x18,0
    169e:	0004                	0x4
    16a0:	0301                	addi	x6,x6,0
    16a2:	0901                	addi	x18,x18,0
    16a4:	0004                	0x4
    16a6:	0301                	addi	x6,x6,0
    16a8:	0902                	c.slli64	x18
    16aa:	0004                	0x4
    16ac:	0301                	addi	x6,x6,0
    16ae:	0901                	addi	x18,x18,0
    16b0:	0004                	0x4
    16b2:	0301                	addi	x6,x6,0
    16b4:	0901                	addi	x18,x18,0
    16b6:	0004                	0x4
    16b8:	0301                	addi	x6,x6,0
    16ba:	0902                	c.slli64	x18
    16bc:	0004                	0x4
    16be:	0301                	addi	x6,x6,0
    16c0:	0901                	addi	x18,x18,0
    16c2:	0004                	0x4
    16c4:	0301                	addi	x6,x6,0
    16c6:	0901                	addi	x18,x18,0
    16c8:	0004                	0x4
    16ca:	0301                	addi	x6,x6,0
    16cc:	0902                	c.slli64	x18
    16ce:	0004                	0x4
    16d0:	0301                	addi	x6,x6,0
    16d2:	0901                	addi	x18,x18,0
    16d4:	0004                	0x4
    16d6:	0301                	addi	x6,x6,0
    16d8:	0901                	addi	x18,x18,0
    16da:	0004                	0x4
    16dc:	0301                	addi	x6,x6,0
    16de:	0902                	c.slli64	x18
    16e0:	0004                	0x4
    16e2:	0301                	addi	x6,x6,0
    16e4:	0901                	addi	x18,x18,0
    16e6:	0004                	0x4
    16e8:	0301                	addi	x6,x6,0
    16ea:	0901                	addi	x18,x18,0
    16ec:	0004                	0x4
    16ee:	0301                	addi	x6,x6,0
    16f0:	0902                	c.slli64	x18
    16f2:	0004                	0x4
    16f4:	0301                	addi	x6,x6,0
    16f6:	0901                	addi	x18,x18,0
    16f8:	0004                	0x4
    16fa:	0301                	addi	x6,x6,0
    16fc:	0901                	addi	x18,x18,0
    16fe:	0004                	0x4
    1700:	0301                	addi	x6,x6,0
    1702:	0902                	c.slli64	x18
    1704:	0004                	0x4
    1706:	0301                	addi	x6,x6,0
    1708:	0901                	addi	x18,x18,0
    170a:	0004                	0x4
    170c:	0301                	addi	x6,x6,0
    170e:	0901                	addi	x18,x18,0
    1710:	0004                	0x4
    1712:	0301                	addi	x6,x6,0
    1714:	0902                	c.slli64	x18
    1716:	0004                	0x4
    1718:	0301                	addi	x6,x6,0
    171a:	0901                	addi	x18,x18,0
    171c:	0004                	0x4
    171e:	0301                	addi	x6,x6,0
    1720:	0901                	addi	x18,x18,0
    1722:	0004                	0x4
    1724:	0301                	addi	x6,x6,0
    1726:	0902                	c.slli64	x18
    1728:	0004                	0x4
    172a:	0301                	addi	x6,x6,0
    172c:	0901                	addi	x18,x18,0
    172e:	0004                	0x4
    1730:	0301                	addi	x6,x6,0
    1732:	0901                	addi	x18,x18,0
    1734:	0004                	0x4
    1736:	0301                	addi	x6,x6,0
    1738:	0902                	c.slli64	x18
    173a:	0004                	0x4
    173c:	0301                	addi	x6,x6,0
    173e:	0901                	addi	x18,x18,0
    1740:	0004                	0x4
    1742:	0301                	addi	x6,x6,0
    1744:	0901                	addi	x18,x18,0
    1746:	0004                	0x4
    1748:	0301                	addi	x6,x6,0
    174a:	0902                	c.slli64	x18
    174c:	0004                	0x4
    174e:	0301                	addi	x6,x6,0
    1750:	0901                	addi	x18,x18,0
    1752:	0004                	0x4
    1754:	0301                	addi	x6,x6,0
    1756:	0901                	addi	x18,x18,0
    1758:	0004                	0x4
    175a:	0301                	addi	x6,x6,0
    175c:	0902                	c.slli64	x18
    175e:	0004                	0x4
    1760:	0301                	addi	x6,x6,0
    1762:	0901                	addi	x18,x18,0
    1764:	0004                	0x4
    1766:	0301                	addi	x6,x6,0
    1768:	0901                	addi	x18,x18,0
    176a:	0004                	0x4
    176c:	0301                	addi	x6,x6,0
    176e:	0902                	c.slli64	x18
    1770:	0004                	0x4
    1772:	0301                	addi	x6,x6,0
    1774:	0901                	addi	x18,x18,0
    1776:	0004                	0x4
    1778:	0301                	addi	x6,x6,0
    177a:	0901                	addi	x18,x18,0
    177c:	0004                	0x4
    177e:	0301                	addi	x6,x6,0
    1780:	0902                	c.slli64	x18
    1782:	0004                	0x4
    1784:	0301                	addi	x6,x6,0
    1786:	0901                	addi	x18,x18,0
    1788:	0004                	0x4
    178a:	0301                	addi	x6,x6,0
    178c:	0901                	addi	x18,x18,0
    178e:	0004                	0x4
    1790:	0301                	addi	x6,x6,0
    1792:	0902                	c.slli64	x18
    1794:	0004                	0x4
    1796:	0301                	addi	x6,x6,0
    1798:	0901                	addi	x18,x18,0
    179a:	0004                	0x4
    179c:	0301                	addi	x6,x6,0
    179e:	0901                	addi	x18,x18,0
    17a0:	0004                	0x4
    17a2:	0301                	addi	x6,x6,0
    17a4:	0902                	c.slli64	x18
    17a6:	0004                	0x4
    17a8:	0301                	addi	x6,x6,0
    17aa:	0901                	addi	x18,x18,0
    17ac:	0004                	0x4
    17ae:	0301                	addi	x6,x6,0
    17b0:	0901                	addi	x18,x18,0
    17b2:	0004                	0x4
    17b4:	0301                	addi	x6,x6,0
    17b6:	0902                	c.slli64	x18
    17b8:	0004                	0x4
    17ba:	0301                	addi	x6,x6,0
    17bc:	0901                	addi	x18,x18,0
    17be:	0004                	0x4
    17c0:	0301                	addi	x6,x6,0
    17c2:	0901                	addi	x18,x18,0
    17c4:	0004                	0x4
    17c6:	0301                	addi	x6,x6,0
    17c8:	0902                	c.slli64	x18
    17ca:	0004                	0x4
    17cc:	0301                	addi	x6,x6,0
    17ce:	0901                	addi	x18,x18,0
    17d0:	0004                	0x4
    17d2:	0301                	addi	x6,x6,0
    17d4:	0901                	addi	x18,x18,0
    17d6:	0004                	0x4
    17d8:	0301                	addi	x6,x6,0
    17da:	0902                	c.slli64	x18
    17dc:	0004                	0x4
    17de:	0301                	addi	x6,x6,0
    17e0:	0901                	addi	x18,x18,0
    17e2:	0004                	0x4
    17e4:	0301                	addi	x6,x6,0
    17e6:	0901                	addi	x18,x18,0
    17e8:	0004                	0x4
    17ea:	0301                	addi	x6,x6,0
    17ec:	0902                	c.slli64	x18
    17ee:	0004                	0x4
    17f0:	0301                	addi	x6,x6,0
    17f2:	0901                	addi	x18,x18,0
    17f4:	0004                	0x4
    17f6:	0301                	addi	x6,x6,0
    17f8:	0901                	addi	x18,x18,0
    17fa:	0004                	0x4
    17fc:	0301                	addi	x6,x6,0
    17fe:	0902                	c.slli64	x18
    1800:	0004                	0x4
    1802:	0301                	addi	x6,x6,0
    1804:	0901                	addi	x18,x18,0
    1806:	0004                	0x4
    1808:	0301                	addi	x6,x6,0
    180a:	0901                	addi	x18,x18,0
    180c:	0004                	0x4
    180e:	0301                	addi	x6,x6,0
    1810:	0902                	c.slli64	x18
    1812:	0004                	0x4
    1814:	0301                	addi	x6,x6,0
    1816:	0901                	addi	x18,x18,0
    1818:	0004                	0x4
    181a:	0301                	addi	x6,x6,0
    181c:	0901                	addi	x18,x18,0
    181e:	0004                	0x4
    1820:	0301                	addi	x6,x6,0
    1822:	0902                	c.slli64	x18
    1824:	0004                	0x4
    1826:	0301                	addi	x6,x6,0
    1828:	0901                	addi	x18,x18,0
    182a:	0004                	0x4
    182c:	0301                	addi	x6,x6,0
    182e:	0901                	addi	x18,x18,0
    1830:	0004                	0x4
    1832:	0301                	addi	x6,x6,0
    1834:	0902                	c.slli64	x18
    1836:	0004                	0x4
    1838:	0301                	addi	x6,x6,0
    183a:	0901                	addi	x18,x18,0
    183c:	0004                	0x4
    183e:	0301                	addi	x6,x6,0
    1840:	0901                	addi	x18,x18,0
    1842:	0004                	0x4
    1844:	0301                	addi	x6,x6,0
    1846:	0902                	c.slli64	x18
    1848:	0004                	0x4
    184a:	0301                	addi	x6,x6,0
    184c:	0901                	addi	x18,x18,0
    184e:	0004                	0x4
    1850:	0301                	addi	x6,x6,0
    1852:	0901                	addi	x18,x18,0
    1854:	0004                	0x4
    1856:	0301                	addi	x6,x6,0
    1858:	0902                	c.slli64	x18
    185a:	0004                	0x4
    185c:	0301                	addi	x6,x6,0
    185e:	0901                	addi	x18,x18,0
    1860:	0004                	0x4
    1862:	0301                	addi	x6,x6,0
    1864:	0901                	addi	x18,x18,0
    1866:	0004                	0x4
    1868:	0301                	addi	x6,x6,0
    186a:	0902                	c.slli64	x18
    186c:	0004                	0x4
    186e:	0301                	addi	x6,x6,0
    1870:	0901                	addi	x18,x18,0
    1872:	0004                	0x4
    1874:	0301                	addi	x6,x6,0
    1876:	0901                	addi	x18,x18,0
    1878:	0004                	0x4
    187a:	0301                	addi	x6,x6,0
    187c:	0902                	c.slli64	x18
    187e:	0004                	0x4
    1880:	0301                	addi	x6,x6,0
    1882:	0901                	addi	x18,x18,0
    1884:	0004                	0x4
    1886:	0301                	addi	x6,x6,0
    1888:	0901                	addi	x18,x18,0
    188a:	0004                	0x4
    188c:	0301                	addi	x6,x6,0
    188e:	0902                	c.slli64	x18
    1890:	0004                	0x4
    1892:	0301                	addi	x6,x6,0
    1894:	0901                	addi	x18,x18,0
    1896:	0004                	0x4
    1898:	0301                	addi	x6,x6,0
    189a:	0901                	addi	x18,x18,0
    189c:	0004                	0x4
    189e:	0301                	addi	x6,x6,0
    18a0:	0902                	c.slli64	x18
    18a2:	0004                	0x4
    18a4:	0301                	addi	x6,x6,0
    18a6:	0901                	addi	x18,x18,0
    18a8:	0004                	0x4
    18aa:	0301                	addi	x6,x6,0
    18ac:	0901                	addi	x18,x18,0
    18ae:	0004                	0x4
    18b0:	0301                	addi	x6,x6,0
    18b2:	0902                	c.slli64	x18
    18b4:	0004                	0x4
    18b6:	0301                	addi	x6,x6,0
    18b8:	0901                	addi	x18,x18,0
    18ba:	0004                	0x4
    18bc:	0301                	addi	x6,x6,0
    18be:	0901                	addi	x18,x18,0
    18c0:	0004                	0x4
    18c2:	0301                	addi	x6,x6,0
    18c4:	0902                	c.slli64	x18
    18c6:	0004                	0x4
    18c8:	0301                	addi	x6,x6,0
    18ca:	0901                	addi	x18,x18,0
    18cc:	0004                	0x4
    18ce:	0301                	addi	x6,x6,0
    18d0:	0901                	addi	x18,x18,0
    18d2:	0004                	0x4
    18d4:	0301                	addi	x6,x6,0
    18d6:	0902                	c.slli64	x18
    18d8:	0004                	0x4
    18da:	0301                	addi	x6,x6,0
    18dc:	0901                	addi	x18,x18,0
    18de:	0004                	0x4
    18e0:	0301                	addi	x6,x6,0
    18e2:	0901                	addi	x18,x18,0
    18e4:	0004                	0x4
    18e6:	0301                	addi	x6,x6,0
    18e8:	0902                	c.slli64	x18
    18ea:	0004                	0x4
    18ec:	0301                	addi	x6,x6,0
    18ee:	0901                	addi	x18,x18,0
    18f0:	0004                	0x4
    18f2:	0301                	addi	x6,x6,0
    18f4:	0901                	addi	x18,x18,0
    18f6:	0004                	0x4
    18f8:	0301                	addi	x6,x6,0
    18fa:	0902                	c.slli64	x18
    18fc:	0004                	0x4
    18fe:	0301                	addi	x6,x6,0
    1900:	0901                	addi	x18,x18,0
    1902:	0004                	0x4
    1904:	0301                	addi	x6,x6,0
    1906:	0901                	addi	x18,x18,0
    1908:	0004                	0x4
    190a:	0301                	addi	x6,x6,0
    190c:	0902                	c.slli64	x18
    190e:	0004                	0x4
    1910:	0301                	addi	x6,x6,0
    1912:	0901                	addi	x18,x18,0
    1914:	0004                	0x4
    1916:	0301                	addi	x6,x6,0
    1918:	0901                	addi	x18,x18,0
    191a:	0004                	0x4
    191c:	0301                	addi	x6,x6,0
    191e:	0902                	c.slli64	x18
    1920:	0004                	0x4
    1922:	0301                	addi	x6,x6,0
    1924:	0901                	addi	x18,x18,0
    1926:	0004                	0x4
    1928:	0301                	addi	x6,x6,0
    192a:	0901                	addi	x18,x18,0
    192c:	0004                	0x4
    192e:	0301                	addi	x6,x6,0
    1930:	0902                	c.slli64	x18
    1932:	0004                	0x4
    1934:	0301                	addi	x6,x6,0
    1936:	0901                	addi	x18,x18,0
    1938:	0004                	0x4
    193a:	0301                	addi	x6,x6,0
    193c:	0901                	addi	x18,x18,0
    193e:	0004                	0x4
    1940:	0301                	addi	x6,x6,0
    1942:	0902                	c.slli64	x18
    1944:	0004                	0x4
    1946:	0301                	addi	x6,x6,0
    1948:	0901                	addi	x18,x18,0
    194a:	0004                	0x4
    194c:	0301                	addi	x6,x6,0
    194e:	0901                	addi	x18,x18,0
    1950:	0004                	0x4
    1952:	0301                	addi	x6,x6,0
    1954:	0902                	c.slli64	x18
    1956:	0004                	0x4
    1958:	0301                	addi	x6,x6,0
    195a:	0901                	addi	x18,x18,0
    195c:	0004                	0x4
    195e:	0301                	addi	x6,x6,0
    1960:	0901                	addi	x18,x18,0
    1962:	0004                	0x4
    1964:	0301                	addi	x6,x6,0
    1966:	0902                	c.slli64	x18
    1968:	0004                	0x4
    196a:	0301                	addi	x6,x6,0
    196c:	0901                	addi	x18,x18,0
    196e:	0004                	0x4
    1970:	0301                	addi	x6,x6,0
    1972:	0901                	addi	x18,x18,0
    1974:	0004                	0x4
    1976:	0301                	addi	x6,x6,0
    1978:	0902                	c.slli64	x18
    197a:	0004                	0x4
    197c:	0301                	addi	x6,x6,0
    197e:	0901                	addi	x18,x18,0
    1980:	0004                	0x4
    1982:	0301                	addi	x6,x6,0
    1984:	0901                	addi	x18,x18,0
    1986:	0004                	0x4
    1988:	0301                	addi	x6,x6,0
    198a:	0902                	c.slli64	x18
    198c:	0004                	0x4
    198e:	0301                	addi	x6,x6,0
    1990:	0901                	addi	x18,x18,0
    1992:	0004                	0x4
    1994:	0301                	addi	x6,x6,0
    1996:	0901                	addi	x18,x18,0
    1998:	0004                	0x4
    199a:	0301                	addi	x6,x6,0
    199c:	0902                	c.slli64	x18
    199e:	0004                	0x4
    19a0:	0301                	addi	x6,x6,0
    19a2:	0901                	addi	x18,x18,0
    19a4:	0004                	0x4
    19a6:	0301                	addi	x6,x6,0
    19a8:	0901                	addi	x18,x18,0
    19aa:	0004                	0x4
    19ac:	0301                	addi	x6,x6,0
    19ae:	0902                	c.slli64	x18
    19b0:	0004                	0x4
    19b2:	0301                	addi	x6,x6,0
    19b4:	0901                	addi	x18,x18,0
    19b6:	0004                	0x4
    19b8:	0301                	addi	x6,x6,0
    19ba:	0901                	addi	x18,x18,0
    19bc:	0004                	0x4
    19be:	0301                	addi	x6,x6,0
    19c0:	0902                	c.slli64	x18
    19c2:	0004                	0x4
    19c4:	0301                	addi	x6,x6,0
    19c6:	0901                	addi	x18,x18,0
    19c8:	0004                	0x4
    19ca:	0301                	addi	x6,x6,0
    19cc:	0901                	addi	x18,x18,0
    19ce:	0004                	0x4
    19d0:	0301                	addi	x6,x6,0
    19d2:	0902                	c.slli64	x18
    19d4:	0004                	0x4
    19d6:	0301                	addi	x6,x6,0
    19d8:	0901                	addi	x18,x18,0
    19da:	0004                	0x4
    19dc:	0301                	addi	x6,x6,0
    19de:	0901                	addi	x18,x18,0
    19e0:	0004                	0x4
    19e2:	0301                	addi	x6,x6,0
    19e4:	0902                	c.slli64	x18
    19e6:	0004                	0x4
    19e8:	0301                	addi	x6,x6,0
    19ea:	0901                	addi	x18,x18,0
    19ec:	0004                	0x4
    19ee:	0301                	addi	x6,x6,0
    19f0:	0901                	addi	x18,x18,0
    19f2:	0004                	0x4
    19f4:	0301                	addi	x6,x6,0
    19f6:	0902                	c.slli64	x18
    19f8:	0004                	0x4
    19fa:	0301                	addi	x6,x6,0
    19fc:	0901                	addi	x18,x18,0
    19fe:	0004                	0x4
    1a00:	0301                	addi	x6,x6,0
    1a02:	0901                	addi	x18,x18,0
    1a04:	0004                	0x4
    1a06:	0301                	addi	x6,x6,0
    1a08:	0902                	c.slli64	x18
    1a0a:	0004                	0x4
    1a0c:	0301                	addi	x6,x6,0
    1a0e:	0901                	addi	x18,x18,0
    1a10:	0004                	0x4
    1a12:	0301                	addi	x6,x6,0
    1a14:	0901                	addi	x18,x18,0
    1a16:	0004                	0x4
    1a18:	0301                	addi	x6,x6,0
    1a1a:	0902                	c.slli64	x18
    1a1c:	0004                	0x4
    1a1e:	0301                	addi	x6,x6,0
    1a20:	0901                	addi	x18,x18,0
    1a22:	0004                	0x4
    1a24:	0301                	addi	x6,x6,0
    1a26:	0901                	addi	x18,x18,0
    1a28:	0004                	0x4
    1a2a:	0301                	addi	x6,x6,0
    1a2c:	0902                	c.slli64	x18
    1a2e:	0004                	0x4
    1a30:	0301                	addi	x6,x6,0
    1a32:	0901                	addi	x18,x18,0
    1a34:	0004                	0x4
    1a36:	0301                	addi	x6,x6,0
    1a38:	0901                	addi	x18,x18,0
    1a3a:	0004                	0x4
    1a3c:	0301                	addi	x6,x6,0
    1a3e:	0902                	c.slli64	x18
    1a40:	0004                	0x4
    1a42:	0301                	addi	x6,x6,0
    1a44:	0901                	addi	x18,x18,0
    1a46:	0004                	0x4
    1a48:	0301                	addi	x6,x6,0
    1a4a:	0901                	addi	x18,x18,0
    1a4c:	0004                	0x4
    1a4e:	0301                	addi	x6,x6,0
    1a50:	0902                	c.slli64	x18
    1a52:	0004                	0x4
    1a54:	0301                	addi	x6,x6,0
    1a56:	0901                	addi	x18,x18,0
    1a58:	0004                	0x4
    1a5a:	0301                	addi	x6,x6,0
    1a5c:	0901                	addi	x18,x18,0
    1a5e:	0004                	0x4
    1a60:	0301                	addi	x6,x6,0
    1a62:	0902                	c.slli64	x18
    1a64:	0004                	0x4
    1a66:	0301                	addi	x6,x6,0
    1a68:	0901                	addi	x18,x18,0
    1a6a:	0004                	0x4
    1a6c:	0301                	addi	x6,x6,0
    1a6e:	0901                	addi	x18,x18,0
    1a70:	0004                	0x4
    1a72:	0301                	addi	x6,x6,0
    1a74:	0902                	c.slli64	x18
    1a76:	0004                	0x4
    1a78:	0301                	addi	x6,x6,0
    1a7a:	0901                	addi	x18,x18,0
    1a7c:	0004                	0x4
    1a7e:	0301                	addi	x6,x6,0
    1a80:	0901                	addi	x18,x18,0
    1a82:	0004                	0x4
    1a84:	0301                	addi	x6,x6,0
    1a86:	0902                	c.slli64	x18
    1a88:	0004                	0x4
    1a8a:	0301                	addi	x6,x6,0
    1a8c:	0901                	addi	x18,x18,0
    1a8e:	0004                	0x4
    1a90:	0301                	addi	x6,x6,0
    1a92:	0901                	addi	x18,x18,0
    1a94:	0004                	0x4
    1a96:	0301                	addi	x6,x6,0
    1a98:	0902                	c.slli64	x18
    1a9a:	0004                	0x4
    1a9c:	0301                	addi	x6,x6,0
    1a9e:	0901                	addi	x18,x18,0
    1aa0:	0004                	0x4
    1aa2:	0301                	addi	x6,x6,0
    1aa4:	0901                	addi	x18,x18,0
    1aa6:	0004                	0x4
    1aa8:	0301                	addi	x6,x6,0
    1aaa:	0902                	c.slli64	x18
    1aac:	0004                	0x4
    1aae:	0301                	addi	x6,x6,0
    1ab0:	0901                	addi	x18,x18,0
    1ab2:	0004                	0x4
    1ab4:	0301                	addi	x6,x6,0
    1ab6:	0901                	addi	x18,x18,0
    1ab8:	0004                	0x4
    1aba:	0301                	addi	x6,x6,0
    1abc:	0902                	c.slli64	x18
    1abe:	0004                	0x4
    1ac0:	0301                	addi	x6,x6,0
    1ac2:	0901                	addi	x18,x18,0
    1ac4:	0004                	0x4
    1ac6:	0301                	addi	x6,x6,0
    1ac8:	0901                	addi	x18,x18,0
    1aca:	0004                	0x4
    1acc:	0301                	addi	x6,x6,0
    1ace:	0902                	c.slli64	x18
    1ad0:	0004                	0x4
    1ad2:	0301                	addi	x6,x6,0
    1ad4:	0901                	addi	x18,x18,0
    1ad6:	0004                	0x4
    1ad8:	0301                	addi	x6,x6,0
    1ada:	0901                	addi	x18,x18,0
    1adc:	0004                	0x4
    1ade:	0301                	addi	x6,x6,0
    1ae0:	0902                	c.slli64	x18
    1ae2:	0004                	0x4
    1ae4:	0301                	addi	x6,x6,0
    1ae6:	0901                	addi	x18,x18,0
    1ae8:	0004                	0x4
    1aea:	0301                	addi	x6,x6,0
    1aec:	0901                	addi	x18,x18,0
    1aee:	0004                	0x4
    1af0:	0301                	addi	x6,x6,0
    1af2:	0902                	c.slli64	x18
    1af4:	0004                	0x4
    1af6:	0301                	addi	x6,x6,0
    1af8:	0901                	addi	x18,x18,0
    1afa:	0004                	0x4
    1afc:	0301                	addi	x6,x6,0
    1afe:	0901                	addi	x18,x18,0
    1b00:	0004                	0x4
    1b02:	0301                	addi	x6,x6,0
    1b04:	0902                	c.slli64	x18
    1b06:	0004                	0x4
    1b08:	0301                	addi	x6,x6,0
    1b0a:	0901                	addi	x18,x18,0
    1b0c:	0004                	0x4
    1b0e:	0301                	addi	x6,x6,0
    1b10:	0901                	addi	x18,x18,0
    1b12:	0004                	0x4
    1b14:	0301                	addi	x6,x6,0
    1b16:	0902                	c.slli64	x18
    1b18:	0004                	0x4
    1b1a:	0301                	addi	x6,x6,0
    1b1c:	0901                	addi	x18,x18,0
    1b1e:	0004                	0x4
    1b20:	0301                	addi	x6,x6,0
    1b22:	0901                	addi	x18,x18,0
    1b24:	0004                	0x4
    1b26:	0301                	addi	x6,x6,0
    1b28:	0902                	c.slli64	x18
    1b2a:	0004                	0x4
    1b2c:	0301                	addi	x6,x6,0
    1b2e:	0901                	addi	x18,x18,0
    1b30:	0004                	0x4
    1b32:	0301                	addi	x6,x6,0
    1b34:	0901                	addi	x18,x18,0
    1b36:	0004                	0x4
    1b38:	0301                	addi	x6,x6,0
    1b3a:	0902                	c.slli64	x18
    1b3c:	0004                	0x4
    1b3e:	0301                	addi	x6,x6,0
    1b40:	0901                	addi	x18,x18,0
    1b42:	0004                	0x4
    1b44:	0301                	addi	x6,x6,0
    1b46:	0901                	addi	x18,x18,0
    1b48:	0004                	0x4
    1b4a:	0301                	addi	x6,x6,0
    1b4c:	0902                	c.slli64	x18
    1b4e:	0004                	0x4
    1b50:	0301                	addi	x6,x6,0
    1b52:	0901                	addi	x18,x18,0
    1b54:	0004                	0x4
    1b56:	0301                	addi	x6,x6,0
    1b58:	0901                	addi	x18,x18,0
    1b5a:	0004                	0x4
    1b5c:	0301                	addi	x6,x6,0
    1b5e:	0902                	c.slli64	x18
    1b60:	0004                	0x4
    1b62:	0301                	addi	x6,x6,0
    1b64:	0901                	addi	x18,x18,0
    1b66:	0004                	0x4
    1b68:	0301                	addi	x6,x6,0
    1b6a:	0901                	addi	x18,x18,0
    1b6c:	0004                	0x4
    1b6e:	0301                	addi	x6,x6,0
    1b70:	0902                	c.slli64	x18
    1b72:	0004                	0x4
    1b74:	0301                	addi	x6,x6,0
    1b76:	0901                	addi	x18,x18,0
    1b78:	0004                	0x4
    1b7a:	0301                	addi	x6,x6,0
    1b7c:	0901                	addi	x18,x18,0
    1b7e:	0004                	0x4
    1b80:	0301                	addi	x6,x6,0
    1b82:	0902                	c.slli64	x18
    1b84:	0004                	0x4
    1b86:	0301                	addi	x6,x6,0
    1b88:	0901                	addi	x18,x18,0
    1b8a:	0004                	0x4
    1b8c:	0301                	addi	x6,x6,0
    1b8e:	0901                	addi	x18,x18,0
    1b90:	0004                	0x4
    1b92:	0301                	addi	x6,x6,0
    1b94:	0902                	c.slli64	x18
    1b96:	0004                	0x4
    1b98:	0301                	addi	x6,x6,0
    1b9a:	0901                	addi	x18,x18,0
    1b9c:	0004                	0x4
    1b9e:	0301                	addi	x6,x6,0
    1ba0:	0901                	addi	x18,x18,0
    1ba2:	0004                	0x4
    1ba4:	0301                	addi	x6,x6,0
    1ba6:	0902                	c.slli64	x18
    1ba8:	0004                	0x4
    1baa:	0301                	addi	x6,x6,0
    1bac:	0901                	addi	x18,x18,0
    1bae:	0004                	0x4
    1bb0:	0301                	addi	x6,x6,0
    1bb2:	0901                	addi	x18,x18,0
    1bb4:	0004                	0x4
    1bb6:	0301                	addi	x6,x6,0
    1bb8:	0902                	c.slli64	x18
    1bba:	0004                	0x4
    1bbc:	0301                	addi	x6,x6,0
    1bbe:	0901                	addi	x18,x18,0
    1bc0:	0004                	0x4
    1bc2:	0301                	addi	x6,x6,0
    1bc4:	0901                	addi	x18,x18,0
    1bc6:	0004                	0x4
    1bc8:	0301                	addi	x6,x6,0
    1bca:	0902                	c.slli64	x18
    1bcc:	0004                	0x4
    1bce:	0301                	addi	x6,x6,0
    1bd0:	0901                	addi	x18,x18,0
    1bd2:	0004                	0x4
    1bd4:	0301                	addi	x6,x6,0
    1bd6:	0901                	addi	x18,x18,0
    1bd8:	0004                	0x4
    1bda:	0301                	addi	x6,x6,0
    1bdc:	0902                	c.slli64	x18
    1bde:	0004                	0x4
    1be0:	0301                	addi	x6,x6,0
    1be2:	0901                	addi	x18,x18,0
    1be4:	0004                	0x4
    1be6:	0301                	addi	x6,x6,0
    1be8:	0901                	addi	x18,x18,0
    1bea:	0004                	0x4
    1bec:	0301                	addi	x6,x6,0
    1bee:	0902                	c.slli64	x18
    1bf0:	0004                	0x4
    1bf2:	0301                	addi	x6,x6,0
    1bf4:	0901                	addi	x18,x18,0
    1bf6:	0004                	0x4
    1bf8:	0301                	addi	x6,x6,0
    1bfa:	0901                	addi	x18,x18,0
    1bfc:	0004                	0x4
    1bfe:	0301                	addi	x6,x6,0
    1c00:	0902                	c.slli64	x18
    1c02:	0004                	0x4
    1c04:	0301                	addi	x6,x6,0
    1c06:	0901                	addi	x18,x18,0
    1c08:	0004                	0x4
    1c0a:	0301                	addi	x6,x6,0
    1c0c:	0901                	addi	x18,x18,0
    1c0e:	0004                	0x4
    1c10:	0301                	addi	x6,x6,0
    1c12:	0902                	c.slli64	x18
    1c14:	0004                	0x4
    1c16:	0301                	addi	x6,x6,0
    1c18:	0901                	addi	x18,x18,0
    1c1a:	0004                	0x4
    1c1c:	0301                	addi	x6,x6,0
    1c1e:	0901                	addi	x18,x18,0
    1c20:	0004                	0x4
    1c22:	0301                	addi	x6,x6,0
    1c24:	0902                	c.slli64	x18
    1c26:	0004                	0x4
    1c28:	0301                	addi	x6,x6,0
    1c2a:	0901                	addi	x18,x18,0
    1c2c:	0004                	0x4
    1c2e:	0301                	addi	x6,x6,0
    1c30:	0901                	addi	x18,x18,0
    1c32:	0004                	0x4
    1c34:	0301                	addi	x6,x6,0
    1c36:	0902                	c.slli64	x18
    1c38:	0004                	0x4
    1c3a:	0301                	addi	x6,x6,0
    1c3c:	0901                	addi	x18,x18,0
    1c3e:	0004                	0x4
    1c40:	0301                	addi	x6,x6,0
    1c42:	0901                	addi	x18,x18,0
    1c44:	0004                	0x4
    1c46:	0301                	addi	x6,x6,0
    1c48:	0902                	c.slli64	x18
    1c4a:	0004                	0x4
    1c4c:	0301                	addi	x6,x6,0
    1c4e:	0901                	addi	x18,x18,0
    1c50:	0004                	0x4
    1c52:	0301                	addi	x6,x6,0
    1c54:	0901                	addi	x18,x18,0
    1c56:	0004                	0x4
    1c58:	0301                	addi	x6,x6,0
    1c5a:	0902                	c.slli64	x18
    1c5c:	0004                	0x4
    1c5e:	0301                	addi	x6,x6,0
    1c60:	0901                	addi	x18,x18,0
    1c62:	0004                	0x4
    1c64:	0301                	addi	x6,x6,0
    1c66:	0901                	addi	x18,x18,0
    1c68:	0004                	0x4
    1c6a:	0301                	addi	x6,x6,0
    1c6c:	0902                	c.slli64	x18
    1c6e:	0004                	0x4
    1c70:	0301                	addi	x6,x6,0
    1c72:	0901                	addi	x18,x18,0
    1c74:	0004                	0x4
    1c76:	0301                	addi	x6,x6,0
    1c78:	0901                	addi	x18,x18,0
    1c7a:	0004                	0x4
    1c7c:	0301                	addi	x6,x6,0
    1c7e:	0902                	c.slli64	x18
    1c80:	0004                	0x4
    1c82:	0301                	addi	x6,x6,0
    1c84:	0901                	addi	x18,x18,0
    1c86:	0004                	0x4
    1c88:	0301                	addi	x6,x6,0
    1c8a:	0901                	addi	x18,x18,0
    1c8c:	0004                	0x4
    1c8e:	0301                	addi	x6,x6,0
    1c90:	0902                	c.slli64	x18
    1c92:	0004                	0x4
    1c94:	0301                	addi	x6,x6,0
    1c96:	0901                	addi	x18,x18,0
    1c98:	0004                	0x4
    1c9a:	0301                	addi	x6,x6,0
    1c9c:	0901                	addi	x18,x18,0
    1c9e:	0004                	0x4
    1ca0:	0301                	addi	x6,x6,0
    1ca2:	0902                	c.slli64	x18
    1ca4:	0004                	0x4
    1ca6:	0301                	addi	x6,x6,0
    1ca8:	0901                	addi	x18,x18,0
    1caa:	0004                	0x4
    1cac:	0301                	addi	x6,x6,0
    1cae:	0901                	addi	x18,x18,0
    1cb0:	0004                	0x4
    1cb2:	0301                	addi	x6,x6,0
    1cb4:	0902                	c.slli64	x18
    1cb6:	0004                	0x4
    1cb8:	0301                	addi	x6,x6,0
    1cba:	0901                	addi	x18,x18,0
    1cbc:	0004                	0x4
    1cbe:	0301                	addi	x6,x6,0
    1cc0:	0901                	addi	x18,x18,0
    1cc2:	0004                	0x4
    1cc4:	0301                	addi	x6,x6,0
    1cc6:	0902                	c.slli64	x18
    1cc8:	0004                	0x4
    1cca:	0301                	addi	x6,x6,0
    1ccc:	0901                	addi	x18,x18,0
    1cce:	0004                	0x4
    1cd0:	0301                	addi	x6,x6,0
    1cd2:	0901                	addi	x18,x18,0
    1cd4:	0004                	0x4
    1cd6:	0301                	addi	x6,x6,0
    1cd8:	0902                	c.slli64	x18
    1cda:	0004                	0x4
    1cdc:	0301                	addi	x6,x6,0
    1cde:	0901                	addi	x18,x18,0
    1ce0:	0004                	0x4
    1ce2:	0301                	addi	x6,x6,0
    1ce4:	0901                	addi	x18,x18,0
    1ce6:	0004                	0x4
    1ce8:	0301                	addi	x6,x6,0
    1cea:	0902                	c.slli64	x18
    1cec:	0004                	0x4
    1cee:	0301                	addi	x6,x6,0
    1cf0:	0901                	addi	x18,x18,0
    1cf2:	0004                	0x4
    1cf4:	0301                	addi	x6,x6,0
    1cf6:	0901                	addi	x18,x18,0
    1cf8:	0004                	0x4
    1cfa:	0301                	addi	x6,x6,0
    1cfc:	0902                	c.slli64	x18
    1cfe:	0004                	0x4
    1d00:	0301                	addi	x6,x6,0
    1d02:	0901                	addi	x18,x18,0
    1d04:	0004                	0x4
    1d06:	0301                	addi	x6,x6,0
    1d08:	0901                	addi	x18,x18,0
    1d0a:	0004                	0x4
    1d0c:	0301                	addi	x6,x6,0
    1d0e:	0902                	c.slli64	x18
    1d10:	0004                	0x4
    1d12:	0301                	addi	x6,x6,0
    1d14:	0901                	addi	x18,x18,0
    1d16:	0004                	0x4
    1d18:	0301                	addi	x6,x6,0
    1d1a:	0901                	addi	x18,x18,0
    1d1c:	0004                	0x4
    1d1e:	0301                	addi	x6,x6,0
    1d20:	0902                	c.slli64	x18
    1d22:	0004                	0x4
    1d24:	0301                	addi	x6,x6,0
    1d26:	0901                	addi	x18,x18,0
    1d28:	0004                	0x4
    1d2a:	0301                	addi	x6,x6,0
    1d2c:	0901                	addi	x18,x18,0
    1d2e:	0004                	0x4
    1d30:	0301                	addi	x6,x6,0
    1d32:	0902                	c.slli64	x18
    1d34:	0004                	0x4
    1d36:	0301                	addi	x6,x6,0
    1d38:	0901                	addi	x18,x18,0
    1d3a:	0004                	0x4
    1d3c:	0301                	addi	x6,x6,0
    1d3e:	0901                	addi	x18,x18,0
    1d40:	0004                	0x4
    1d42:	0301                	addi	x6,x6,0
    1d44:	0902                	c.slli64	x18
    1d46:	0004                	0x4
    1d48:	0301                	addi	x6,x6,0
    1d4a:	0901                	addi	x18,x18,0
    1d4c:	0004                	0x4
    1d4e:	0301                	addi	x6,x6,0
    1d50:	0901                	addi	x18,x18,0
    1d52:	0004                	0x4
    1d54:	0301                	addi	x6,x6,0
    1d56:	0902                	c.slli64	x18
    1d58:	0004                	0x4
    1d5a:	0301                	addi	x6,x6,0
    1d5c:	0901                	addi	x18,x18,0
    1d5e:	0004                	0x4
    1d60:	0301                	addi	x6,x6,0
    1d62:	0901                	addi	x18,x18,0
    1d64:	0004                	0x4
    1d66:	0301                	addi	x6,x6,0
    1d68:	0902                	c.slli64	x18
    1d6a:	0004                	0x4
    1d6c:	0301                	addi	x6,x6,0
    1d6e:	0901                	addi	x18,x18,0
    1d70:	0004                	0x4
    1d72:	0301                	addi	x6,x6,0
    1d74:	0901                	addi	x18,x18,0
    1d76:	0004                	0x4
    1d78:	0301                	addi	x6,x6,0
    1d7a:	0902                	c.slli64	x18
    1d7c:	0004                	0x4
    1d7e:	0301                	addi	x6,x6,0
    1d80:	0901                	addi	x18,x18,0
    1d82:	0004                	0x4
    1d84:	0301                	addi	x6,x6,0
    1d86:	0901                	addi	x18,x18,0
    1d88:	0004                	0x4
    1d8a:	0301                	addi	x6,x6,0
    1d8c:	0902                	c.slli64	x18
    1d8e:	0004                	0x4
    1d90:	0301                	addi	x6,x6,0
    1d92:	0901                	addi	x18,x18,0
    1d94:	0004                	0x4
    1d96:	0301                	addi	x6,x6,0
    1d98:	0901                	addi	x18,x18,0
    1d9a:	0004                	0x4
    1d9c:	0301                	addi	x6,x6,0
    1d9e:	0902                	c.slli64	x18
    1da0:	0004                	0x4
    1da2:	0301                	addi	x6,x6,0
    1da4:	0901                	addi	x18,x18,0
    1da6:	0004                	0x4
    1da8:	0301                	addi	x6,x6,0
    1daa:	0901                	addi	x18,x18,0
    1dac:	0004                	0x4
    1dae:	0301                	addi	x6,x6,0
    1db0:	0902                	c.slli64	x18
    1db2:	0004                	0x4
    1db4:	0301                	addi	x6,x6,0
    1db6:	0901                	addi	x18,x18,0
    1db8:	0004                	0x4
    1dba:	0301                	addi	x6,x6,0
    1dbc:	0901                	addi	x18,x18,0
    1dbe:	0004                	0x4
    1dc0:	0301                	addi	x6,x6,0
    1dc2:	0902                	c.slli64	x18
    1dc4:	0004                	0x4
    1dc6:	0301                	addi	x6,x6,0
    1dc8:	0901                	addi	x18,x18,0
    1dca:	0004                	0x4
    1dcc:	0301                	addi	x6,x6,0
    1dce:	0901                	addi	x18,x18,0
    1dd0:	0004                	0x4
    1dd2:	0301                	addi	x6,x6,0
    1dd4:	0902                	c.slli64	x18
    1dd6:	0004                	0x4
    1dd8:	0301                	addi	x6,x6,0
    1dda:	0901                	addi	x18,x18,0
    1ddc:	0004                	0x4
    1dde:	0301                	addi	x6,x6,0
    1de0:	0901                	addi	x18,x18,0
    1de2:	0004                	0x4
    1de4:	0301                	addi	x6,x6,0
    1de6:	0902                	c.slli64	x18
    1de8:	0004                	0x4
    1dea:	0301                	addi	x6,x6,0
    1dec:	0901                	addi	x18,x18,0
    1dee:	0004                	0x4
    1df0:	0301                	addi	x6,x6,0
    1df2:	0901                	addi	x18,x18,0
    1df4:	0004                	0x4
    1df6:	0301                	addi	x6,x6,0
    1df8:	0902                	c.slli64	x18
    1dfa:	0004                	0x4
    1dfc:	0301                	addi	x6,x6,0
    1dfe:	0901                	addi	x18,x18,0
    1e00:	0004                	0x4
    1e02:	0301                	addi	x6,x6,0
    1e04:	0901                	addi	x18,x18,0
    1e06:	0004                	0x4
    1e08:	0301                	addi	x6,x6,0
    1e0a:	0902                	c.slli64	x18
    1e0c:	0004                	0x4
    1e0e:	0301                	addi	x6,x6,0
    1e10:	0901                	addi	x18,x18,0
    1e12:	0004                	0x4
    1e14:	0301                	addi	x6,x6,0
    1e16:	0901                	addi	x18,x18,0
    1e18:	0004                	0x4
    1e1a:	0301                	addi	x6,x6,0
    1e1c:	0902                	c.slli64	x18
    1e1e:	0004                	0x4
    1e20:	0301                	addi	x6,x6,0
    1e22:	0901                	addi	x18,x18,0
    1e24:	0004                	0x4
    1e26:	0301                	addi	x6,x6,0
    1e28:	0901                	addi	x18,x18,0
    1e2a:	0004                	0x4
    1e2c:	0301                	addi	x6,x6,0
    1e2e:	0902                	c.slli64	x18
    1e30:	0004                	0x4
    1e32:	0301                	addi	x6,x6,0
    1e34:	0901                	addi	x18,x18,0
    1e36:	0004                	0x4
    1e38:	0301                	addi	x6,x6,0
    1e3a:	0901                	addi	x18,x18,0
    1e3c:	0004                	0x4
    1e3e:	0301                	addi	x6,x6,0
    1e40:	0902                	c.slli64	x18
    1e42:	0004                	0x4
    1e44:	0301                	addi	x6,x6,0
    1e46:	0901                	addi	x18,x18,0
    1e48:	0004                	0x4
    1e4a:	0301                	addi	x6,x6,0
    1e4c:	0901                	addi	x18,x18,0
    1e4e:	0004                	0x4
    1e50:	0301                	addi	x6,x6,0
    1e52:	0902                	c.slli64	x18
    1e54:	0004                	0x4
    1e56:	0301                	addi	x6,x6,0
    1e58:	0901                	addi	x18,x18,0
    1e5a:	0004                	0x4
    1e5c:	0301                	addi	x6,x6,0
    1e5e:	0901                	addi	x18,x18,0
    1e60:	0004                	0x4
    1e62:	0301                	addi	x6,x6,0
    1e64:	0902                	c.slli64	x18
    1e66:	0004                	0x4
    1e68:	0301                	addi	x6,x6,0
    1e6a:	0901                	addi	x18,x18,0
    1e6c:	0004                	0x4
    1e6e:	0301                	addi	x6,x6,0
    1e70:	0901                	addi	x18,x18,0
    1e72:	0004                	0x4
    1e74:	0301                	addi	x6,x6,0
    1e76:	0902                	c.slli64	x18
    1e78:	0004                	0x4
    1e7a:	0301                	addi	x6,x6,0
    1e7c:	0901                	addi	x18,x18,0
    1e7e:	0004                	0x4
    1e80:	0301                	addi	x6,x6,0
    1e82:	0901                	addi	x18,x18,0
    1e84:	0004                	0x4
    1e86:	0301                	addi	x6,x6,0
    1e88:	0902                	c.slli64	x18
    1e8a:	0004                	0x4
    1e8c:	0301                	addi	x6,x6,0
    1e8e:	0901                	addi	x18,x18,0
    1e90:	0004                	0x4
    1e92:	0301                	addi	x6,x6,0
    1e94:	0901                	addi	x18,x18,0
    1e96:	0004                	0x4
    1e98:	0301                	addi	x6,x6,0
    1e9a:	0902                	c.slli64	x18
    1e9c:	0004                	0x4
    1e9e:	0301                	addi	x6,x6,0
    1ea0:	0901                	addi	x18,x18,0
    1ea2:	0004                	0x4
    1ea4:	0301                	addi	x6,x6,0
    1ea6:	0901                	addi	x18,x18,0
    1ea8:	0004                	0x4
    1eaa:	0301                	addi	x6,x6,0
    1eac:	0902                	c.slli64	x18
    1eae:	0004                	0x4
    1eb0:	0301                	addi	x6,x6,0
    1eb2:	0901                	addi	x18,x18,0
    1eb4:	0004                	0x4
    1eb6:	0301                	addi	x6,x6,0
    1eb8:	0901                	addi	x18,x18,0
    1eba:	0004                	0x4
    1ebc:	0301                	addi	x6,x6,0
    1ebe:	0902                	c.slli64	x18
    1ec0:	0004                	0x4
    1ec2:	0301                	addi	x6,x6,0
    1ec4:	0901                	addi	x18,x18,0
    1ec6:	0004                	0x4
    1ec8:	0301                	addi	x6,x6,0
    1eca:	0901                	addi	x18,x18,0
    1ecc:	0004                	0x4
    1ece:	0301                	addi	x6,x6,0
    1ed0:	0902                	c.slli64	x18
    1ed2:	0004                	0x4
    1ed4:	0301                	addi	x6,x6,0
    1ed6:	0901                	addi	x18,x18,0
    1ed8:	0004                	0x4
    1eda:	0301                	addi	x6,x6,0
    1edc:	0901                	addi	x18,x18,0
    1ede:	0004                	0x4
    1ee0:	0301                	addi	x6,x6,0
    1ee2:	0902                	c.slli64	x18
    1ee4:	0004                	0x4
    1ee6:	0301                	addi	x6,x6,0
    1ee8:	0901                	addi	x18,x18,0
    1eea:	0004                	0x4
    1eec:	0301                	addi	x6,x6,0
    1eee:	0901                	addi	x18,x18,0
    1ef0:	0004                	0x4
    1ef2:	0301                	addi	x6,x6,0
    1ef4:	0902                	c.slli64	x18
    1ef6:	0004                	0x4
    1ef8:	0301                	addi	x6,x6,0
    1efa:	0901                	addi	x18,x18,0
    1efc:	0004                	0x4
    1efe:	0301                	addi	x6,x6,0
    1f00:	0901                	addi	x18,x18,0
    1f02:	0004                	0x4
    1f04:	0301                	addi	x6,x6,0
    1f06:	0902                	c.slli64	x18
    1f08:	0004                	0x4
    1f0a:	0301                	addi	x6,x6,0
    1f0c:	0901                	addi	x18,x18,0
    1f0e:	0004                	0x4
    1f10:	0301                	addi	x6,x6,0
    1f12:	0901                	addi	x18,x18,0
    1f14:	0004                	0x4
    1f16:	0301                	addi	x6,x6,0
    1f18:	0902                	c.slli64	x18
    1f1a:	0004                	0x4
    1f1c:	0301                	addi	x6,x6,0
    1f1e:	0901                	addi	x18,x18,0
    1f20:	0004                	0x4
    1f22:	0301                	addi	x6,x6,0
    1f24:	0901                	addi	x18,x18,0
    1f26:	0004                	0x4
    1f28:	0301                	addi	x6,x6,0
    1f2a:	0902                	c.slli64	x18
    1f2c:	0004                	0x4
    1f2e:	0301                	addi	x6,x6,0
    1f30:	0901                	addi	x18,x18,0
    1f32:	0004                	0x4
    1f34:	0301                	addi	x6,x6,0
    1f36:	0901                	addi	x18,x18,0
    1f38:	0004                	0x4
    1f3a:	0301                	addi	x6,x6,0
    1f3c:	0902                	c.slli64	x18
    1f3e:	0004                	0x4
    1f40:	0501                	addi	x10,x10,0
    1f42:	0308                	addi	x10,x2,384
    1f44:	0902                	c.slli64	x18
    1f46:	0004                	0x4
    1f48:	0501                	addi	x10,x10,0
    1f4a:	0302                	c.slli64	x6
    1f4c:	00040903          	lb	x18,0(x8)
    1f50:	0501                	addi	x10,x10,0
    1f52:	0300                	addi	x8,x2,384
    1f54:	77de                	flw	f15,244(x2)
    1f56:	1409                	addi	x8,x8,-30
    1f58:	0100                	addi	x8,x2,128
    1f5a:	0104                	addi	x9,x2,128
    1f5c:	1c05                	addi	x24,x24,-31
    1f5e:	030a                	slli	x6,x6,0x2
    1f60:	0000093b          	0x93b
    1f64:	0501                	addi	x10,x10,0
    1f66:	033a                	slli	x6,x6,0xe
    1f68:	0901                	addi	x18,x18,0
    1f6a:	0008                	0x8
    1f6c:	0501                	addi	x10,x10,0
    1f6e:	0321                	addi	x6,x6,8
    1f70:	090c                	addi	x11,x2,144
    1f72:	0004                	0x4
    1f74:	0501                	addi	x10,x10,0
    1f76:	0316                	slli	x6,x6,0x5
    1f78:	0902                	c.slli64	x18
    1f7a:	0004                	0x4
    1f7c:	0501                	addi	x10,x10,0
    1f7e:	031c                	addi	x15,x2,384
    1f80:	00c6                	slli	x1,x1,0x11
    1f82:	0409                	addi	x8,x8,2
    1f84:	0100                	addi	x8,x2,128
    1f86:	3a05                	jal	18b6 <_bsg_elf_stack_ptr+0x8ba>
    1f88:	04090103          	lb	x2,64(x18)
    1f8c:	0100                	addi	x8,x2,128
    1f8e:	2105                	jal	23ae <_bsg_elf_stack_ptr+0x13b2>
    1f90:	04090c03          	lb	x24,64(x18)
    1f94:	0100                	addi	x8,x2,128
    1f96:	1605                	addi	x12,x12,-31
    1f98:	04090203          	lb	x4,64(x18)
    1f9c:	0100                	addi	x8,x2,128
    1f9e:	2105                	jal	23be <_bsg_elf_stack_ptr+0x13c2>
    1fa0:	097fa903          	lw	x18,151(x31)
    1fa4:	0004                	0x4
    1fa6:	0501                	addi	x10,x10,0
    1fa8:	0316                	slli	x6,x6,0x5
    1faa:	0902                	c.slli64	x18
    1fac:	0004                	0x4
    1fae:	0501                	addi	x10,x10,0
    1fb0:	0321                	addi	x6,x6,8
    1fb2:	040900d3          	0x40900d3
    1fb6:	0100                	addi	x8,x2,128
    1fb8:	1605                	addi	x12,x12,-31
    1fba:	04090203          	lb	x4,64(x18)
    1fbe:	0100                	addi	x8,x2,128
    1fc0:	0809                	addi	x16,x16,2
    1fc2:	0000                	unimp
    1fc4:	0101                	addi	x2,x2,0

Disassembly of section .debug_info:

00000000 <.debug_info>:
  li  x1, 0
   0:	0022                	c.slli	x0,0x8
   2:	0000                	unimp
  li  x3, 0
   4:	0002                	c.slli64	x0
   6:	0000                	unimp
  li  x4, 0
   8:	0000                	unimp
   a:	0104                	addi	x9,x2,128
	...
  li  x7, 0
  14:	0128                	addi	x10,x2,136
  16:	0000                	unimp
  li  x8, 0
  18:	0000                	unimp
  1a:	0000                	unimp
  li  x9, 0
  1c:	0071                	c.nop	28
  1e:	0000                	unimp
  li  x10,0
  20:	00e2                	slli	x1,x1,0x18
  22:	0000                	unimp
  li  x11,0
  24:	8001                	c.srli64	x8
  26:	0000014b          	fnmsub.s	f2,f0,f0,f0,rne
  li  x12,0
  2a:	0004                	0x4
  li  x13,0
  2c:	0014                	0x14
  2e:	0000                	unimp
  li  x14,0
  30:	0104                	addi	x9,x2,128
  32:	0101                	addi	x2,x2,0
  li  x15,0
  34:	0000                	unimp
  36:	530c                	lw	x11,32(x14)
  li  x16,0
  38:	0002                	c.slli64	x0
  3a:	7100                	flw	f8,32(x10)
  li  x17,0
  3c:	0000                	unimp
  3e:	2800                	fld	f8,16(x8)
  li  x18,0
  40:	0001                	nop
  42:	a000                	fsd	f8,0(x8)
  li  x19,0
  44:	0000                	unimp
  46:	4b00                	lw	x8,16(x14)
  li  x20,0
  48:	0002                	c.slli64	x0
  4a:	0200                	addi	x8,x2,256
  li  x21,0
  4c:	021f 0000 1403      	0x14030000021f
  li  x22,0
  52:	3119                	jal	fffffc58 <_bsg_dram_end_addr+0x7efffc58>
  li  x23,0
  54:	0000                	unimp
  56:	0300                	addi	x8,x2,384
  li  x24,0
  58:	3e04                	fld	f9,56(x12)
  5a:	0000                	unimp
  li  x25,0
  5c:	0400                	addi	x8,x2,512
  5e:	0504                	addi	x9,x2,640
  li  x26,0
  60:	6e69                	lui	x28,0x1a
  62:	0074                	addi	x13,x2,12
  li  x27,0
  64:	3705                	jal	ffffff84 <_bsg_dram_end_addr+0x7effff84>
  66:	0000                	unimp
  li  x28,0
  68:	0600                	addi	x8,x2,768
  6a:	0404                	addi	x9,x2,512
  li  x29,0
  6c:	0305                	addi	x6,x6,1
  6e:	0000                	unimp
  li  x30,0
  70:	0106                	slli	x2,x2,0x1
  72:	f508                	fsw	f10,40(x10)
  li  x31,0
  74:	0001                	nop
  76:	0600                	addi	x8,x2,768
  li t0, 0x00003000 # mstatus.FS
  78:	0702                	c.slli64	x14
  7a:	00ee                	slli	x1,x1,0x1b
  csrs mstatus, t0 # enable FPU
  7c:	0000                	unimp
  7e:	0406                	slli	x8,x8,0x1
  fscsr x0
  80:	0004e907          	0x4e907
  li t0, 0
  84:	0700                	addi	x8,x2,896
  86:	0000024b          	fnmsub.s	f4,f0,f0,f0,rne
  fcvt.s.w f0, x0 
  8a:	1602                	slli	x12,x12,0x20
  fcvt.s.w f1, x0 
  8c:	370c                	fld	f11,40(x14)
  8e:	0000                	unimp
  fcvt.s.w f2, x0 
  90:	0700                	addi	x8,x2,896
  92:	01b9                	addi	x3,x3,14
  fcvt.s.w f3, x0 
  94:	0000                	unimp
  96:	1702                	slli	x14,x14,0x20
  fcvt.s.w f4, x0 
  98:	370c                	fld	f11,40(x14)
  9a:	0000                	unimp
  fcvt.s.w f5, x0 
  9c:	0700                	addi	x8,x2,896
  9e:	01b0                	addi	x12,x2,200
  fcvt.s.w f6, x0 
  a0:	0000                	unimp
  a2:	1802                	slli	x16,x16,0x20
  fcvt.s.w f7, x0 
  a4:	370c                	fld	f11,40(x14)
  a6:	0000                	unimp
  fcvt.s.w f8, x0 
  a8:	0700                	addi	x8,x2,896
  aa:	0000020f          	0x20f
  fcvt.s.w f9, x0 
  ae:	1902                	slli	x18,x18,0x20
  fcvt.s.w f10,x0 
  b0:	370c                	fld	f11,40(x14)
  b2:	0000                	unimp
  fcvt.s.w f11,x0 
  b4:	0700                	addi	x8,x2,896
  b6:	0000030b          	0x30b
  fcvt.s.w f12,x0 
  ba:	1a02                	slli	x20,x20,0x20
  fcvt.s.w f13,x0 
  bc:	370c                	fld	f11,40(x14)
  be:	0000                	unimp
  fcvt.s.w f14,x0 
  c0:	0700                	addi	x8,x2,896
  c2:	02d4                	addi	x13,x2,324
  fcvt.s.w f15,x0 
  c4:	0000                	unimp
  c6:	1b02                	slli	x22,x22,0x20
  fcvt.s.w f16,x0 
  c8:	370c                	fld	f11,40(x14)
  ca:	0000                	unimp
  fcvt.s.w f17,x0 
  cc:	0700                	addi	x8,x2,896
  ce:	0000031b          	0x31b
  fcvt.s.w f18,x0 
  d2:	1c02                	slli	x24,x24,0x20
  fcvt.s.w f19,x0 
  d4:	370c                	fld	f11,40(x14)
  d6:	0000                	unimp
  fcvt.s.w f20,x0 
  d8:	0700                	addi	x8,x2,896
  da:	01c9                	addi	x3,x3,18
  fcvt.s.w f21,x0 
  dc:	0000                	unimp
  de:	1d02                	slli	x26,x26,0x20
  fcvt.s.w f22,x0 
  e0:	370c                	fld	f11,40(x14)
  e2:	0000                	unimp
  fcvt.s.w f23,x0 
  e4:	0700                	addi	x8,x2,896
  e6:	01df 0000 1e02      	0x1e02000001df
  fcvt.s.w f25,x0 
  ec:	370c                	fld	f11,40(x14)
  ee:	0000                	unimp
  fcvt.s.w f26,x0 
  f0:	0700                	addi	x8,x2,896
  f2:	02f1                	addi	x5,x5,28
  fcvt.s.w f27,x0 
  f4:	0000                	unimp
  f6:	1f02                	slli	x30,x30,0x20
  fcvt.s.w f28,x0 
  f8:	370c                	fld	f11,40(x14)
  fa:	0000                	unimp
  fcvt.s.w f29,x0 
  fc:	0800                	addi	x8,x2,16
  fe:	023a                	slli	x4,x4,0xe
  fcvt.s.w f30,x0 
 100:	0000                	unimp
 102:	0501                	addi	x10,x10,0
  fcvt.s.w f31,x0 
 104:	2806                	fld	f16,64(x2)
 106:	0001                	nop
  la gp, _gp
 108:	a000                	fsd	f8,0(x8)
 10a:	0000                	unimp
 10c:	0100                	addi	x8,x2,128
 10e:	099c                	addi	x15,x2,208
  la  tp, _bsg_data_end_addr + 63
 110:	0232                	slli	x4,x4,0xc
 112:	0000                	unimp
 114:	0701                	addi	x14,x14,0
 116:	3111                	jal	fffffd1a <_bsg_dram_end_addr+0x7efffd1a>
  and tp, tp, -64
 118:	0000                	unimp
 11a:	0900                	addi	x8,x2,144
  la sp, _sp
 11c:	01c1                	addi	x3,x3,16
 11e:	0000                	unimp
 120:	0801                	addi	x16,x16,0
 122:	3111                	jal	fffffd26 <_bsg_dram_end_addr+0x7efffd26>
  j main
 124:	0000                	unimp
 126:	0a00                	addi	x8,x2,272
  bsg_remote_store(0,0,bsg_x_v,0);
 128:	00000203          	lb	x4,0(x0) # 0 <_bsg_data_start_addr>
 12c:	0a01                	addi	x20,x20,0
 12e:	2516                	fld	f10,320(x2)
 130:	0000                	unimp
 132:	0100                	addi	x8,x2,128
  bsg_remote_store(0,0,bsg_y_v,0);
 134:	0a5d                	addi	x20,x20,23
 136:	02e5                	addi	x5,x5,25
  bsg_remote_store(0,0,bsg_x_v,0);
 138:	0000                	unimp
 13a:	0b01                	addi	x22,x22,0
  bsg_remote_store(0,0,bsg_y_v,0);
 13c:	2516                	fld	f10,320(x2)
 13e:	0000                	unimp
 140:	0100                	addi	x8,x2,128
 142:	0b56                	slli	x22,x22,0x15
  bsg_wait_while(*bsg_x_v < 0);
 144:	0164                	addi	x9,x2,140
 146:	0000                	unimp
 148:	0008                	0x8
 14a:	0000                	unimp
  bsg_wait_while(*bsg_y_v < 0);
 14c:	780c                	flw	f11,48(x8)
 14e:	0100                	addi	x8,x2,128
 150:	0e15                	addi	x28,x28,5
 152:	00000037          	lui	x0,0x0
  if (!*bsg_x_v && !*bsg_y_v)
 156:	0000                	unimp
 158:	0000                	unimp
 15a:	0001640b          	0x1640b
 15e:	0800                	addi	x8,x2,16
 160:	0000                	unimp
 162:	0c00                	addi	x8,x2,528
        bsg_remote_store(x,y,bsg_x_v,x);
 164:	0079                	c.nop	30
 166:	1601                	addi	x12,x12,-32
        bsg_remote_store(x,y,bsg_y_v,y);
 168:	3710                	fld	f12,40(x14)
	...
  grp_org_x_p = bsg_remote_ptr_control( __bsg_x, __bsg_y, CSR_TGO_X );
 172:	0000                	unimp
 174:	d500                	sw	x8,40(x10)
 176:	0000                	unimp
 178:	0400                	addi	x8,x2,512
 17a:	c200                	sw	x8,0(x12)
 17c:	0000                	unimp
 17e:	0400                	addi	x8,x2,512
 180:	0101                	addi	x2,x2,0
 182:	0001                	nop
 184:	0c00                	addi	x8,x2,528
 186:	032c                	addi	x11,x2,392
 188:	0000                	unimp
 18a:	0071                	c.nop	28
  __bsg_grp_org_x  = * grp_org_x_p;
 18c:	0000                	unimp
 18e:	00000587          	0x587
  grp_org_y_p = bsg_remote_ptr_control( __bsg_x, __bsg_y, CSR_TGO_Y );
 192:	4b02                	lw	x22,0(x2)
 194:	0002                	c.slli64	x0
 196:	0100                	addi	x8,x2,128
  __bsg_grp_org_x  = * grp_org_x_p;
 198:	0512                	slli	x10,x10,0x4
 19a:	0000002f          	0x2f
  __bsg_grp_org_y  = * grp_org_y_p;
 19e:	0305                	addi	x6,x6,1
  __bsg_id = __bsg_y * bsg_tiles_X + __bsg_x;
 1a0:	002c                	addi	x11,x2,8
 1a2:	0000                	unimp
  __bsg_grid_dim_x = 1;
 1a4:	69050403          	lb	x8,1680(x10) # 1a690 <_bsg_elf_stack_ptr+0x19694>
  __bsg_grp_org_y  = * grp_org_y_p;
 1a8:	746e                	flw	f8,248(x2)
 1aa:	0200                	addi	x8,x2,256
  __bsg_id = __bsg_y * bsg_tiles_X + __bsg_x;
 1ac:	01b9                	addi	x3,x3,14
 1ae:	0000                	unimp
  __bsg_grid_dim_x = 1;
 1b0:	1301                	addi	x6,x6,-32
 1b2:	2f05                	jal	8e2 <_gp+0xda>
  __bsg_grid_dim_y = 1;
 1b4:	0000                	unimp
 1b6:	0500                	addi	x8,x2,640
  __bsg_tile_group_id_x = 0;
 1b8:	00002803          	lw	x16,0(x0) # 0 <_bsg_data_start_addr>
  __bsg_tile_group_id_y = 0;
 1bc:	0200                	addi	x8,x2,256
 1be:	01b0                	addi	x12,x2,200
  __bsg_tile_group_id = 0;
 1c0:	0000                	unimp
 1c2:	1401                	addi	x8,x8,-32
}
 1c4:	2f05                	jal	8f4 <_gp+0xec>
 1c6:	0000                	unimp
  if (__bsg_id == 0) 
 1c8:	0500                	addi	x8,x2,640
 1ca:	00002403          	lw	x8,0(x0) # 0 <_bsg_data_start_addr>
 1ce:	0200                	addi	x8,x2,256
     *signal_ptr = cuda_finish_signal_val;     
 1d0:	0000020f          	0x20f
 1d4:	1501                	addi	x10,x10,-32
 1d6:	2f05                	jal	906 <_gp+0xfe>
 1d8:	0000                	unimp
 1da:	0500                	addi	x8,x2,640
}
 1dc:	00002003          	lw	x0,0(x0) # 0 <_bsg_data_start_addr>
int kernel_energy_fadd_demo(float *A, float *B, float *C, int N) {
 1e0:	0200                	addi	x8,x2,256
 1e2:	0000030b          	0x30b
 1e6:	1601                	addi	x12,x12,-32
 1e8:	2f05                	jal	918 <_gp+0x110>
 1ea:	0000                	unimp
 1ec:	0500                	addi	x8,x2,640
 1ee:	00001c03          	lh	x24,0(x0) # 0 <_bsg_data_start_addr>
 1f2:	0200                	addi	x8,x2,256
    asm volatile("flw     %0,    0(%1)"   : "=f"(A_tmp) : "r"(A)     : "memory");
 1f4:	02d4                	addi	x13,x2,324
 1f6:	0000                	unimp
 1f8:	1701                	addi	x14,x14,-32
 1fa:	2f05                	jal	92a <_gp+0x122>
 1fc:	0000                	unimp
 1fe:	0500                	addi	x8,x2,640
 200:	00001803          	lh	x16,0(x0) # 0 <_bsg_data_start_addr>
    asm volatile("fsw     %0,    0(%1)"   :: "f"(A_tmp) , "r"(A_ptr) : "memory");
 204:	0200                	addi	x8,x2,256
 206:	0000031b          	0x31b
    asm volatile("flw     %0,    0(%1)"   : "=f"(B_tmp) : "r"(B)     : "memory");
 20a:	1801                	addi	x16,x16,-32
    asm volatile("flw     %0,    0(%1)"   : "=f"(A_tmp) : "r"(A)     : "memory");
 20c:	2f05                	jal	93c <_gp+0x134>
 20e:	0000                	unimp
    asm volatile("fsw     %0,    0(%1)"   :: "f"(B_tmp) , "r"(B_ptr) : "memory");
 210:	0500                	addi	x8,x2,640
 212:	00001403          	lh	x8,0(x0) # 0 <_bsg_data_start_addr>
  for(uint32_t i = 0; i < 255; i++) {
 216:	0200                	addi	x8,x2,256
 218:	01c9                	addi	x3,x3,18
 21a:	0000                	unimp
  bsg_saif_start();
 21c:	1901                	addi	x18,x18,-32
 21e:	2f05                	jal	94e <_gp+0x146>
  asm volatile("flw     %0,    0(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 220:	0000                	unimp
 222:	0500                	addi	x8,x2,640
  asm volatile("flw     %0,    0(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 224:	00001003          	lh	x0,0(x0) # 0 <_bsg_data_start_addr>
 228:	0200                	addi	x8,x2,256
 22a:	01df 0000 1a01      	0x1a01000001df
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 230:	2f05                	jal	960 <_gp+0x158>
 232:	0000                	unimp
  asm volatile("flw     %0,    4(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 234:	0500                	addi	x8,x2,640
 236:	00000c03          	lb	x24,0(x0) # 0 <_bsg_data_start_addr>
  asm volatile("flw     %0,    4(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 23a:	0200                	addi	x8,x2,256
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 23c:	02f1                	addi	x5,x5,28
 23e:	0000                	unimp
  asm volatile("flw     %0,    8(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 240:	1b01                	addi	x22,x22,-32
 242:	2f05                	jal	972 <_gp+0x16a>
  asm volatile("flw     %0,    8(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 244:	0000                	unimp
 246:	0500                	addi	x8,x2,640
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 248:	00000803          	lb	x16,0(x0) # 0 <_bsg_data_start_addr>
  asm volatile("flw     %0,   12(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 24c:	0000                	unimp
 24e:	0235                	addi	x4,x4,13
  asm volatile("flw     %0,   12(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 250:	0000                	unimp
 252:	0004                	0x4
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 254:	00f0                	addi	x12,x2,76
 256:	0000                	unimp
  asm volatile("flw     %0,   16(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 258:	0104                	addi	x9,x2,128
 25a:	0101                	addi	x2,x2,0
  asm volatile("flw     %0,   16(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 25c:	0000                	unimp
 25e:	3f0c                	fld	f11,56(x14)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 260:	0004                	0x4
 262:	7100                	flw	f8,32(x10)
	...
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 26c:	0000                	unimp
 26e:	2c00                	fld	f8,24(x8)
  asm volatile("flw     %0,   24(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 270:	0006                	c.slli	x0,0x1
 272:	0200                	addi	x8,x2,256
  asm volatile("flw     %0,   24(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 274:	0504                	addi	x9,x2,640
 276:	6e69                	lui	x28,0x1a
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 278:	0074                	addi	x13,x2,12
 27a:	05040403          	lb	x8,80(x8)
  asm volatile("flw     %0,   28(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 27e:	03000003          	lb	x0,48(x0) # 30 <__bsg_x+0x4>
  asm volatile("flw     %0,   28(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 282:	0801                	addi	x16,x16,0
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 284:	01f5                	addi	x3,x3,29
 286:	0000                	unimp
  asm volatile("flw     %0,   32(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 288:	ee070203          	lb	x4,-288(x14) # 1dee0 <_bsg_elf_stack_ptr+0x1cee4>
  asm volatile("flw     %0,   32(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 28c:	0000                	unimp
 28e:	0300                	addi	x8,x2,384
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 290:	0704                	addi	x9,x2,896
 292:	04e9                	addi	x9,x9,26
  asm volatile("flw     %0,   36(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 294:	0000                	unimp
 296:	4b04                	lw	x9,16(x14)
  asm volatile("flw     %0,   36(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 298:	0002                	c.slli64	x0
 29a:	0300                	addi	x8,x2,384
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 29c:	0c16                	slli	x24,x24,0x5
 29e:	0025                	c.nop	9
  asm volatile("flw     %0,   40(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2a0:	0000                	unimp
 2a2:	b904                	fsd	f9,48(x10)
  asm volatile("flw     %0,   40(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2a4:	0001                	nop
 2a6:	0300                	addi	x8,x2,384
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2a8:	00250c17          	auipc	x24,0x250
  asm volatile("flw     %0,   44(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2ac:	0000                	unimp
 2ae:	b004                	fsd	f9,32(x8)
  asm volatile("flw     %0,   44(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2b0:	0001                	nop
 2b2:	0300                	addi	x8,x2,384
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2b4:	0c18                	addi	x14,x2,528
 2b6:	0025                	c.nop	9
  asm volatile("flw     %0,   48(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2b8:	0000                	unimp
 2ba:	0f04                	addi	x9,x2,912
  asm volatile("flw     %0,   48(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2bc:	0002                	c.slli64	x0
 2be:	0300                	addi	x8,x2,384
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2c0:	0c19                	addi	x24,x24,6
 2c2:	0025                	c.nop	9
  asm volatile("flw     %0,   52(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2c4:	0000                	unimp
 2c6:	0b04                	addi	x9,x2,400
  asm volatile("flw     %0,   52(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2c8:	03000003          	lb	x0,48(x0) # 30 <__bsg_x+0x4>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2cc:	0c1a                	slli	x24,x24,0x6
 2ce:	0025                	c.nop	9
  asm volatile("flw     %0,   56(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2d0:	0000                	unimp
 2d2:	d404                	sw	x9,40(x8)
  asm volatile("flw     %0,   56(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2d4:	0002                	c.slli64	x0
 2d6:	0300                	addi	x8,x2,384
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2d8:	00250c1b          	0x250c1b
  asm volatile("flw     %0,   60(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2dc:	0000                	unimp
 2de:	1b04                	addi	x9,x2,432
  asm volatile("flw     %0,   60(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2e0:	03000003          	lb	x0,48(x0) # 30 <__bsg_x+0x4>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2e4:	0c1c                	addi	x15,x2,528
 2e6:	0025                	c.nop	9
  asm volatile("flw     %0,   64(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2e8:	0000                	unimp
 2ea:	c904                	sw	x9,16(x10)
  asm volatile("flw     %0,   64(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2ec:	0001                	nop
 2ee:	0300                	addi	x8,x2,384
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2f0:	0c1d                	addi	x24,x24,7
 2f2:	0025                	c.nop	9
  asm volatile("flw     %0,   68(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2f4:	0000                	unimp
 2f6:	df04                	sw	x9,56(x14)
  asm volatile("flw     %0,   68(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2f8:	0001                	nop
 2fa:	0300                	addi	x8,x2,384
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2fc:	0c1e                	slli	x24,x24,0x7
 2fe:	0025                	c.nop	9
  asm volatile("flw     %0,   72(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 300:	0000                	unimp
 302:	f104                	fsw	f9,32(x10)
  asm volatile("flw     %0,   72(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 304:	0002                	c.slli64	x0
 306:	0300                	addi	x8,x2,384
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 308:	0c1f 0025 0000      	0x250c1f
  asm volatile("flw     %0,   76(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 30e:	f7060103          	lb	x2,-144(x12) # 1af70 <_bsg_elf_stack_ptr+0x19f74>
  asm volatile("flw     %0,   76(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 312:	0001                	nop
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 314:	0300                	addi	x8,x2,384
 316:	0502                	c.slli64	x10
  asm volatile("flw     %0,   80(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 318:	0435                	addi	x8,x8,13
 31a:	0000                	unimp
  asm volatile("flw     %0,   80(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 31c:	b105                	j	ffffff3c <_bsg_dram_end_addr+0x7effff3c>
 31e:	04000003          	lb	x0,64(x0) # 40 <cuda_finish_signal_val>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 322:	184d                	addi	x16,x16,-13
  asm volatile("flw     %0,   84(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 324:	00da                	slli	x1,x1,0x16
 326:	0000                	unimp
  asm volatile("flw     %0,   84(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 328:	18050403          	lb	x8,384(x10)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 32c:	0004                	0x4
 32e:	0500                	addi	x8,x2,640
  asm volatile("flw     %0,   88(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 330:	00000403          	lb	x8,0(x0) # 0 <_bsg_data_start_addr>
  asm volatile("flw     %0,   88(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 334:	4f04                	lw	x9,24(x14)
 336:	ed19                	bnez	x10,354 <kernel_energy_fadd_demo+0x174>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 338:	0000                	unimp
 33a:	0300                	addi	x8,x2,384
  asm volatile("flw     %0,   92(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 33c:	0704                	addi	x9,x2,896
 33e:	04e4                	addi	x9,x2,588
  asm volatile("flw     %0,   92(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 340:	0000                	unimp
 342:	13050803          	lb	x16,304(x10)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 346:	0004                	0x4
  asm volatile("flw     %0,   96(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 348:	0300                	addi	x8,x2,384
 34a:	0708                	addi	x10,x2,896
  asm volatile("flw     %0,   96(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 34c:	04df 0000 b305      	0xb305000004df
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 352:	05000003          	lb	x0,80(x0) # 50 <cuda_kernel_ptr>
  asm volatile("flw     %0,  100(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 356:	132c                	addi	x11,x2,424
  asm volatile("flw     %0,  100(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 358:	00ce                	slli	x1,x1,0x13
 35a:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 35c:	0505                	addi	x10,x10,1
 35e:	0004                	0x4
  asm volatile("flw     %0,  104(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 360:	0500                	addi	x8,x2,640
 362:	1430                	addi	x12,x2,552
  asm volatile("flw     %0,  104(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 364:	00e1                	addi	x1,x1,24
 366:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 368:	c506                	sw	x1,136(x2)
 36a:	0004                	0x4
  asm volatile("flw     %0,  108(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 36c:	0100                	addi	x8,x2,128
 36e:	0918                	addi	x14,x2,144
  asm volatile("flw     %0,  108(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 370:	0102                	c.slli64	x2
 372:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 374:	0305                	addi	x6,x6,1
 376:	0050                	addi	x12,x2,4
  asm volatile("flw     %0,  112(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 378:	0000                	unimp
 37a:	d506                	sw	x1,168(x2)
  asm volatile("flw     %0,  112(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 37c:	0004                	0x4
 37e:	0100                	addi	x8,x2,128
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 380:	0a1a                	slli	x20,x20,0x6
 382:	010e                	slli	x2,x2,0x3
  asm volatile("flw     %0,  116(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 384:	0000                	unimp
 386:	0305                	addi	x6,x6,1
  asm volatile("flw     %0,  116(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 388:	004c                	addi	x11,x2,4
 38a:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 38c:	d306                	sw	x1,164(x2)
 38e:	01000003          	lb	x0,16(x0) # 10 <__bsg_tile_group_id_x>
  asm volatile("flw     %0,  120(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 392:	0a1c                	addi	x15,x2,272
  asm volatile("flw     %0,  120(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 394:	010e                	slli	x2,x2,0x3
 396:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 398:	0305                	addi	x6,x6,1
 39a:	0048                	addi	x10,x2,4
  asm volatile("flw     %0,  124(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 39c:	0000                	unimp
 39e:	bb06                	fsd	f1,432(x2)
  asm volatile("flw     %0,  124(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 3a0:	01000003          	lb	x0,16(x0) # 10 <__bsg_tile_group_id_x>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 3a4:	0a1e                	slli	x20,x20,0x7
 3a6:	010e                	slli	x2,x2,0x3
  asm volatile("flw     %0,  128(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 3a8:	0000                	unimp
 3aa:	0305                	addi	x6,x6,1
  asm volatile("flw     %0,  128(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 3ac:	0044                	addi	x9,x2,4
 3ae:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 3b0:	e106                	fsw	f1,128(x2)
 3b2:	01000003          	lb	x0,16(x0) # 10 <__bsg_tile_group_id_x>
  asm volatile("flw     %0,  132(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 3b6:	0a20                	addi	x8,x2,280
  asm volatile("flw     %0,  132(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 3b8:	010e                	slli	x2,x2,0x3
 3ba:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 3bc:	0305                	addi	x6,x6,1
 3be:	0040                	addi	x8,x2,4
  asm volatile("flw     %0,  136(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 3c0:	0000                	unimp
 3c2:	f606                	fsw	f1,44(x2)
  asm volatile("flw     %0,  136(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 3c4:	0004                	0x4
 3c6:	0100                	addi	x8,x2,128
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 3c8:	0a22                	slli	x20,x20,0x8
 3ca:	010e                	slli	x2,x2,0x3
  asm volatile("flw     %0,  140(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 3cc:	0000                	unimp
 3ce:	0305                	addi	x6,x6,1
  asm volatile("flw     %0,  140(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 3d0:	003c                	addi	x15,x2,8
 3d2:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 3d4:	00040e07          	0x40e07
  asm volatile("flw     %0,  144(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 3d8:	0200                	addi	x8,x2,256
 3da:	0506                	slli	x10,x10,0x1
  asm volatile("flw     %0,  144(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 3dc:	0025                	c.nop	9
 3de:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 3e0:	0e70                	addi	x12,x2,796
 3e2:	0000                	unimp
  asm volatile("flw     %0,  148(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 3e4:	00d4                	addi	x13,x2,68
 3e6:	0000                	unimp
  asm volatile("flw     %0,  148(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 3e8:	9c01                	0x9c01
 3ea:	01da                	slli	x3,x3,0x16
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 3ec:	0000                	unimp
 3ee:	da08                	sw	x10,48(x12)
  asm volatile("flw     %0,  152(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 3f0:	0001                	nop
 3f2:	2400                	fld	f8,8(x8)
  asm volatile("flw     %0,  152(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 3f4:	1400000f          	0x1400000f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 3f8:	0000                	unimp
 3fa:	0200                	addi	x8,x2,256
  asm volatile("flw     %0,  156(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 3fc:	0908                	addi	x10,x2,144
 3fe:	da08                	sw	x10,48(x12)
  asm volatile("flw     %0,  156(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 400:	0001                	nop
 402:	2c00                	fld	f8,24(x8)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 404:	0c00000f          	fence	io,unknown
  asm volatile("flw     %0,  160(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 408:	0000                	unimp
 40a:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,  160(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 40c:	0544                	addi	x9,x2,644
 40e:	eb09                	bnez	x14,420 <kernel_energy_fadd_demo+0x240>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 410:	0001                	nop
 412:	2c00                	fld	f8,24(x8)
  asm volatile("flw     %0,  164(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 414:	0c00000f          	fence	io,unknown
  asm volatile("flw     %0,  164(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 418:	0000                	unimp
 41a:	0a00                	addi	x8,x2,272
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 41c:	01ec                	addi	x11,x2,204
 41e:	0000                	unimp
  asm volatile("flw     %0,  168(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 420:	0014                	0x14
 422:	0000                	unimp
  asm volatile("flw     %0,  168(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 424:	0000                	unimp
 426:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 428:	0004210b          	0x4210b
  asm volatile("flw     %0,  172(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 42c:	0100                	addi	x8,x2,128
 42e:	0544                	addi	x9,x2,644
  asm volatile("flw     %0,  172(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 430:	0025                	c.nop	9
 432:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 434:	fa01                	bnez	x12,344 <kernel_energy_fadd_demo+0x164>
 436:	0001                	nop
  asm volatile("flw     %0,  176(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 438:	0c00                	addi	x8,x2,528
 43a:	f80d                	bnez	x8,36c <kernel_energy_fadd_demo+0x18c>
  asm volatile("flw     %0,  176(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 43c:	01000003          	lb	x0,16(x0) # 10 <__bsg_tile_group_id_x>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 440:	0b48                	addi	x10,x2,404
 442:	01fa                	slli	x3,x3,0x1e
  asm volatile("flw     %0,  180(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 444:	0000                	unimp
 446:	0000                	unimp
  asm volatile("flw     %0,  180(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 448:	040e                	slli	x8,x8,0x3
 44a:	0025                	c.nop	9
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 44c:	0000                	unimp
 44e:	0001da0f          	0x1da0f
  asm volatile("flw     %0,  184(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 452:	c800                	sw	x8,16(x8)
  asm volatile("flw     %0,  184(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 454:	0001                	nop
 456:	1800                	addi	x8,x2,48
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 458:	0000                	unimp
 45a:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,  188(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 45c:	089c                	addi	x15,x2,80
 45e:	01da                	slli	x3,x3,0x16
  asm volatile("flw     %0,  188(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 460:	0000                	unimp
 462:	01d0                	addi	x12,x2,196
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 464:	0000                	unimp
 466:	000c                	0xc
  asm volatile("flw     %0,  192(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 468:	0000                	unimp
 46a:	4401                	li	x8,0
  asm volatile("flw     %0,  192(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 46c:	0905                	addi	x18,x18,1
 46e:	000001eb          	0x1eb
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 472:	01d0                	addi	x12,x2,196
  asm volatile("flw     %0,  196(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 474:	0000                	unimp
 476:	000c                	0xc
  asm volatile("flw     %0,  196(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 478:	0000                	unimp
 47a:	ec0a                	fsw	f2,24(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 47c:	0001                	nop
 47e:	2b00                	fld	f8,16(x14)
  asm volatile("flw     %0,  200(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 480:	0000                	unimp
 482:	0000                	unimp
  asm volatile("flw     %0,  200(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 484:	0000                	unimp
 486:	d900                	sw	x8,48(x10)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 488:	04000007          	0x4000007
  asm volatile("flw     %0,  204(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 48c:	d200                	sw	x8,32(x12)
 48e:	0001                	nop
  asm volatile("flw     %0,  204(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 490:	0400                	addi	x8,x2,512
 492:	1101                	addi	x2,x2,-32
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 494:	0005                	c.nop	1
 496:	1a00                	addi	x8,x2,304
  asm volatile("flw     %0,  208(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 498:	2600                	fld	f8,8(x12)
 49a:	000a                	c.slli	x0,0x2
  asm volatile("flw     %0,  208(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 49c:	8e00                	0x8e00
 49e:	0009                	c.nop	2
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 4a0:	7100                	flw	f8,32(x10)
 4a2:	0000                	unimp
  asm volatile("flw     %0,  212(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 4a4:	e000                	fsw	f8,0(x8)
 4a6:	0001                	nop
  asm volatile("flw     %0,  212(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 4a8:	9000                	0x9000
 4aa:	000c                	0xc
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 4ac:	0200                	addi	x8,x2,256
 4ae:	06d4                	addi	x13,x2,836
  asm volatile("flw     %0,  216(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 4b0:	0000                	unimp
 4b2:	00000037          	lui	x0,0x0
  asm volatile("flw     %0,  216(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 4b6:	0702                	c.slli64	x14
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 4b8:	0305                	addi	x6,x6,1
 4ba:	0058                	addi	x14,x2,4
  asm volatile("flw     %0,  220(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 4bc:	0000                	unimp
 4be:	083c0503          	lb	x10,131(x24) # 25032b <_bsg_elf_vcache_size+0x15032b>
  asm volatile("flw     %0,  220(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 4c2:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 4c4:	0110                	addi	x12,x2,128
 4c6:	04e9                	addi	x9,x9,26
  asm volatile("flw     %0,  224(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 4c8:	0000058b          	0x58b
  asm volatile("flw     %0,  224(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 4cc:	00b8                	addi	x14,x2,72
 4ce:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 4d0:	ec01                	bnez	x8,4e8 <kernel_energy_fadd_demo+0x308>
 4d2:	0400                	addi	x8,x2,512
  asm volatile("flw     %0,  228(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 4d4:	06d2                	slli	x13,x13,0x14
 4d6:	0000                	unimp
  asm volatile("flw     %0,  228(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 4d8:	0189                	addi	x3,x3,2
 4da:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 4dc:	ed01                	bnez	x10,4f4 <kernel_energy_fadd_demo+0x314>
 4de:	0508                	addi	x10,x2,640
  asm volatile("flw     %0,  232(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 4e0:	07cd                	addi	x15,x15,19
 4e2:	0000                	unimp
  asm volatile("flw     %0,  232(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 4e4:	022c                	addi	x11,x2,264
 4e6:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 4e8:	ee01                	bnez	x12,500 <kernel_energy_fadd_demo+0x320>
 4ea:	0500                	addi	x8,x2,640
  asm volatile("flw     %0,  236(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 4ec:	07dc                	addi	x15,x2,964
 4ee:	0000                	unimp
  asm volatile("flw     %0,  236(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 4f0:	022c                	addi	x11,x2,264
 4f2:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 4f4:	ef01                	bnez	x14,50c <kernel_energy_fadd_demo+0x32c>
 4f6:	0600                	addi	x8,x2,768
  asm volatile("flw     %0,  240(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 4f8:	000007eb          	0x7eb
  asm volatile("flw     %0,  240(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 4fc:	f401                	bnez	x8,404 <kernel_energy_fadd_demo+0x224>
 4fe:	0701                	addi	x14,x14,0
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 500:	0231                	addi	x4,x4,12
 502:	0000                	unimp
  asm volatile("flw     %0,  244(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 504:	0800                	addi	x8,x2,16
 506:	000007f7          	0x7f7
  asm volatile("flw     %0,  244(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 50a:	05f4                	addi	x13,x2,716
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 50c:	0000                	unimp
 50e:	fa01                	bnez	x12,41e <kernel_energy_fadd_demo+0x23e>
  asm volatile("flw     %0,  248(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 510:	0701                	addi	x14,x14,0
 512:	0231                	addi	x4,x4,12
  asm volatile("flw     %0,  248(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 514:	0000                	unimp
 516:	0900                	addi	x8,x2,144
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 518:	081a                	slli	x16,x16,0x6
 51a:	0000                	unimp
  asm volatile("flw     %0,  252(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 51c:	0672                	slli	x12,x12,0x1c
 51e:	0000                	unimp
  asm volatile("flw     %0,  252(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 520:	0101                	addi	x2,x2,0
 522:	0101                	addi	x2,x2,0
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 524:	00023107          	fld	f2,0(x4) # ffff9000 <_bsg_dram_end_addr+0x7eff9000>
  asm volatile("flw     %0,  256(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 528:	0000                	unimp
 52a:	820a                	mv	x4,x2
  asm volatile("flw     %0,  256(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 52c:	0001                	nop
 52e:	b100                	fsd	f8,32(x10)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 530:	0006                	c.slli	x0,0x1
 532:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,  260(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 534:	820a                	mv	x4,x2
 536:	0001                	nop
  asm volatile("flw     %0,  260(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 538:	ac00                	fsd	f8,24(x8)
 53a:	01000007          	0x1000007
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 53e:	0300                	addi	x8,x2,384
  asm volatile("flw     %0,  264(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 540:	bf05                	j	470 <kernel_energy_fadd_demo+0x290>
 542:	0006                	c.slli	x0,0x1
  asm volatile("flw     %0,  264(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 544:	0800                	addi	x8,x2,16
 546:	2801                	jal	556 <kernel_energy_fadd_demo+0x376>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 548:	9504                	0x9504
 54a:	0005                	c.nop	1
  asm volatile("flw     %0,  268(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 54c:	5100                	lw	x8,32(x10)
 54e:	0001                	nop
  asm volatile("flw     %0,  268(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 550:	0100                	addi	x8,x2,128
 552:	a204003b          	0xa204003b
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 556:	0005                	c.nop	1
  asm volatile("flw     %0,  272(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 558:	5d00                	lw	x8,56(x10)
 55a:	0001                	nop
  asm volatile("flw     %0,  272(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 55c:	0100                	addi	x8,x2,128
 55e:	043c                	addi	x15,x2,520
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 560:	c106                	sw	x1,128(x2)
 562:	0005                	c.nop	1
  asm volatile("flw     %0,  276(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 564:	0100                	addi	x8,x2,128
 566:	0140                	addi	x8,x2,132
  asm volatile("flw     %0,  276(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 568:	00017d07          	0x17d07
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 56c:	0000                	unimp
 56e:	d108                	sw	x10,32(x10)
  asm volatile("flw     %0,  280(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 570:	0005                	c.nop	1
 572:	f400                	fsw	f8,40(x8)
  asm volatile("flw     %0,  280(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 574:	0005                	c.nop	1
 576:	0100                	addi	x8,x2,128
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 578:	0146                	slli	x2,x2,0x11
 57a:	00017d07          	0x17d07
  asm volatile("flw     %0,  284(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 57e:	0000                	unimp
  asm volatile("flw     %0,  284(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 580:	fa08                	fsw	f10,48(x12)
 582:	0005                	c.nop	1
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 584:	7200                	flw	f8,32(x12)
 586:	0006                	c.slli	x0,0x1
  asm volatile("flw     %0,  288(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 588:	0100                	addi	x8,x2,128
 58a:	0151                	addi	x2,x2,20
  asm volatile("flw     %0,  288(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 58c:	00017d07          	0x17d07
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 590:	0b00                	addi	x8,x2,400
 592:	0000016f          	jal	x2,592 <kernel_energy_fadd_demo+0x3b2>
  asm volatile("flw     %0,  292(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 596:	0800                	addi	x8,x2,16
  asm volatile("flw     %0,  292(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 598:	061c                	addi	x15,x2,768
 59a:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 59c:	059c                	addi	x15,x2,704
 59e:	0000                	unimp
  asm volatile("flw     %0,  296(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 5a0:	6001                	0x6001
 5a2:	0701                	addi	x14,x14,0
  asm volatile("flw     %0,  296(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 5a4:	017d                	addi	x2,x2,31
 5a6:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 5a8:	0800                	addi	x8,x2,16
 5aa:	0000063f 0000066a 	0x66a0000063f
  asm volatile("flw     %0,  300(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 5b2:	7301                	lui	x6,0xfffe0
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 5b4:	0701                	addi	x14,x14,0
 5b6:	017d                	addi	x2,x2,31
  asm volatile("flw     %0,  304(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 5b8:	0000                	unimp
 5ba:	0800                	addi	x8,x2,16
  asm volatile("flw     %0,  304(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 5bc:	00000677          	0x677
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 5c0:	000006a3          	sb	x0,13(x0) # d <__bsg_tile_group_id_y+0x1>
  asm volatile("flw     %0,  308(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 5c4:	7a01                	lui	x20,0xfffe0
 5c6:	0701                	addi	x14,x14,0
  asm volatile("flw     %0,  308(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 5c8:	017d                	addi	x2,x2,31
 5ca:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 5cc:	0a00                	addi	x8,x2,272
 5ce:	0182                	c.slli64	x3
  asm volatile("flw     %0,  312(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 5d0:	0000                	unimp
 5d2:	06b1                	addi	x13,x13,12
  asm volatile("flw     %0,  312(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 5d4:	0000                	unimp
 5d6:	0001                	nop
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 5d8:	560c                	lw	x11,40(x12)
 5da:	0001                	nop
  asm volatile("flw     %0,  316(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 5dc:	0d00                	addi	x8,x2,656
 5de:	04e9                	addi	x9,x9,26
  asm volatile("flw     %0,  316(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 5e0:	0000                	unimp
 5e2:	6a0e0407          	0x6a0e0407
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 5e6:	0001                	nop
  asm volatile("flw     %0,  320(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 5e8:	0f00                	addi	x8,x2,912
 5ea:	0176                	slli	x2,x2,0x1d
  asm volatile("flw     %0,  320(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 5ec:	0000                	unimp
 5ee:	0100                	addi	x8,x2,128
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 5f0:	0c00                	addi	x8,x2,528
 5f2:	0000016f          	jal	x2,5f2 <kernel_energy_fadd_demo+0x412>
  asm volatile("flw     %0,  324(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 5f6:	f50d                	bnez	x10,520 <kernel_energy_fadd_demo+0x340>
  asm volatile("flw     %0,  324(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 5f8:	0001                	nop
 5fa:	0800                	addi	x8,x2,16
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 5fc:	1001                	c.nop	-32
 5fe:	05ad                	addi	x11,x11,11
  asm volatile("flw     %0,  328(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 600:	0000                	unimp
 602:	0708                	addi	x10,x2,896
  asm volatile("flw     %0,  328(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 604:	b811                	j	fffffe18 <_bsg_dram_end_addr+0x7efffe18>
 606:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 608:	0d00                	addi	x8,x2,656
 60a:	04f2                	slli	x9,x9,0x1c
  asm volatile("flw     %0,  332(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 60c:	0000                	unimp
 60e:	0405                	addi	x8,x8,1
  asm volatile("flw     %0,  332(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 610:	07ba0503          	lb	x10,123(x20) # fffe007b <_bsg_dram_end_addr+0x7efe007b>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 614:	0000                	unimp
 616:	0108                	addi	x10,x2,128
  asm volatile("flw     %0,  336(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 618:	048d                	addi	x9,x9,3
 61a:	0595                	addi	x11,x11,5
  asm volatile("flw     %0,  336(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 61c:	0000                	unimp
 61e:	0151                	addi	x2,x2,20
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 620:	0000                	unimp
 622:	9001                	srli	x8,x8,0x20
  asm volatile("flw     %0,  340(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 624:	0400                	addi	x8,x2,512
 626:	05a2                	slli	x11,x11,0x8
  asm volatile("flw     %0,  340(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 628:	0000                	unimp
 62a:	015d                	addi	x2,x2,23
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 62c:	0000                	unimp
 62e:	9101                	srli	x10,x10,0x20
  asm volatile("flw     %0,  344(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 630:	0604                	addi	x9,x2,768
 632:	06dc                	addi	x15,x2,836
  asm volatile("flw     %0,  344(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 634:	0000                	unimp
 636:	9501                	srai	x10,x10,0x20
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 638:	0701                	addi	x14,x14,0
 63a:	00000227          	0x227
  asm volatile("flw     %0,  348(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 63e:	0800                	addi	x8,x2,16
  asm volatile("flw     %0,  348(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 640:	06ec                	addi	x11,x2,844
 642:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 644:	05f4                	addi	x13,x2,716
 646:	0000                	unimp
  asm volatile("flw     %0,  352(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 648:	9b01                	andi	x14,x14,-32
 64a:	0701                	addi	x14,x14,0
  asm volatile("flw     %0,  352(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 64c:	00000227          	0x227
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 650:	0800                	addi	x8,x2,16
 652:	0000070f          	0x70f
  asm volatile("flw     %0,  356(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 656:	0672                	slli	x12,x12,0x1c
  asm volatile("flw     %0,  356(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 658:	0000                	unimp
 65a:	a501                	j	c5a <_gp+0x452>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 65c:	0701                	addi	x14,x14,0
 65e:	00000227          	0x227
  asm volatile("flw     %0,  360(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 662:	00016f0b          	0x16f0b
  asm volatile("flw     %0,  360(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 666:	0b00                	addi	x8,x2,400
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 668:	0000016f          	jal	x2,668 <kernel_energy_fadd_demo+0x488>
  asm volatile("flw     %0,  364(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 66c:	0800                	addi	x8,x2,16
 66e:	0732                	slli	x14,x14,0xc
  asm volatile("flw     %0,  364(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 670:	0000                	unimp
 672:	059c                	addi	x15,x2,704
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 674:	0000                	unimp
 676:	b901                	j	286 <kernel_energy_fadd_demo+0xa6>
  asm volatile("flw     %0,  368(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 678:	0701                	addi	x14,x14,0
 67a:	00000227          	0x227
  asm volatile("flw     %0,  368(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 67e:	0800                	addi	x8,x2,16
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 680:	0755                	addi	x14,x14,21
 682:	0000                	unimp
  asm volatile("flw     %0,  372(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 684:	066a                	slli	x12,x12,0x1a
 686:	0000                	unimp
  asm volatile("flw     %0,  372(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 688:	cc01                	beqz	x8,6a0 <kernel_energy_fadd_demo+0x4c0>
 68a:	0701                	addi	x14,x14,0
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 68c:	00000227          	0x227
  asm volatile("flw     %0,  376(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 690:	0800                	addi	x8,x2,16
 692:	0780                	addi	x8,x2,960
  asm volatile("flw     %0,  376(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 694:	0000                	unimp
 696:	000006a3          	sb	x0,13(x0) # d <__bsg_tile_group_id_y+0x1>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 69a:	d301                	beqz	x14,59a <kernel_energy_fadd_demo+0x3ba>
  asm volatile("flw     %0,  380(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 69c:	0701                	addi	x14,x14,0
 69e:	00000227          	0x227
  asm volatile("flw     %0,  380(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 6a2:	0a00                	addi	x8,x2,272
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 6a4:	0182                	c.slli64	x3
 6a6:	0000                	unimp
  asm volatile("flw     %0,  384(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 6a8:	07ac                	addi	x11,x2,968
 6aa:	0000                	unimp
  asm volatile("flw     %0,  384(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 6ac:	0001                	nop
 6ae:	8911                	andi	x10,x10,4
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 6b0:	0001                	nop
 6b2:	1200                	addi	x8,x2,288
  asm volatile("flw     %0,  388(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 6b4:	0000016f          	jal	x2,6b4 <kernel_energy_fadd_demo+0x4d4>
  asm volatile("flw     %0,  388(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 6b8:	3711                	jal	5bc <kernel_energy_fadd_demo+0x3dc>
 6ba:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 6bc:	1300                	addi	x8,x2,416
 6be:	084e                	slli	x16,x16,0x13
  asm volatile("flw     %0,  392(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 6c0:	0000                	unimp
 6c2:	0514                	addi	x13,x2,640
  asm volatile("flw     %0,  392(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 6c4:	0003002f          	0x3002f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 6c8:	1400                	addi	x8,x2,544
 6ca:	3005                	jal	fffffeea <_bsg_dram_end_addr+0x7efffeea>
  asm volatile("flw     %0,  396(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 6cc:	031d                	addi	x6,x6,7
 6ce:	0000                	unimp
  asm volatile("flw     %0,  396(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 6d0:	0514                	addi	x13,x2,640
 6d2:	3a31                	jal	ffffffee <_bsg_dram_end_addr+0x7effffee>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 6d4:	14000003          	lb	x0,320(x0) # 140 <bsg_set_tile_x_y+0x18>
  asm volatile("flw     %0,  400(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 6d8:	3205                	jal	fffffff8 <_bsg_dram_end_addr+0x7efffff8>
 6da:	0350                	addi	x12,x2,388
  asm volatile("flw     %0,  400(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 6dc:	0000                	unimp
 6de:	0514                	addi	x13,x2,640
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 6e0:	6d34                	flw	f13,88(x10)
 6e2:	14000003          	lb	x0,320(x0) # 140 <bsg_set_tile_x_y+0x18>
  asm volatile("flw     %0,  404(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 6e6:	3505                	jal	506 <kernel_energy_fadd_demo+0x326>
  asm volatile("flw     %0,  404(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 6e8:	0378                	addi	x14,x2,396
 6ea:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 6ec:	0514                	addi	x13,x2,640
 6ee:	8336                	mv	x6,x13
  asm volatile("flw     %0,  408(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 6f0:	14000003          	lb	x0,320(x0) # 140 <bsg_set_tile_x_y+0x18>
  asm volatile("flw     %0,  408(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 6f4:	3705                	jal	614 <kernel_energy_fadd_demo+0x434>
 6f6:	038e                	slli	x7,x7,0x3
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 6f8:	0000                	unimp
 6fa:	0514                	addi	x13,x2,640
  asm volatile("flw     %0,  412(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 6fc:	9939                	andi	x10,x10,-18
 6fe:	14000003          	lb	x0,320(x0) # 140 <bsg_set_tile_x_y+0x18>
  asm volatile("flw     %0,  412(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 702:	3a05                	jal	32 <__bsg_x+0x6>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 704:	000003af          	0x3af
  asm volatile("flw     %0,  416(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 708:	0514                	addi	x13,x2,640
 70a:	0003c53b          	0x3c53b
  asm volatile("flw     %0,  416(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 70e:	1400                	addi	x8,x2,544
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 710:	3c05                	jal	140 <bsg_set_tile_x_y+0x18>
 712:	000003db          	0x3db
  asm volatile("flw     %0,  420(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 716:	0514                	addi	x13,x2,640
  asm volatile("flw     %0,  420(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 718:	f13e                	fsw	f15,160(x2)
 71a:	14000003          	lb	x0,320(x0) # 140 <bsg_set_tile_x_y+0x18>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 71e:	3f05                	jal	64e <kernel_energy_fadd_demo+0x46e>
  asm volatile("flw     %0,  424(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 720:	00000407          	0x407
  asm volatile("flw     %0,  424(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 724:	0514                	addi	x13,x2,640
 726:	1d41                	addi	x26,x26,-16
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 728:	0004                	0x4
 72a:	1400                	addi	x8,x2,544
  asm volatile("flw     %0,  428(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 72c:	4205                	li	x4,1
 72e:	00000433          	add	x8,x0,x0
  asm volatile("flw     %0,  428(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 732:	0514                	addi	x13,x2,640
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 734:	00045043          	fmadd.s	f0,f8,f0,f0,unknown
  asm volatile("flw     %0,  432(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 738:	1400                	addi	x8,x2,544
 73a:	4405                	li	x8,1
  asm volatile("flw     %0,  432(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 73c:	0466                	slli	x8,x8,0x19
 73e:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 740:	0514                	addi	x13,x2,640
 742:	8346                	mv	x6,x17
  asm volatile("flw     %0,  436(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 744:	0004                	0x4
 746:	1400                	addi	x8,x2,544
  asm volatile("flw     %0,  436(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 748:	4705                	li	x14,1
 74a:	048e                	slli	x9,x9,0x3
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 74c:	0000                	unimp
 74e:	0514                	addi	x13,x2,640
  asm volatile("flw     %0,  440(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 750:	9948                	0x9948
 752:	0004                	0x4
  asm volatile("flw     %0,  440(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 754:	1400                	addi	x8,x2,544
 756:	4905                	li	x18,1
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 758:	04a4                	addi	x9,x2,584
 75a:	0000                	unimp
  asm volatile("flw     %0,  444(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 75c:	0514                	addi	x13,x2,640
 75e:	0004af4b          	fnmsub.s	f30,f9,f0,f0,rdn
  asm volatile("flw     %0,  444(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 762:	1400                	addi	x8,x2,544
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 764:	4c05                	li	x24,1
 766:	04c5                	addi	x9,x9,17
  asm volatile("flw     %0,  448(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 768:	0000                	unimp
 76a:	0514                	addi	x13,x2,640
  asm volatile("flw     %0,  448(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 76c:	db4d                	beqz	x14,71e <kernel_energy_fadd_demo+0x53e>
 76e:	0004                	0x4
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 770:	1400                	addi	x8,x2,544
 772:	4e05                	li	x28,1
  asm volatile("flw     %0,  452(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 774:	04f1                	addi	x9,x9,28
 776:	0000                	unimp
  asm volatile("flw     %0,  452(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 778:	0514                	addi	x13,x2,640
 77a:	0750                	addi	x12,x2,900
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 77c:	0005                	c.nop	1
 77e:	1400                	addi	x8,x2,544
  asm volatile("flw     %0,  456(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 780:	5105                	li	x2,-31
 782:	051d                	addi	x10,x10,7
  asm volatile("flw     %0,  456(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 784:	0000                	unimp
 786:	1500                	addi	x8,x2,672
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 788:	0000030b          	0x30b
  asm volatile("flw     %0,  460(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 78c:	0854                	addi	x13,x2,20
 78e:	0000                	unimp
  asm volatile("flw     %0,  460(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 790:	1404                	addi	x9,x2,544
 792:	1615                	addi	x12,x12,-27
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 794:	52000003          	lb	x0,1312(x0) # 520 <kernel_energy_fadd_demo+0x340>
  asm volatile("flw     %0,  464(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 798:	0008                	0x8
 79a:	0300                	addi	x8,x2,384
  asm volatile("flw     %0,  464(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 79c:	0d29                	addi	x26,x26,10
 79e:	000001f7          	0x1f7
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 7a2:	0106                	slli	x2,x2,0x1
  asm volatile("flw     %0,  468(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 7a4:	2815                	jal	7d8 <kernel_energy_fadd_demo+0x5f8>
 7a6:	5d000003          	lb	x0,1488(x0) # 5d0 <kernel_energy_fadd_demo+0x3f0>
  asm volatile("flw     %0,  468(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 7aa:	0008                	0x8
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 7ac:	0400                	addi	x8,x2,512
 7ae:	1520                	addi	x8,x2,680
  asm volatile("flw     %0,  472(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 7b0:	00000333          	add	x6,x0,x0
  asm volatile("flw     %0,  472(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 7b4:	0000085b          	0x85b
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 7b8:	d70d3703          	0xd70d3703
  asm volatile("flw     %0,  476(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 7bc:	0008                	0x8
 7be:	0500                	addi	x8,x2,640
  asm volatile("flw     %0,  476(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 7c0:	1502                	slli	x10,x10,0x20
 7c2:	0345                	addi	x6,x6,17
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 7c4:	0000                	unimp
 7c6:	000003b3          	add	x7,x0,x0
  asm volatile("flw     %0,  480(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 7ca:	2c04                	fld	f9,24(x8)
  asm volatile("flw     %0,  480(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 7cc:	8215                	srli	x12,x12,0x5
 7ce:	0001                	nop
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 7d0:	b100                	fsd	f8,32(x10)
 7d2:	03000003          	lb	x0,48(x0) # 30 <__bsg_x+0x4>
  asm volatile("flw     %0,  484(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 7d6:	154d                	addi	x10,x10,-13
  asm volatile("flw     %0,  484(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 7d8:	0000035b          	0x35b
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 7dc:	00000867          	jalr	x16,x0 # 0 <_bsg_data_start_addr>
  asm volatile("flw     %0,  488(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 7e0:	3804                	fld	f9,48(x8)
 7e2:	6615                	lui	x12,0x5
  asm volatile("flw     %0,  488(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 7e4:	65000003          	lb	x0,1616(x0) # 650 <kernel_energy_fadd_demo+0x470>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 7e8:	0008                	0x8
 7ea:	0300                	addi	x8,x2,384
  asm volatile("flw     %0,  492(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 7ec:	04130d67          	jalr	x26,65(x6) # fffe0041 <_bsg_dram_end_addr+0x7efe0041>
  asm volatile("flw     %0,  492(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 7f0:	0000                	unimp
 7f2:	0805                	addi	x16,x16,1
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 7f4:	1615                	addi	x12,x12,-27
 7f6:	f4000003          	lb	x0,-192(x0) # ffffff40 <_bsg_dram_end_addr+0x7effff40>
  asm volatile("flw     %0,  496(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 7fa:	0008                	0x8
  asm volatile("flw     %0,  496(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 7fc:	0600                	addi	x8,x2,768
 7fe:	03331533          	mulh	x10,x6,x19
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 802:	0000                	unimp
  asm volatile("flw     %0,  500(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 804:	0901                	addi	x18,x18,0
 806:	0000                	unimp
  asm volatile("flw     %0,  500(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 808:	3d06                	fld	f26,96(x2)
 80a:	8215                	srli	x12,x12,0x5
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 80c:	0001                	nop
 80e:	0f00                	addi	x8,x2,912
  asm volatile("flw     %0,  504(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 810:	0009                	c.nop	2
 812:	0600                	addi	x8,x2,768
  asm volatile("flw     %0,  504(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 814:	03661547          	fmsub.d	f10,f12,f22,f0,rtz
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 818:	0000                	unimp
 81a:	091d                	addi	x18,x18,7
  asm volatile("flw     %0,  508(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 81c:	0000                	unimp
 81e:	5106                	lw	x2,96(x2)
  asm volatile("flw     %0,  508(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 820:	a415                	j	a44 <_gp+0x23c>
 822:	71000003          	lb	x0,1808(x0) # 710 <kernel_energy_fadd_demo+0x530>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 826:	0008                	0x8
  asm volatile("flw     %0,  512(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 828:	0600                	addi	x8,x2,768
 82a:	1515                	addi	x10,x10,-27
  asm volatile("flw     %0,  512(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 82c:	0316                	slli	x6,x6,0x5
 82e:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 830:	0000086f          	jal	x16,830 <_gp+0x28>
  asm volatile("flw     %0,  516(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 834:	ba158603          	lb	x12,-1119(x11)
  asm volatile("flw     %0,  516(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 838:	80000003          	lb	x0,-2048(x0) # fffff800 <_bsg_dram_end_addr+0x7efff800>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 83c:	0008                	0x8
 83e:	0600                	addi	x8,x2,768
  asm volatile("flw     %0,  520(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 840:	0333151b          	0x333151b
  asm volatile("flw     %0,  520(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 844:	0000                	unimp
 846:	087e                	slli	x16,x16,0x1f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 848:	0000                	unimp
 84a:	d015a003          	lw	x0,-767(x11)
  asm volatile("flw     %0,  524(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 84e:	90000003          	lb	x0,-1792(x0) # fffff900 <_bsg_dram_end_addr+0x7efff900>
  asm volatile("flw     %0,  524(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 852:	0008                	0x8
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 854:	0600                	addi	x8,x2,768
 856:	1521                	addi	x10,x10,-24
  asm volatile("flw     %0,  528(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 858:	0182                	c.slli64	x3
 85a:	0000                	unimp
  asm volatile("flw     %0,  528(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 85c:	088e                	slli	x17,x17,0x3
 85e:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 860:	e615b603          	0xe615b603
  asm volatile("flw     %0,  532(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 864:	a0000003          	lb	x0,-1536(x0) # fffffa00 <_bsg_dram_end_addr+0x7efffa00>
  asm volatile("flw     %0,  532(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 868:	0008                	0x8
 86a:	0600                	addi	x8,x2,768
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 86c:	03661527          	0x3661527
  asm volatile("flw     %0,  536(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 870:	0000                	unimp
 872:	089e                	slli	x17,x17,0x7
  asm volatile("flw     %0,  536(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 874:	0000                	unimp
 876:	fc15c803          	lbu	x16,-63(x11)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 87a:	b0000003          	lb	x0,-1280(x0) # fffffb00 <_bsg_dram_end_addr+0x7efffb00>
  asm volatile("flw     %0,  540(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 87e:	0008                	0x8
  asm volatile("flw     %0,  540(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 880:	0400                	addi	x8,x2,512
 882:	03661543          	fmadd.d	f10,f12,f22,f0,rtz
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 886:	0000                	unimp
  asm volatile("flw     %0,  544(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 888:	08ae                	slli	x17,x17,0xb
 88a:	0000                	unimp
  asm volatile("flw     %0,  544(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 88c:	1215d603          	lhu	x12,289(x11)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 890:	0004                	0x4
 892:	bb00                	fsd	f8,48(x14)
  asm volatile("flw     %0,  548(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 894:	0008                	0x8
 896:	0400                	addi	x8,x2,512
  asm volatile("flw     %0,  548(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 898:	154d                	addi	x10,x10,-13
 89a:	0182                	c.slli64	x3
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 89c:	0000                	unimp
 89e:	08b9                	addi	x17,x17,14
  asm volatile("flw     %0,  552(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 8a0:	0000                	unimp
 8a2:	2815e603          	0x2815e603
  asm volatile("flw     %0,  552(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 8a6:	0004                	0x4
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 8a8:	c600                	sw	x8,8(x12)
 8aa:	0008                	0x8
  asm volatile("flw     %0,  556(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 8ac:	0400                	addi	x8,x2,512
 8ae:	1518                	addi	x14,x2,672
  asm volatile("flw     %0,  556(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 8b0:	0000016f          	jal	x2,8b0 <_gp+0xa8>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 8b4:	08c4                	addi	x9,x2,84
 8b6:	0000                	unimp
  asm volatile("flw     %0,  560(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 8b8:	3e152b03          	lw	x22,993(x10)
  asm volatile("flw     %0,  560(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 8bc:	0004                	0x4
 8be:	df00                	sw	x8,56(x14)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 8c0:	0008                	0x8
 8c2:	0400                	addi	x8,x2,512
  asm volatile("flw     %0,  564(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 8c4:	1524                	addi	x9,x2,680
 8c6:	0449                	addi	x8,x8,18
  asm volatile("flw     %0,  564(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 8c8:	0000                	unimp
 8ca:	08dd                	addi	x17,x17,23
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 8cc:	0000                	unimp
 8ce:	ce0d3903          	0xce0d3903
  asm volatile("flw     %0,  568(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 8d2:	0008                	0x8
  asm volatile("flw     %0,  568(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 8d4:	0700                	addi	x8,x2,896
 8d6:	1502                	slli	x10,x10,0x20
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 8d8:	0000045b          	0x45b
  asm volatile("flw     %0,  572(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 8dc:	0405                	addi	x8,x8,1
 8de:	0000                	unimp
  asm volatile("flw     %0,  572(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 8e0:	3004                	fld	f9,32(x8)
 8e2:	5615                	li	x12,-27
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 8e4:	0001                	nop
 8e6:	0300                	addi	x8,x2,384
  asm volatile("flw     %0,  576(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 8e8:	0004                	0x4
 8ea:	0300                	addi	x8,x2,384
  asm volatile("flw     %0,  576(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 8ec:	0471154f          	0x471154f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 8f0:	0000                	unimp
 8f2:	08ea                	slli	x17,x17,0x1a
  asm volatile("flw     %0,  580(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 8f4:	0000                	unimp
 8f6:	3c04                	fld	f9,56(x8)
  asm volatile("flw     %0,  580(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 8f8:	7c15                	lui	x24,0xfffe5
 8fa:	0004                	0x4
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 8fc:	e800                	fsw	f8,16(x8)
 8fe:	0008                	0x8
  asm volatile("flw     %0,  584(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 900:	0300                	addi	x8,x2,384
 902:	0d69                	addi	x26,x26,26
  asm volatile("flw     %0,  584(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 904:	04df 0000 0807      	0x807000004df
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 90a:	6f15                	lui	x30,0x5
  asm volatile("flw     %0,  588(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 90c:	0001                	nop
 90e:	f300                	fsw	f8,32(x14)
  asm volatile("flw     %0,  588(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 910:	0008                	0x8
 912:	0600                	addi	x8,x2,768
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 914:	1534                	addi	x13,x2,680
 916:	0449                	addi	x8,x8,18
  asm volatile("flw     %0,  592(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 918:	0000                	unimp
 91a:	0900                	addi	x8,x2,144
  asm volatile("flw     %0,  592(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 91c:	0000                	unimp
 91e:	3e06                	fld	f28,96(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 920:	5615                	li	x12,-27
 922:	0001                	nop
  asm volatile("flw     %0,  596(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 924:	0e00                	addi	x8,x2,784
 926:	0009                	c.nop	2
  asm volatile("flw     %0,  596(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 928:	0600                	addi	x8,x2,768
 92a:	1548                	addi	x10,x2,676
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 92c:	047c                	addi	x15,x2,524
 92e:	0000                	unimp
  asm volatile("flw     %0,  600(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 930:	091c                	addi	x15,x2,144
 932:	0000                	unimp
  asm volatile("flw     %0,  600(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 934:	5206                	lw	x4,96(x2)
 936:	ba15                	j	26a <kernel_energy_fadd_demo+0x8a>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 938:	0004                	0x4
 93a:	2c00                	fld	f8,24(x8)
  asm volatile("flw     %0,  604(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 93c:	0009                	c.nop	2
 93e:	0600                	addi	x8,x2,768
  asm volatile("flw     %0,  604(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 940:	1516                	slli	x10,x10,0x25
 942:	0000016f          	jal	x2,942 <_gp+0x13a>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 946:	092a                	slli	x18,x18,0xa
  asm volatile("flw     %0,  608(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 948:	0000                	unimp
 94a:	d0158803          	lb	x16,-767(x11)
  asm volatile("flw     %0,  608(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 94e:	0004                	0x4
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 950:	3c00                	fld	f8,56(x8)
 952:	0009                	c.nop	2
  asm volatile("flw     %0,  612(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 954:	0600                	addi	x8,x2,768
 956:	151c                	addi	x15,x2,672
  asm volatile("flw     %0,  612(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 958:	0449                	addi	x8,x8,18
 95a:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 95c:	093a                	slli	x18,x18,0xe
 95e:	0000                	unimp
  asm volatile("flw     %0,  616(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 960:	e615a203          	lw	x4,-415(x11)
  asm volatile("flw     %0,  616(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 964:	0004                	0x4
 966:	4d00                	lw	x8,24(x10)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 968:	0009                	c.nop	2
 96a:	0600                	addi	x8,x2,768
  asm volatile("flw     %0,  620(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 96c:	1522                	slli	x10,x10,0x28
 96e:	0156                	slli	x2,x2,0x15
  asm volatile("flw     %0,  620(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 970:	0000                	unimp
 972:	0000094b          	fnmsub.s	f18,f0,f0,f0,rne
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 976:	fc15b803          	0xfc15b803
  asm volatile("flw     %0,  624(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 97a:	0004                	0x4
  asm volatile("flw     %0,  624(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 97c:	5e00                	lw	x8,56(x12)
 97e:	0009                	c.nop	2
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 980:	0600                	addi	x8,x2,768
 982:	1528                	addi	x10,x2,680
  asm volatile("flw     %0,  628(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 984:	047c                	addi	x15,x2,524
 986:	0000                	unimp
  asm volatile("flw     %0,  628(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 988:	095c                	addi	x15,x2,148
 98a:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 98c:	1215ca03          	lbu	x20,289(x11)
  asm volatile("flw     %0,  632(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 990:	0005                	c.nop	1
 992:	6f00                	flw	f8,24(x14)
  asm volatile("flw     %0,  632(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 994:	0009                	c.nop	2
 996:	0400                	addi	x8,x2,512
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 998:	1548                	addi	x10,x2,676
 99a:	047c                	addi	x15,x2,524
  asm volatile("flw     %0,  636(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 99c:	0000                	unimp
 99e:	096d                	addi	x18,x18,27
  asm volatile("flw     %0,  636(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 9a0:	0000                	unimp
 9a2:	2815de03          	lhu	x28,641(x11)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 9a6:	0005                	c.nop	1
  asm volatile("flw     %0,  640(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 9a8:	7b00                	flw	f8,48(x14)
 9aa:	0009                	c.nop	2
  asm volatile("flw     %0,  640(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 9ac:	0400                	addi	x8,x2,512
 9ae:	1552                	slli	x10,x10,0x34
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 9b0:	0156                	slli	x2,x2,0x15
 9b2:	0000                	unimp
  asm volatile("flw     %0,  644(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 9b4:	0979                	addi	x18,x18,30
 9b6:	0000                	unimp
  asm volatile("flw     %0,  644(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 9b8:	e016e803          	0xe016e803
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 9bc:	0001                	nop
 9be:	5800                	lw	x8,48(x8)
  asm volatile("flw     %0,  648(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 9c0:	000c                	0xc
 9c2:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,  648(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 9c4:	ff52                	fsw	f20,188(x2)
 9c6:	0009                	c.nop	2
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 9c8:	0200                	addi	x8,x2,256
 9ca:	820a                	mv	x4,x2
  asm volatile("flw     %0,  652(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 9cc:	0001                	nop
 9ce:	1700                	addi	x8,x2,928
  asm volatile("flw     %0,  652(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 9d0:	0042                	c.slli	x0,0x10
 9d2:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 9d4:	0a3d                	addi	x20,x20,15
 9d6:	0000                	unimp
  asm volatile("flw     %0,  656(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 9d8:	0a02                	c.slli64	x20
 9da:	000007d7          	0x7d7
  asm volatile("flw     %0,  656(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 9de:	00005517          	auipc	x10,0x5
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 9e2:	3f00                	fld	f8,56(x14)
  asm volatile("flw     %0,  660(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 9e4:	000a                	c.slli	x0,0x2
 9e6:	0200                	addi	x8,x2,256
  asm volatile("flw     %0,  660(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 9e8:	d70a                	sw	x2,172(x2)
 9ea:	17000007          	0x17000007
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 9ee:	0068                	addi	x10,x2,12
  asm volatile("flw     %0,  664(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 9f0:	0000                	unimp
 9f2:	0a41                	addi	x20,x20,16
  asm volatile("flw     %0,  664(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 9f4:	0000                	unimp
 9f6:	0a02                	c.slli64	x20
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 9f8:	000007d7          	0x7d7
  asm volatile("flw     %0,  668(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 9fc:	00007b17          	auipc	x22,0x7
  asm volatile("flw     %0,  668(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a00:	4300                	lw	x8,0(x14)
 a02:	000a                	c.slli	x0,0x2
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a04:	0200                	addi	x8,x2,256
 a06:	820a                	mv	x4,x2
  asm volatile("flw     %0,  672(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a08:	0001                	nop
 a0a:	1800                	addi	x8,x2,48
  asm volatile("flw     %0,  672(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a0c:	08849103          	lh	x2,136(x9)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a10:	0a31                	addi	x20,x20,12
 a12:	0000                	unimp
  asm volatile("flw     %0,  676(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a14:	0d02                	c.slli64	x26
 a16:	000007c3          	fmadd.s	f15,f0,f0,f0,rne
  asm volatile("flw     %0,  676(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a1a:	0218                	addi	x14,x2,256
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a1c:	0891                	addi	x17,x17,4
 a1e:	00000a37          	lui	x20,0x0
  asm volatile("flw     %0,  680(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a22:	0e02                	c.slli64	x28
  asm volatile("flw     %0,  680(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a24:	000007c3          	fmadd.s	f15,f0,f0,f0,rne
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a28:	8e19                	sub	x12,x12,x14
 a2a:	0000                	unimp
  asm volatile("flw     %0,  684(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a2c:	4500                	lw	x8,8(x10)
 a2e:	000a                	c.slli	x0,0x2
  asm volatile("flw     %0,  684(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a30:	0200                	addi	x8,x2,256
 a32:	d711                	beqz	x14,93e <_gp+0x136>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a34:	19000007          	0x19000007
  asm volatile("flw     %0,  688(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a38:	000000a3          	sb	x0,1(x0) # 1 <_bsg_data_start_addr+0x1>
  asm volatile("flw     %0,  688(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a3c:	00000a4b          	fnmsub.s	f20,f0,f0,f0,rne
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a40:	1002                	c.slli	x0,0x20
 a42:	000007d7          	0x7d7
  asm volatile("flw     %0,  692(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a46:	b919                	j	65c <kernel_energy_fadd_demo+0x47c>
  asm volatile("flw     %0,  692(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a48:	0000                	unimp
 a4a:	5100                	lw	x8,32(x10)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a4c:	000a                	c.slli	x0,0x2
 a4e:	0200                	addi	x8,x2,256
  asm volatile("flw     %0,  696(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a50:	0007d00f          	0x7d00f
  asm volatile("flw     %0,  696(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a54:	1900                	addi	x8,x2,176
 a56:	00d9                	addi	x1,x1,22
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a58:	0000                	unimp
 a5a:	00000a57          	0xa57
  asm volatile("flw     %0,  700(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a5e:	0f02                	c.slli64	x30
  asm volatile("flw     %0,  700(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a60:	07d0                	addi	x12,x2,964
 a62:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a64:	f919                	bnez	x10,97a <_gp+0x172>
 a66:	0000                	unimp
  asm volatile("flw     %0,  704(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a68:	5d00                	lw	x8,56(x10)
 a6a:	000a                	c.slli	x0,0x2
  asm volatile("flw     %0,  704(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a6c:	0200                	addi	x8,x2,256
 a6e:	0007d00f          	0x7d00f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a72:	1a00                	addi	x8,x2,304
  asm volatile("flw     %0,  708(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a74:	01f4                	addi	x13,x2,204
 a76:	0000                	unimp
  asm volatile("flw     %0,  708(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a78:	0028                	addi	x10,x2,8
 a7a:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a7c:	0009de1b          	0x9de1b
  asm volatile("flw     %0,  712(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a80:	0200                	addi	x8,x2,256
 a82:	5012                	0x5012
  asm volatile("flw     %0,  712(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a84:	0004                	0x4
 a86:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a88:	1c00                	addi	x8,x2,560
 a8a:	0985                	addi	x19,x19,1
  asm volatile("flw     %0,  716(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a8c:	0000                	unimp
 a8e:	00d9                	addi	x1,x1,22
  asm volatile("flw     %0,  716(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a90:	0000                	unimp
 a92:	1001                	c.nop	-32
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a94:	0006                	c.slli	x0,0x1
 a96:	1d00                	addi	x8,x2,688
  asm volatile("flw     %0,  720(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a98:	09a4                	addi	x9,x2,216
 a9a:	0000                	unimp
  asm volatile("flw     %0,  720(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a9c:	061a                	slli	x12,x12,0x6
 a9e:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 aa0:	1100                	addi	x8,x2,160
 aa2:	00b8                	addi	x14,x2,72
  asm volatile("flw     %0,  724(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 aa4:	0000                	unimp
 aa6:	a91c                	fsd	f15,16(x10)
  asm volatile("flw     %0,  724(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 aa8:	0009                	c.nop	2
 aaa:	7000                	flw	f8,32(x8)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 aac:	0000                	unimp
 aae:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,  728(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 ab0:	062d                	addi	x12,x12,11
 ab2:	0000                	unimp
  asm volatile("flw     %0,  728(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 ab4:	a41d                	j	cda <_gp+0x4d2>
 ab6:	0009                	c.nop	2
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 ab8:	3700                	fld	f8,40(x14)
 aba:	0006                	c.slli	x0,0x1
  asm volatile("flw     %0,  732(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 abc:	0000                	unimp
 abe:	3711                	jal	9c2 <_gp+0x1ba>
  asm volatile("flw     %0,  732(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 ac0:	0000                	unimp
 ac2:	1e00                	addi	x8,x2,816
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 ac4:	09c8                	addi	x10,x2,212
 ac6:	0000                	unimp
  asm volatile("flw     %0,  736(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 ac8:	0702                	c.slli64	x14
 aca:	1f01                	addi	x30,x30,-32
  asm volatile("flw     %0,  736(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 acc:	000000e7          	jalr	x0 # 0 <_bsg_data_start_addr>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 ad0:	4e01                	li	x28,0
 ad2:	0006                	c.slli	x0,0x1
  asm volatile("flw     %0,  740(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 ad4:	1d00                	addi	x8,x2,688
 ad6:	09a4                	addi	x9,x2,216
  asm volatile("flw     %0,  740(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 ad8:	0000                	unimp
 ada:	061a                	slli	x12,x12,0x6
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 adc:	0000                	unimp
 ade:	1b20                	addi	x8,x2,440
  asm volatile("flw     %0,  744(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 ae0:	09de                	slli	x19,x19,0x17
 ae2:	0000                	unimp
  asm volatile("flw     %0,  744(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 ae4:	4701                	li	x14,0
 ae6:	0182                	c.slli64	x3
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 ae8:	0000                	unimp
 aea:	0000                	unimp
  asm volatile("flw     %0,  748(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 aec:	e01c                	fsw	f15,0(x8)
 aee:	0009                	c.nop	2
  asm volatile("flw     %0,  748(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 af0:	aa00                	fsd	f8,16(x12)
 af2:	0001                	nop
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 af4:	0100                	addi	x8,x2,128
 af6:	00000673          	0x673
  asm volatile("flw     %0,  752(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 afa:	a41d                	j	d20 <_gp+0x518>
  asm volatile("flw     %0,  752(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 afc:	0009                	c.nop	2
 afe:	7d00                	flw	f8,56(x10)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 b00:	0006                	c.slli	x0,0x1
 b02:	0000                	unimp
  asm volatile("flw     %0,  756(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 b04:	8911                	andi	x10,x10,4
 b06:	0001                	nop
  asm volatile("flw     %0,  756(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 b08:	1f00                	addi	x8,x2,944
 b0a:	01b8                	addi	x14,x2,200
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 b0c:	0000                	unimp
 b0e:	8c01                	sub	x8,x8,x8
  asm volatile("flw     %0,  760(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 b10:	0006                	c.slli	x0,0x1
 b12:	1d00                	addi	x8,x2,688
  asm volatile("flw     %0,  760(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 b14:	09a4                	addi	x9,x2,216
 b16:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 b18:	067d                	addi	x12,x12,31
 b1a:	0000                	unimp
  asm volatile("flw     %0,  764(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 b1c:	1b20                	addi	x8,x2,440
 b1e:	09de                	slli	x19,x19,0x17
  asm volatile("flw     %0,  764(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 b20:	0000                	unimp
 b22:	9c01                	0x9c01
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 b24:	0182                	c.slli64	x3
 b26:	0000                	unimp
  asm volatile("flw     %0,  768(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 b28:	0000                	unimp
 b2a:	3821                	jal	342 <kernel_energy_fadd_demo+0x162>
  asm volatile("flw     %0,  768(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 b2c:	000e                	c.slli	x0,0x3
 b2e:	3800                	fld	f8,48(x8)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 b30:	0000                	unimp
 b32:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,  772(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 b34:	1752                	slli	x14,x14,0x34
 b36:	000a                	c.slli	x0,0x2
  asm volatile("flw     %0,  772(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 b38:	2200                	fld	f8,0(x12)
 b3a:	063c                	addi	x15,x2,776
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 b3c:	0000                	unimp
 b3e:	0e38                	addi	x14,x2,792
  asm volatile("flw     %0,  776(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 b40:	0000                	unimp
 b42:	0038                	addi	x14,x2,8
  asm volatile("flw     %0,  776(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 b44:	0000                	unimp
 b46:	0002                	c.slli64	x0
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 b48:	00061f23          	sh	x0,30(x12) # 501e <_bsg_elf_stack_ptr+0x4022>
  asm volatile("flw     %0,  780(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 b4c:	3800                	fld	f8,48(x8)
 b4e:	000e                	c.slli	x0,0x3
  asm volatile("flw     %0,  780(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 b50:	3800                	fld	f8,48(x8)
 b52:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 b54:	0200                	addi	x8,x2,256
 b56:	92242707          	flw	f14,-1758(x8)
  asm volatile("flw     %0,  784(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 b5a:	0001                	nop
  asm volatile("flw     %0,  784(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 b5c:	2d00                	fld	f8,24(x10)
 b5e:	0006                	c.slli	x0,0x1
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 b60:	2300                	fld	f8,0(x14)
 b62:	0602                	c.slli64	x12
  asm volatile("flw     %0,  788(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 b64:	0000                	unimp
 b66:	0e38                	addi	x14,x2,792
  asm volatile("flw     %0,  788(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 b68:	0000                	unimp
 b6a:	0014                	0x14
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 b6c:	0000                	unimp
 b6e:	f401                	bnez	x8,a76 <_gp+0x26e>
  asm volatile("flw     %0,  792(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 b70:	2405                	jal	d90 <_gp+0x588>
 b72:	017f                	0x17f
  asm volatile("flw     %0,  792(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 b74:	0000                	unimp
 b76:	0610                	addi	x12,x2,768
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 b78:	0000                	unimp
 b7a:	00064423          	0x64423
  asm volatile("flw     %0,  796(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 b7e:	4400                	lw	x8,8(x8)
  asm volatile("flw     %0,  796(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 b80:	000e                	c.slli	x0,0x3
 b82:	0800                	addi	x8,x2,16
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 b84:	0000                	unimp
 b86:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,  800(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 b88:	0f41                	addi	x30,x30,16
 b8a:	0125                	addi	x2,x2,9
  asm volatile("flw     %0,  800(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 b8c:	00064e5b          	0x64e5b
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 b90:	1a00                	addi	x8,x2,304
 b92:	0e44                	addi	x9,x2,788
  asm volatile("flw     %0,  804(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 b94:	0000                	unimp
 b96:	0004                	0x4
  asm volatile("flw     %0,  804(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 b98:	0000                	unimp
 b9a:	5d26                	lw	x26,104(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 b9c:	0001                	nop
 b9e:	5800                	lw	x8,48(x8)
  asm volatile("flw     %0,  808(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 ba0:	0006                	c.slli	x0,0x1
 ba2:	0000                	unimp
  asm volatile("flw     %0,  808(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 ba4:	0000                	unimp
 ba6:	00066523          	0x66523
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 baa:	4c00                	lw	x8,24(x8)
  asm volatile("flw     %0,  812(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 bac:	000e                	c.slli	x0,0x3
 bae:	1000                	addi	x8,x2,32
  asm volatile("flw     %0,  812(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 bb0:	0000                	unimp
 bb2:	0100                	addi	x8,x2,128
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 bb4:	05f4                	addi	x13,x2,716
 bb6:	0325                	addi	x6,x6,9
  asm volatile("flw     %0,  816(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 bb8:	739f087b          	0x739f087b
  asm volatile("flw     %0,  816(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 bbc:	0006                	c.slli	x0,0x1
 bbe:	2300                	fld	f8,0(x14)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 bc0:	0682                	c.slli64	x13
 bc2:	0000                	unimp
  asm volatile("flw     %0,  820(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 bc4:	0e54                	addi	x13,x2,788
 bc6:	0000                	unimp
  asm volatile("flw     %0,  820(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 bc8:	0008                	0x8
 bca:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 bcc:	9601                	srai	x12,x12,0x20
 bce:	7b03250f          	0x7b03250f
  asm volatile("flw     %0,  824(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 bd2:	9f08                	0x9f08
  asm volatile("flw     %0,  824(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 bd4:	068c                	addi	x11,x2,832
 bd6:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 bd8:	541a                	lw	x8,164(x2)
 bda:	000e                	c.slli	x0,0x3
  asm volatile("flw     %0,  828(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 bdc:	0400                	addi	x8,x2,512
 bde:	0000                	unimp
  asm volatile("flw     %0,  828(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 be0:	2600                	fld	f8,8(x12)
 be2:	0000013b          	0x13b
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 be6:	0696                	slli	x13,x13,0x5
  asm volatile("flw     %0,  832(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 be8:	0000                	unimp
 bea:	0000                	unimp
  asm volatile("flw     %0,  832(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 bec:	2300                	fld	f8,0(x14)
 bee:	0644                	addi	x9,x2,772
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 bf0:	0000                	unimp
 bf2:	0e5c                	addi	x15,x2,788
  asm volatile("flw     %0,  836(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 bf4:	0000                	unimp
 bf6:	0008                	0x8
  asm volatile("flw     %0,  836(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 bf8:	0000                	unimp
 bfa:	f501                	bnez	x10,b02 <_gp+0x2fa>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 bfc:	2419                	jal	e02 <_gp+0x5fa>
 bfe:	01a5                	addi	x3,x3,9
  asm volatile("flw     %0,  840(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 c00:	0000                	unimp
 c02:	064e                	slli	x12,x12,0x13
  asm volatile("flw     %0,  840(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 c04:	0000                	unimp
 c06:	5c1a                	lw	x24,164(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 c08:	000e                	c.slli	x0,0x3
 c0a:	0400                	addi	x8,x2,512
  asm volatile("flw     %0,  844(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 c0c:	0000                	unimp
 c0e:	2600                	fld	f8,8(x12)
  asm volatile("flw     %0,  844(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 c10:	0119                	addi	x2,x2,6
 c12:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 c14:	0658                	addi	x14,x2,772
 c16:	0000                	unimp
  asm volatile("flw     %0,  848(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 c18:	0000                	unimp
 c1a:	00068223          	sb	x0,4(x13)
  asm volatile("flw     %0,  848(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 c1e:	6400                	flw	f8,8(x8)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 c20:	000e                	c.slli	x0,0x3
 c22:	0c00                	addi	x8,x2,528
  asm volatile("flw     %0,  852(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 c24:	0000                	unimp
 c26:	0100                	addi	x8,x2,128
  asm volatile("flw     %0,  852(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 c28:	19f6                	slli	x19,x19,0x3d
 c2a:	da24                	sw	x9,112(x12)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 c2c:	0001                	nop
 c2e:	8c00                	0x8c00
  asm volatile("flw     %0,  856(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 c30:	0006                	c.slli	x0,0x1
 c32:	1a00                	addi	x8,x2,304
  asm volatile("flw     %0,  856(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 c34:	0e64                	addi	x9,x2,796
 c36:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 c38:	0004                	0x4
 c3a:	0000                	unimp
  asm volatile("flw     %0,  860(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 c3c:	b826                	fsd	f9,48(x2)
 c3e:	0001                	nop
  asm volatile("flw     %0,  860(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 c40:	9600                	0x9600
 c42:	0006                	c.slli	x0,0x1
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 c44:	0000                	unimp
 c46:	0000                	unimp
  asm volatile("flw     %0,  864(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 c48:	0000                	unimp
 c4a:	d00e                	sw	x3,32(x2)
  asm volatile("flw     %0,  864(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 c4c:	0f000007          	0xf000007
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 c50:	0176                	slli	x2,x2,0x1d
 c52:	0000                	unimp
  asm volatile("flw     %0,  868(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 c54:	ff00                	fsw	f8,56(x14)
 c56:	0d00                	addi	x8,x2,656
  asm volatile("flw     %0,  868(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 c58:	0305                	addi	x6,x6,1
 c5a:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 c5c:	0404                	addi	x9,x2,512
 c5e:	d011                	beqz	x8,b62 <_gp+0x35a>
  asm volatile("flw     %0,  872(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 c60:	00000007          	0x7

Disassembly of section .debug_abbrev:

00000000 <.debug_abbrev>:
  li  x1, 0
   0:	1101                	addi	x2,x2,-32
   2:	1000                	addi	x8,x2,32
  li  x3, 0
   4:	1106                	slli	x2,x2,0x21
   6:	1201                	addi	x4,x4,-32
  li  x4, 0
   8:	0301                	addi	x6,x6,0
   a:	1b0e                	slli	x22,x22,0x23
  li  x5, 0
   c:	250e                	fld	f10,192(x2)
   e:	130e                	slli	x6,x6,0x23
  li  x6, 0
  10:	0005                	c.nop	1
  12:	0000                	unimp
  li  x7, 0
  14:	1101                	addi	x2,x2,-32
  16:	2501                	jal	616 <kernel_energy_fadd_demo+0x436>
  li  x8, 0
  18:	130e                	slli	x6,x6,0x23
  1a:	1b0e030b          	0x1b0e030b
  li  x9, 0
  1e:	110e                	slli	x2,x2,0x23
  li  x10,0
  20:	1201                	addi	x4,x4,-32
  22:	1006                	c.slli	x0,0x21
  li  x11,0
  24:	02000017          	auipc	x0,0x2000
  li  x12,0
  28:	0016                	c.slli	x0,0x5
  2a:	0b3a0e03          	lb	x28,179(x20) # b3 <__dmem_end+0x4b>
  li  x13,0
  2e:	0b390b3b          	0xb390b3b
  li  x14,0
  32:	1349                	addi	x6,x6,-14
  li  x15,0
  34:	0000                	unimp
  36:	0b000f03          	lb	x30,176(x0) # b0 <__dmem_end+0x48>
  li  x16,0
  3a:	0013490b          	0x13490b
  li  x17,0
  3e:	0400                	addi	x8,x2,512
  li  x18,0
  40:	0024                	addi	x9,x2,8
  42:	0b3e0b0b          	0xb3e0b0b
  li  x19,0
  46:	00000803          	lb	x16,0(x0) # 0 <_bsg_data_start_addr>
  li  x20,0
  4a:	3505                	jal	fffffe6a <_bsg_dram_end_addr+0x7efffe6a>
  li  x21,0
  4c:	4900                	lw	x8,16(x10)
  4e:	06000013          	li	x0,96
  li  x22,0
  52:	0024                	addi	x9,x2,8
  li  x23,0
  54:	0b3e0b0b          	0xb3e0b0b
  li  x24,0
  58:	00000e03          	lb	x28,0(x0) # 0 <_bsg_data_start_addr>
  li  x25,0
  5c:	03003407          	fld	f8,48(x0) # 30 <__bsg_x+0x4>
  li  x26,0
  60:	3a0e                	fld	f20,224(x2)
  62:	390b3b0b          	0x390b3b0b
  li  x27,0
  66:	3f13490b          	0x3f13490b
  li  x28,0
  6a:	3c19                	jal	fffffa80 <_bsg_dram_end_addr+0x7efffa80>
  li  x29,0
  6c:	0019                	c.nop	6
  6e:	0800                	addi	x8,x2,16
  li  x30,0
  70:	012e                	slli	x2,x2,0xb
  72:	0e03193f 0b3b0b3a 	0xb3b0b3a0e03193f
  li t0, 0x00003000 # mstatus.FS
  7a:	0b39                	addi	x22,x22,14
  csrs mstatus, t0 # enable FPU
  7c:	0111                	addi	x2,x2,4
  7e:	0612                	slli	x12,x12,0x4
  fscsr x0
  80:	1840                	addi	x8,x2,52
  82:	00194297          	auipc	x5,0x194
  li t0, 0
  86:	0900                	addi	x8,x2,144
  fcvt.s.w f0, x0 
  88:	0034                	addi	x13,x2,8
  8a:	0b3a0e03          	lb	x28,179(x20)
  fcvt.s.w f1, x0 
  8e:	0b390b3b          	0xb390b3b
  fcvt.s.w f2, x0 
  92:	1349                	addi	x6,x6,-14
  fcvt.s.w f3, x0 
  94:	0000                	unimp
  96:	340a                	fld	f8,160(x2)
  fcvt.s.w f4, x0 
  98:	0300                	addi	x8,x2,384
  9a:	3a0e                	fld	f20,224(x2)
  fcvt.s.w f5, x0 
  9c:	390b3b0b          	0x390b3b0b
  fcvt.s.w f6, x0 
  a0:	0213490b          	0x213490b
  fcvt.s.w f7, x0 
  a4:	0018                	0x18
  a6:	0b00                	addi	x8,x2,400
  fcvt.s.w f8, x0 
  a8:	0111010b          	0x111010b
  fcvt.s.w f9, x0 
  ac:	0612                	slli	x12,x12,0x4
  ae:	0000                	unimp
  fcvt.s.w f10,x0 
  b0:	340c                	fld	f11,40(x8)
  b2:	0300                	addi	x8,x2,384
  fcvt.s.w f11,x0 
  b4:	3a08                	fld	f10,48(x12)
  b6:	390b3b0b          	0x390b3b0b
  fcvt.s.w f12,x0 
  ba:	0213490b          	0x213490b
  fcvt.s.w f13,x0 
  be:	00000017          	auipc	x0,0x0
  fcvt.s.w f14,x0 
  c2:	1101                	addi	x2,x2,-32
  fcvt.s.w f15,x0 
  c4:	2501                	jal	6c4 <kernel_energy_fadd_demo+0x4e4>
  c6:	130e                	slli	x6,x6,0x23
  fcvt.s.w f16,x0 
  c8:	1b0e030b          	0x1b0e030b
  fcvt.s.w f17,x0 
  cc:	100e                	c.slli	x0,0x23
  ce:	02000017          	auipc	x0,0x2000
  fcvt.s.w f18,x0 
  d2:	0034                	addi	x13,x2,8
  fcvt.s.w f19,x0 
  d4:	0b3a0e03          	lb	x28,179(x20)
  fcvt.s.w f20,x0 
  d8:	0b390b3b          	0xb390b3b
  fcvt.s.w f21,x0 
  dc:	1349                	addi	x6,x6,-14
  de:	1802193f 24030000 	0x240300001802193f
  fcvt.s.w f23,x0 
  e6:	0b00                	addi	x8,x2,400
  fcvt.s.w f24,x0 
  e8:	030b3e0b          	0x30b3e0b
  fcvt.s.w f25,x0 
  ec:	0008                	0x8
  ee:	0000                	unimp
  fcvt.s.w f26,x0 
  f0:	1101                	addi	x2,x2,-32
  f2:	2501                	jal	6f2 <kernel_energy_fadd_demo+0x512>
  fcvt.s.w f27,x0 
  f4:	130e                	slli	x6,x6,0x23
  f6:	1b0e030b          	0x1b0e030b
  fcvt.s.w f28,x0 
  fa:	550e                	lw	x10,224(x2)
  fcvt.s.w f29,x0 
  fc:	10011117          	auipc	x2,0x10011
  fcvt.s.w f30,x0 
 100:	02000017          	auipc	x0,0x2000
  fcvt.s.w f31,x0 
 104:	0024                	addi	x9,x2,8
 106:	0b3e0b0b          	0xb3e0b0b
  la gp, _gp
 10a:	00000803          	lb	x16,0(x0) # 0 <_bsg_data_start_addr>
 10e:	0b002403          	lw	x8,176(x0) # b0 <__dmem_end+0x48>
  la  tp, _bsg_data_end_addr + 63
 112:	030b3e0b          	0x30b3e0b
 116:	000e                	c.slli	x0,0x3
  and tp, tp, -64
 118:	0400                	addi	x8,x2,512
 11a:	0034                	addi	x13,x2,8
  la sp, _sp
 11c:	0b3a0e03          	lb	x28,179(x20)
 120:	0b390b3b          	0xb390b3b
  j main
 124:	1349                	addi	x6,x6,-14
 126:	193c193f 16050000 	0x16050000193c193f
  bsg_remote_store(0,0,bsg_x_v,0);
 12e:	0300                	addi	x8,x2,384
 130:	3a0e                	fld	f20,224(x2)
 132:	390b3b0b          	0x390b3b0b
  bsg_remote_store(0,0,bsg_y_v,0);
 136:	0013490b          	0x13490b
  bsg_remote_store(0,0,bsg_x_v,0);
 13a:	0600                	addi	x8,x2,768
  bsg_remote_store(0,0,bsg_y_v,0);
 13c:	0034                	addi	x13,x2,8
 13e:	0b3a0e03          	lb	x28,179(x20)
 142:	0b390b3b          	0xb390b3b
  bsg_wait_while(*bsg_x_v < 0);
 146:	1349                	addi	x6,x6,-14
 148:	1802193f 2e070000 	0x2e0700001802193f
  bsg_wait_while(*bsg_y_v < 0);
 150:	3f01                	jal	60 <barrier+0x8>
 152:	0319                	addi	x6,x6,6
  if (!*bsg_x_v && !*bsg_y_v)
 154:	3a0e                	fld	f20,224(x2)
 156:	390b3b0b          	0x390b3b0b
 15a:	1113490b          	0x1113490b
 15e:	1201                	addi	x4,x4,-32
 160:	4006                	0x4006
 162:	9718                	0x9718
        bsg_remote_store(x,y,bsg_x_v,x);
 164:	1942                	slli	x18,x18,0x30
 166:	1301                	addi	x6,x6,-32
        bsg_remote_store(x,y,bsg_y_v,y);
 168:	0000                	unimp
 16a:	1d08                	addi	x10,x2,688
  grp_org_x_p = bsg_remote_ptr_control( __bsg_x, __bsg_y, CSR_TGO_X );
 16c:	3101                	jal	fffffd6c <_bsg_dram_end_addr+0x7efffd6c>
 16e:	12011113          	0x12011113
 172:	5806                	lw	x16,96(x2)
 174:	570b590b          	0x570b590b
 178:	0900000b          	0x900000b
 17c:	1331010b          	0x1331010b
 180:	0111                	addi	x2,x2,4
 182:	0612                	slli	x12,x12,0x4
 184:	0000                	unimp
 186:	340a                	fld	f8,160(x2)
 188:	3100                	fld	f8,32(x10)
 18a:	00170213          	addi	x4,x14,1
  __bsg_grp_org_x  = * grp_org_x_p;
 18e:	0b00                	addi	x8,x2,400
  grp_org_y_p = bsg_remote_ptr_control( __bsg_x, __bsg_y, CSR_TGO_Y );
 190:	012e                	slli	x2,x2,0xb
 192:	0e03193f 0b3b0b3a 	0xb3b0b3a0e03193f
  __bsg_grp_org_x  = * grp_org_x_p;
 19a:	0b39                	addi	x22,x22,14
  __bsg_grp_org_y  = * grp_org_y_p;
 19c:	1349                	addi	x6,x6,-14
 19e:	0b20                	addi	x8,x2,408
  __bsg_id = __bsg_y * bsg_tiles_X + __bsg_x;
 1a0:	1301                	addi	x6,x6,-32
 1a2:	0000                	unimp
  __bsg_grid_dim_x = 1;
 1a4:	0b0c                	addi	x11,x2,400
 1a6:	0001                	nop
  __bsg_grp_org_y  = * grp_org_y_p;
 1a8:	0d00                	addi	x8,x2,656
 1aa:	0034                	addi	x13,x2,8
  __bsg_id = __bsg_y * bsg_tiles_X + __bsg_x;
 1ac:	0b3a0e03          	lb	x28,179(x20)
  __bsg_grid_dim_x = 1;
 1b0:	0b390b3b          	0xb390b3b
  __bsg_grid_dim_y = 1;
 1b4:	1349                	addi	x6,x6,-14
 1b6:	0000                	unimp
  __bsg_tile_group_id_x = 0;
 1b8:	0f0e                	slli	x30,x30,0x3
 1ba:	0b00                	addi	x8,x2,400
  __bsg_tile_group_id_y = 0;
 1bc:	0013490b          	0x13490b
  __bsg_tile_group_id = 0;
 1c0:	0f00                	addi	x8,x2,912
 1c2:	012e                	slli	x2,x2,0xb
}
 1c4:	1331                	addi	x6,x6,-20
 1c6:	0111                	addi	x2,x2,4
  if (__bsg_id == 0) 
 1c8:	0612                	slli	x12,x12,0x4
 1ca:	1840                	addi	x8,x2,52
 1cc:	00194297          	auipc	x5,0x194
     *signal_ptr = cuda_finish_signal_val;     
 1d0:	0000                	unimp
 1d2:	1101                	addi	x2,x2,-32
 1d4:	2501                	jal	7d4 <kernel_energy_fadd_demo+0x5f4>
 1d6:	130e                	slli	x6,x6,0x23
 1d8:	0305                	addi	x6,x6,1
 1da:	100e                	c.slli	x0,0x23
}
 1dc:	110e1b17          	auipc	x22,0x110e1
int kernel_energy_fadd_demo(float *A, float *B, float *C, int N) {
 1e0:	1201                	addi	x4,x4,-32
 1e2:	0006                	c.slli	x0,0x1
 1e4:	0200                	addi	x8,x2,256
 1e6:	0034                	addi	x13,x2,8
 1e8:	13490e03          	lb	x28,308(x18)
 1ec:	0b3a193f 18020b3b 	0x18020b3b0b3a193f
    asm volatile("flw     %0,    0(%1)"   : "=f"(A_tmp) : "r"(A)     : "memory");
 1f4:	0000                	unimp
 1f6:	36010203          	lb	x4,864(x2) # 1001145c <_bsg_elf_vcache_size+0xff1145c>
 1fa:	0b0e030b          	0xb0e030b
 1fe:	3b0b3a0b          	0x3b0b3a0b
 202:	0400000b          	0x400000b
    asm volatile("fsw     %0,    0(%1)"   :: "f"(A_tmp) , "r"(A_ptr) : "memory");
 206:	000d                	c.nop	3
    asm volatile("flw     %0,    0(%1)"   : "=f"(B_tmp) : "r"(B)     : "memory");
 208:	13490e03          	lb	x28,308(x18)
    asm volatile("flw     %0,    0(%1)"   : "=f"(A_tmp) : "r"(A)     : "memory");
 20c:	0b3a                	slli	x22,x22,0xe
 20e:	0b380b3b          	0xb380b3b
    asm volatile("fsw     %0,    0(%1)"   :: "f"(B_tmp) , "r"(B_ptr) : "memory");
 212:	0000                	unimp
  for(uint32_t i = 0; i < 255; i++) {
 214:	0d05                	addi	x26,x26,1
 216:	0300                	addi	x8,x2,384
 218:	490e                	lw	x18,192(x2)
 21a:	3b0b3a13          	sltiu	x20,x22,944
  bsg_saif_start();
 21e:	3c193f0b          	0x3c193f0b
  asm volatile("flw     %0,    0(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 222:	1c19                	addi	x24,x24,-26
  asm volatile("flw     %0,    0(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 224:	0600000f          	fence	or,unknown
 228:	012e                	slli	x2,x2,0xb
 22a:	0b3a0e03          	lb	x28,179(x20)
 22e:	193c0b3b          	0x193c0b3b
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 232:	0b32193f 05070000 	0x50700000b32193f
  asm volatile("flw     %0,    4(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 23a:	4900                	lw	x8,16(x10)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 23c:	00193413          	seqz	x8,x18
  asm volatile("flw     %0,    8(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 240:	0800                	addi	x8,x2,16
 242:	012e                	slli	x2,x2,0xb
  asm volatile("flw     %0,    8(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 244:	0e6e                	slli	x28,x28,0x1b
 246:	0b3a0e03          	lb	x28,179(x20)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 24a:	193c0b3b          	0x193c0b3b
  asm volatile("flw     %0,   12(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 24e:	0b32193f 2e090000 	0x2e0900000b32193f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 256:	6e01                	0x6e01
  asm volatile("flw     %0,   16(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 258:	030e                	slli	x6,x6,0x3
 25a:	3a0e                	fld	f20,224(x2)
  asm volatile("flw     %0,   16(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 25c:	3c053b0b          	0x3c053b0b
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 260:	3f19                	jal	176 <bsg_set_tile_x_y+0x4e>
 262:	3219                	jal	fffffb68 <_bsg_dram_end_addr+0x7efffb68>
  asm volatile("flw     %0,   20(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 264:	0a00000b          	0xa00000b
  asm volatile("flw     %0,   20(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 268:	0030                	addi	x12,x2,8
 26a:	1349                	addi	x6,x6,-14
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 26c:	0d1c0e03          	lb	x28,209(x24) # fffe50d1 <_bsg_dram_end_addr+0x7efe50d1>
  asm volatile("flw     %0,   24(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 270:	0000                	unimp
 272:	4900050b          	0x4900050b
  asm volatile("flw     %0,   24(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 276:	0c000013          	li	x0,192
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 27a:	0035                	c.nop	13
  asm volatile("flw     %0,   28(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 27c:	1349                	addi	x6,x6,-14
 27e:	0000                	unimp
  asm volatile("flw     %0,   28(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 280:	240d                	jal	4a2 <kernel_energy_fadd_demo+0x2c2>
 282:	0300                	addi	x8,x2,384
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 284:	3e0e                	fld	f28,224(x2)
 286:	000b0b0b          	0xb0b0b
  asm volatile("flw     %0,   32(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 28a:	0e00                	addi	x8,x2,784
  asm volatile("flw     %0,   32(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 28c:	0101                	addi	x2,x2,0
 28e:	1349                	addi	x6,x6,-14
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 290:	0000                	unimp
 292:	4900210f          	0x4900210f
  asm volatile("flw     %0,   36(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 296:	370b2213          	slti	x4,x22,880
  asm volatile("flw     %0,   36(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 29a:	1000000b          	0x1000000b
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 29e:	0024                	addi	x9,x2,8
  asm volatile("flw     %0,   40(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2a0:	0b0b0e03          	lb	x28,176(x22) # 110e128c <_bsg_elf_vcache_size+0x10fe128c>
  asm volatile("flw     %0,   40(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2a4:	0b3e                	slli	x22,x22,0xf
 2a6:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2a8:	0f11                	addi	x30,x30,4
 2aa:	4900                	lw	x8,16(x10)
  asm volatile("flw     %0,   44(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2ac:	12000013          	li	x0,288
  asm volatile("flw     %0,   44(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2b0:	0026                	c.slli	x0,0x9
 2b2:	1349                	addi	x6,x6,-14
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2b4:	0000                	unimp
 2b6:	03013913          	sltiu	x18,x2,48
  asm volatile("flw     %0,   48(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2ba:	000e                	c.slli	x0,0x3
  asm volatile("flw     %0,   48(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2bc:	1400                	addi	x8,x2,544
 2be:	0008                	0x8
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2c0:	0b3a                	slli	x22,x22,0xe
 2c2:	13180b3b          	0x13180b3b
  asm volatile("flw     %0,   52(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2c6:	0000                	unimp
  asm volatile("flw     %0,   52(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2c8:	1615                	addi	x12,x12,-27
 2ca:	4900                	lw	x8,16(x10)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2cc:	3a0e0313          	addi	x6,x28,928 # 1a3a0 <_bsg_elf_stack_ptr+0x193a4>
  asm volatile("flw     %0,   56(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2d0:	000b3b0b          	0xb3b0b
  asm volatile("flw     %0,   56(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2d4:	1600                	addi	x8,x2,800
 2d6:	012e                	slli	x2,x2,0xb
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2d8:	0111                	addi	x2,x2,4
 2da:	0612                	slli	x12,x12,0x4
  asm volatile("flw     %0,   60(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2dc:	1840                	addi	x8,x2,52
 2de:	03194297          	auipc	x5,0x3194
  asm volatile("flw     %0,   60(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2e2:	3a0e                	fld	f20,224(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2e4:	490b3b0b          	0x490b3b0b
  asm volatile("flw     %0,   64(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2e8:	00193f13          	seqz	x30,x18
  asm volatile("flw     %0,   64(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2ec:	1700                	addi	x8,x2,928
 2ee:	0005                	c.nop	1
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2f0:	1702                	slli	x14,x14,0x20
 2f2:	0b3a0e03          	lb	x28,179(x20)
  asm volatile("flw     %0,   68(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2f6:	13490b3b          	0x13490b3b
  asm volatile("flw     %0,   68(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2fa:	0000                	unimp
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2fc:	3418                	fld	f14,40(x8)
 2fe:	0200                	addi	x8,x2,256
  asm volatile("flw     %0,   72(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 300:	0318                	addi	x14,x2,384
 302:	3a0e                	fld	f20,224(x2)
  asm volatile("flw     %0,   72(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 304:	490b3b0b          	0x490b3b0b
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 308:	19000013          	li	x0,400
  asm volatile("flw     %0,   76(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 30c:	0034                	addi	x13,x2,8
 30e:	1702                	slli	x14,x14,0x20
  asm volatile("flw     %0,   76(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 310:	0b3a0e03          	lb	x28,179(x20)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 314:	13490b3b          	0x13490b3b
  asm volatile("flw     %0,   80(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 318:	0000                	unimp
 31a:	0b1a                	slli	x22,x22,0x6
  asm volatile("flw     %0,   80(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 31c:	1101                	addi	x2,x2,-32
 31e:	1201                	addi	x4,x4,-32
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 320:	0006                	c.slli	x0,0x1
 322:	1b00                	addi	x8,x2,432
  asm volatile("flw     %0,   84(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 324:	0034                	addi	x13,x2,8
 326:	0b3a0e03          	lb	x28,179(x20)
  asm volatile("flw     %0,   84(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 32a:	13490b3b          	0x13490b3b
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 32e:	0000                	unimp
  asm volatile("flw     %0,   88(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 330:	2e1c                	fld	f15,24(x12)
 332:	6e01                	0x6e01
  asm volatile("flw     %0,   88(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 334:	470e                	lw	x14,192(x2)
 336:	640b2013          	slti	x0,x22,1600
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 33a:	1d000013          	li	x0,464
  asm volatile("flw     %0,   92(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 33e:	0005                	c.nop	1
  asm volatile("flw     %0,   92(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 340:	13490e03          	lb	x28,308(x18)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 344:	1934                	addi	x13,x2,184
 346:	0000                	unimp
  asm volatile("flw     %0,   96(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 348:	2e1e                	fld	f28,448(x2)
 34a:	0300                	addi	x8,x2,384
  asm volatile("flw     %0,   96(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 34c:	3a0e                	fld	f20,224(x2)
 34e:	200b3b0b          	0x200b3b0b
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 352:	1f00000b          	0x1f00000b
  asm volatile("flw     %0,  100(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 356:	012e                	slli	x2,x2,0xb
  asm volatile("flw     %0,  100(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 358:	0b201347          	fmsub.d	f6,f0,f18,f1,rtz
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 35c:	1364                	addi	x9,x2,428
 35e:	0000                	unimp
  asm volatile("flw     %0,  104(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 360:	0b20                	addi	x8,x2,408
 362:	0001                	nop
  asm volatile("flw     %0,  104(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 364:	2100                	fld	f8,0(x10)
 366:	012e                	slli	x2,x2,0xb
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 368:	0111                	addi	x2,x2,4
 36a:	0612                	slli	x12,x12,0x4
  asm volatile("flw     %0,  108(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 36c:	1840                	addi	x8,x2,52
 36e:	6e194297          	auipc	x5,0x6e194
  asm volatile("flw     %0,  108(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 372:	340e                	fld	f8,224(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 374:	0019                	c.nop	6
 376:	2200                	fld	f8,0(x12)
  asm volatile("flw     %0,  112(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 378:	011d                	addi	x2,x2,7
 37a:	1331                	addi	x6,x6,-20
  asm volatile("flw     %0,  112(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 37c:	0111                	addi	x2,x2,4
 37e:	0612                	slli	x12,x12,0x4
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 380:	0b58                	addi	x14,x2,404
 382:	0b59                	addi	x22,x22,22
  asm volatile("flw     %0,  116(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 384:	0000                	unimp
 386:	31011d23          	sh	x16,794(x2)
  asm volatile("flw     %0,  116(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 38a:	12011113          	0x12011113
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 38e:	5806                	lw	x16,96(x2)
  asm volatile("flw     %0,  120(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 390:	570b590b          	0x570b590b
  asm volatile("flw     %0,  120(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 394:	2400000b          	0x2400000b
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 398:	0005                	c.nop	1
 39a:	1702                	slli	x14,x14,0x20
  asm volatile("flw     %0,  124(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 39c:	1331                	addi	x6,x6,-20
 39e:	0000                	unimp
  asm volatile("flw     %0,  124(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 3a0:	0525                	addi	x10,x10,9
 3a2:	0200                	addi	x8,x2,256
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 3a4:	3118                	fld	f14,32(x10)
 3a6:	26000013          	li	x0,608
  asm volatile("flw     %0,  128(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 3aa:	0034                	addi	x13,x2,8
  asm volatile("flw     %0,  128(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 3ac:	1702                	slli	x14,x14,0x20
 3ae:	1331                	addi	x6,x6,-20
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 3b0:	0000                	unimp
	...

Disassembly of section .debug_aranges:

00000000 <.debug_aranges>:
  li  x1, 0
   0:	001c                	0x1c
   2:	0000                	unimp
  li  x3, 0
   4:	0002                	c.slli64	x0
   6:	0000                	unimp
  li  x4, 0
   8:	0000                	unimp
   a:	0004                	0x4
	...
  li  x7, 0
  14:	012c                	addi	x11,x2,136
	...
  li  x9, 0
  1e:	0000                	unimp
  li  x10,0
  20:	001c                	0x1c
  22:	0000                	unimp
  li  x11,0
  24:	0002                	c.slli64	x0
  26:	0026                	c.slli	x0,0x9
  li  x12,0
  28:	0000                	unimp
  2a:	0004                	0x4
  li  x13,0
  2c:	0000                	unimp
  2e:	0000                	unimp
  li  x14,0
  30:	0128                	addi	x10,x2,136
  32:	0000                	unimp
  li  x15,0
  34:	00a0                	addi	x8,x2,72
	...
  li  x17,0
  3e:	0000                	unimp
  li  x18,0
  40:	0014                	0x14
  42:	0000                	unimp
  li  x19,0
  44:	0002                	c.slli64	x0
  46:	0175                	addi	x2,x2,29
  li  x20,0
  48:	0000                	unimp
  4a:	0004                	0x4
	...
  li  x24,0
  58:	0024                	addi	x9,x2,8
  5a:	0000                	unimp
  li  x25,0
  5c:	0002                	c.slli64	x0
  5e:	024e                	slli	x4,x4,0x13
  li  x26,0
  60:	0000                	unimp
  62:	0004                	0x4
  li  x27,0
  64:	0000                	unimp
  66:	0000                	unimp
  li  x28,0
  68:	01c8                	addi	x10,x2,196
  6a:	0000                	unimp
  li  x29,0
  6c:	0018                	0x18
  6e:	0000                	unimp
  li  x30,0
  70:	0e70                	addi	x12,x2,796
  72:	0000                	unimp
  li  x31,0
  74:	00d4                	addi	x13,x2,68
	...

Disassembly of section .debug_str:

00000000 <.debug_str>:
  li  x1, 0
   0:	726f772f          	0x726f772f
  li  x3, 0
   4:	6c672f6b          	0x6c672f6b
  li  x4, 0
   8:	6c61626f          	jal	x4,166ce <_bsg_elf_stack_ptr+0x156d2>
  li  x5, 0
   c:	38636c2f          	0x38636c2f
  li  x6, 0
  10:	772f3337          	lui	x6,0x772f3
  li  x7, 0
  14:	2f6b726f          	jal	x4,b730a <_bsg_elf_stack_ptr+0xb630e>
  li  x8, 0
  18:	2f686473          	csrrsi	x8,0x2f6,16
  li  x9, 0
  1c:	6c70                	flw	f12,92(x8)
  1e:	7961                	lui	x18,0xffff8
  li  x10,0
  20:	756f7267          	0x756f7267
  li  x11,0
  24:	646e                	flw	f8,216(x2)
  26:	6769622f          	0x6769622f
  li  x12,0
  2a:	6c62                	flw	f24,24(x2)
  li  x13,0
  2c:	6461                	lui	x8,0x18
  2e:	2d65                	jal	6e6 <kernel_energy_fadd_demo+0x506>
  li  x14,0
  30:	6e65                	lui	x28,0x19
  32:	7265                	lui	x4,0xffff9
  li  x15,0
  34:	622f7967          	0x622f7967
  li  x16,0
  38:	625f6773          	csrrsi	x14,0x625,30
  li  x17,0
  3c:	616c                	flw	f11,68(x10)
  3e:	6564                	flw	f9,76(x10)
  li  x18,0
  40:	7572                	flw	f10,60(x2)
  42:	6e6e                	flw	f28,216(x2)
  li  x19,0
  44:	7265                	lui	x4,0xffff9
  46:	6773622f          	0x6773622f
  li  x20,0
  4a:	6d5f 6e61 6379      	0x63796e616d5f
  li  x22,0
  50:	2f65726f          	jal	x4,57346 <_bsg_elf_stack_ptr+0x5634a>
  li  x23,0
  54:	74666f73          	csrrsi	x30,0x746,12
  li  x24,0
  58:	65726177          	0x65726177
  li  x25,0
  5c:	6d70732f          	0x6d70732f
  li  x26,0
  60:	2f64                	fld	f9,216(x14)
  62:	6d6f632f          	0x6d6f632f
  li  x27,0
  66:	6f6d                	lui	x30,0x1b
  li  x28,0
  68:	2f6e                	fld	f30,216(x2)
  6a:	7472632f          	0x7472632f
  li  x29,0
  6e:	532e                	lw	x6,232(x2)
  li  x30,0
  70:	2f00                	fld	f8,24(x14)
  72:	6f68                	flw	f10,92(x14)
  li  x31,0
  74:	656d                	lui	x10,0x1b
  76:	38636c2f          	0x38636c2f
  li t0, 0x00003000 # mstatus.FS
  7a:	772f3337          	lui	x6,0x772f3
  csrs mstatus, t0 # enable FPU
  7e:	2f6b726f          	jal	x4,b7374 <_bsg_elf_stack_ptr+0xb6378>
  fscsr x0
  82:	2f686473          	csrrsi	x8,0x2f6,16
  li t0, 0
  86:	6c70                	flw	f12,92(x8)
  fcvt.s.w f0, x0 
  88:	7961                	lui	x18,0xffff8
  8a:	756f7267          	0x756f7267
  fcvt.s.w f1, x0 
  8e:	646e                	flw	f8,216(x2)
  fcvt.s.w f2, x0 
  90:	6769622f          	0x6769622f
  fcvt.s.w f3, x0 
  94:	6c62                	flw	f24,24(x2)
  96:	6461                	lui	x8,0x18
  fcvt.s.w f4, x0 
  98:	2d65                	jal	750 <kernel_energy_fadd_demo+0x570>
  9a:	6e65                	lui	x28,0x19
  fcvt.s.w f5, x0 
  9c:	7265                	lui	x4,0xffff9
  9e:	622f7967          	0x622f7967
  fcvt.s.w f6, x0 
  a2:	625f6773          	csrrsi	x14,0x625,30
  fcvt.s.w f7, x0 
  a6:	616c                	flw	f11,68(x10)
  fcvt.s.w f8, x0 
  a8:	6564                	flw	f9,76(x10)
  aa:	7572                	flw	f10,60(x2)
  fcvt.s.w f9, x0 
  ac:	6e6e                	flw	f28,216(x2)
  ae:	7265                	lui	x4,0xffff9
  fcvt.s.w f10,x0 
  b0:	6773622f          	0x6773622f
  fcvt.s.w f11,x0 
  b4:	725f 7065 696c      	0x696c7065725f
  fcvt.s.w f12,x0 
  ba:	746e6163          	bltu	x28,x6,7fc <kernel_energy_fadd_demo+0x61c>
  fcvt.s.w f13,x0 
  be:	6178652f          	0x6178652f
  fcvt.s.w f14,x0 
  c2:	706d                	c.lui	x0,0xffffb
  fcvt.s.w f15,x0 
  c4:	656c                	flw	f11,76(x10)
  c6:	75632f73          	csrrs	x30,0x756,x6
  fcvt.s.w f16,x0 
  ca:	6164                	flw	f9,68(x10)
  fcvt.s.w f17,x0 
  cc:	656e652f          	0x656e652f
  fcvt.s.w f18,x0 
  d0:	6772                	flw	f14,28(x2)
  d2:	5f79                	li	x30,-2
  fcvt.s.w f19,x0 
  d4:	6166                	flw	f2,88(x2)
  d6:	6464                	flw	f9,76(x8)
  fcvt.s.w f20,x0 
  d8:	645f 6d65 5f6f      	0x5f6f6d65645f
  fcvt.s.w f21,x0 
  de:	7831                	lui	x16,0xfffec
  fcvt.s.w f22,x0 
  e0:	0031                	c.nop	12
  e2:	20554e47          	fmsub.s	f28,f10,f5,f4,rmm
  fcvt.s.w f23,x0 
  e6:	5341                	li	x6,-16
  fcvt.s.w f24,x0 
  e8:	3220                	fld	f8,96(x12)
  ea:	332e                	fld	f6,232(x2)
  fcvt.s.w f25,x0 
  ec:	0032                	c.slli	x0,0xc
  ee:	726f6873          	csrrsi	x16,0x726,30
  fcvt.s.w f26,x0 
  f2:	2074                	fld	f13,192(x8)
  fcvt.s.w f27,x0 
  f4:	6e75                	lui	x28,0x1d
  f6:	6e676973          	csrrsi	x18,0x6e6,14
  fcvt.s.w f28,x0 
  fa:	6465                	lui	x8,0x19
  fcvt.s.w f29,x0 
  fc:	6920                	flw	f8,80(x10)
  fe:	746e                	flw	f8,248(x2)
  fcvt.s.w f30,x0 
 100:	4700                	lw	x8,8(x14)
 102:	554e                	lw	x10,240(x2)
  fcvt.s.w f31,x0 
 104:	4320                	lw	x8,64(x14)
 106:	3939                	jal	fffffd24 <_bsg_dram_end_addr+0x7efffd24>
  la gp, _gp
 108:	3920                	fld	f8,112(x10)
 10a:	322e                	fld	f4,232(x2)
 10c:	302e                	fld	f0,232(x2)
 10e:	2d20                	fld	f8,88(x10)
  la  tp, _bsg_data_end_addr + 63
 110:	6e6d                	lui	x28,0x1b
 112:	64662d6f          	jal	x26,62758 <_bsg_elf_stack_ptr+0x6175c>
 116:	7669                	lui	x12,0xffffa
  and tp, tp, -64
 118:	2d20                	fld	f8,88(x10)
 11a:	616d                	addi	x2,x2,240
  la sp, _sp
 11c:	6372                	flw	f6,28(x2)
 11e:	3d68                	fld	f10,248(x10)
 120:	7672                	flw	f12,60(x2)
 122:	6d693233          	0x6d693233
  j main
 126:	6661                	lui	x12,0x18
  bsg_remote_store(0,0,bsg_x_v,0);
 128:	2d20                	fld	f8,88(x10)
 12a:	746d                	lui	x8,0xffffb
 12c:	6e75                	lui	x28,0x1d
 12e:	3d65                	jal	ffffffe6 <_bsg_dram_end_addr+0x7effffe6>
 130:	6f72                	flw	f30,28(x2)
 132:	74656b63          	bltu	x10,x6,888 <_gp+0x80>
  bsg_remote_store(0,0,bsg_y_v,0);
 136:	2d20                	fld	f8,88(x10)
  bsg_remote_store(0,0,bsg_x_v,0);
 138:	616d                	addi	x2,x2,240
 13a:	6962                	flw	f18,24(x2)
  bsg_remote_store(0,0,bsg_y_v,0);
 13c:	693d                	lui	x18,0xf
 13e:	706c                	flw	f11,100(x8)
 140:	20663233          	0x20663233
  bsg_wait_while(*bsg_x_v < 0);
 144:	672d                	lui	x14,0xb
 146:	2d20                	fld	f8,88(x10)
 148:	2d20324f          	0x2d20324f
  bsg_wait_while(*bsg_y_v < 0);
 14c:	3d647473          	csrrci	x8,0x3d6,8
 150:	39756e67          	0x39756e67
  if (!*bsg_x_v && !*bsg_y_v)
 154:	2039                	jal	162 <bsg_set_tile_x_y+0x3a>
 156:	662d                	lui	x12,0xb
 158:	6572                	flw	f10,28(x2)
 15a:	7572                	flw	f10,60(x2)
 15c:	2d6e                	fld	f26,216(x2)
 15e:	2d657363          	bgeu	x10,x22,424 <kernel_energy_fadd_demo+0x244>
 162:	6661                	lui	x12,0x18
        bsg_remote_store(x,y,bsg_x_v,x);
 164:	6574                	flw	f13,76(x10)
 166:	2d72                	fld	f26,280(x2)
        bsg_remote_store(x,y,bsg_y_v,y);
 168:	6f6c                	flw	f11,92(x14)
 16a:	2d20706f          	j	743c <_bsg_elf_stack_ptr+0x6440>
  grp_org_x_p = bsg_remote_ptr_control( __bsg_x, __bsg_y, CSR_TGO_X );
 16e:	7766                	flw	f14,120(x2)
 170:	6265                	lui	x4,0x19
 172:	2d20                	fld	f8,88(x10)
 174:	7266                	flw	f4,120(x2)
 176:	6e65                	lui	x28,0x19
 178:	6d61                	lui	x26,0x18
 17a:	2d65                	jal	832 <_gp+0x2a>
 17c:	6572                	flw	f10,28(x2)
 17e:	74736967          	0x74736967
 182:	7265                	lui	x4,0xffff9
 184:	662d2073          	csrs	0x662,x26
 188:	6166                	flw	f2,88(x2)
 18a:	6d2d7473          	csrrci	x8,0x6d2,26
  __bsg_grp_org_x  = * grp_org_x_p;
 18e:	7461                	lui	x8,0xffff8
  grp_org_y_p = bsg_remote_ptr_control( __bsg_x, __bsg_y, CSR_TGO_Y );
 190:	2068                	fld	f10,192(x8)
 192:	662d                	lui	x12,0xb
 194:	6f6e                	flw	f30,216(x2)
 196:	632d                	lui	x6,0xb
  __bsg_grp_org_x  = * grp_org_x_p;
 198:	6f6d6d6f          	jal	x26,d688e <_bsg_elf_stack_ptr+0xd5892>
  __bsg_grp_org_y  = * grp_org_y_p;
 19c:	206e                	fld	f0,216(x2)
 19e:	662d                	lui	x12,0xb
  __bsg_id = __bsg_y * bsg_tiles_X + __bsg_x;
 1a0:	7066                	flw	f0,120(x2)
 1a2:	632d                	lui	x6,0xb
  __bsg_grid_dim_x = 1;
 1a4:	72746e6f          	jal	x28,470ca <_bsg_elf_stack_ptr+0x460ce>
  __bsg_grp_org_y  = * grp_org_y_p;
 1a8:	6361                	lui	x6,0x18
 1aa:	3d74                	fld	f13,248(x10)
  __bsg_id = __bsg_y * bsg_tiles_X + __bsg_x;
 1ac:	0066666f          	jal	x12,661b2 <_bsg_elf_stack_ptr+0x651b6>
  __bsg_grid_dim_x = 1;
 1b0:	5f5f 7362 5f67      	0x5f6773625f5f
  __bsg_grid_dim_y = 1;
 1b6:	6469                	lui	x8,0x1a
  __bsg_tile_group_id_x = 0;
 1b8:	5f00                	lw	x8,56(x14)
 1ba:	625f 6773 795f      	0x795f6773625f
  __bsg_tile_group_id = 0;
 1c0:	6200                	flw	f8,0(x12)
 1c2:	795f6773          	csrrsi	x14,0x795,30
}
 1c6:	765f 5f00 625f      	0x625f5f00765f
  if (__bsg_id == 0) 
 1cc:	745f6773          	csrrsi	x14,0x745,30
     *signal_ptr = cuda_finish_signal_val;     
 1d0:	6c69                	lui	x24,0x1a
 1d2:	5f65                	li	x30,-7
 1d4:	756f7267          	0x756f7267
 1d8:	5f70                	lw	x12,124(x14)
 1da:	6469                	lui	x8,0x1a
}
 1dc:	785f 5f00 625f      	0x625f5f00785f
int kernel_energy_fadd_demo(float *A, float *B, float *C, int N) {
 1e2:	745f6773          	csrrsi	x14,0x745,30
 1e6:	6c69                	lui	x24,0x1a
 1e8:	5f65                	li	x30,-7
 1ea:	756f7267          	0x756f7267
 1ee:	5f70                	lw	x12,124(x14)
 1f0:	6469                	lui	x8,0x1a
 1f2:	795f 7500 736e      	0x736e7500795f
    asm volatile("flw     %0,    0(%1)"   : "=f"(A_tmp) : "r"(A)     : "memory");
 1f8:	6769                	lui	x14,0x1a
 1fa:	656e                	flw	f10,216(x2)
 1fc:	2064                	fld	f9,192(x8)
 1fe:	72616863          	bltu	x2,x6,92e <_gp+0x126>
 202:	6700                	flw	f8,8(x14)
    asm volatile("fsw     %0,    0(%1)"   :: "f"(A_tmp) , "r"(A_ptr) : "memory");
 204:	7072                	flw	f0,60(x2)
 206:	6f5f 6772 785f      	0x785f67726f5f
    asm volatile("flw     %0,    0(%1)"   : "=f"(A_tmp) : "r"(A)     : "memory");
 20c:	705f 5f00 625f      	0x625f5f00705f
    asm volatile("fsw     %0,    0(%1)"   :: "f"(B_tmp) , "r"(B_ptr) : "memory");
 212:	675f6773          	csrrsi	x14,0x675,30
  for(uint32_t i = 0; i < 255; i++) {
 216:	7072                	flw	f0,60(x2)
 218:	6f5f 6772 785f      	0x785f67726f5f
  bsg_saif_start();
 21e:	6200                	flw	f8,0(x12)
  asm volatile("flw     %0,    0(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 220:	725f6773          	csrrsi	x14,0x725,30
  asm volatile("flw     %0,    0(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 224:	6d65                	lui	x26,0x19
 226:	5f65746f          	jal	x8,5781c <_bsg_elf_stack_ptr+0x56820>
 22a:	6e69                	lui	x28,0x1a
 22c:	5f74                	lw	x13,124(x14)
 22e:	7470                	flw	f12,108(x8)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 230:	0072                	c.slli	x0,0x1c
 232:	7362                	flw	f6,56(x2)
  asm volatile("flw     %0,    4(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 234:	5f785f67          	0x5f785f67
  asm volatile("flw     %0,    4(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 238:	0076                	c.slli	x0,0x1d
 23a:	7362                	flw	f6,56(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 23c:	65735f67          	0x65735f67
  asm volatile("flw     %0,    8(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 240:	5f74                	lw	x13,124(x14)
 242:	6974                	flw	f13,84(x10)
  asm volatile("flw     %0,    8(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 244:	656c                	flw	f11,76(x10)
 246:	785f 795f 5f00      	0x5f00795f785f
  asm volatile("flw     %0,   12(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 24c:	625f 6773 785f      	0x785f6773625f
  asm volatile("flw     %0,   12(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 252:	2f00                	fld	f8,24(x14)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 254:	6b726f77          	0x6b726f77
  asm volatile("flw     %0,   16(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 258:	6f6c672f          	0x6f6c672f
  asm volatile("flw     %0,   16(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 25c:	6162                	flw	f2,24(x2)
 25e:	2f6c                	fld	f11,216(x14)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 260:	636c                	flw	f11,68(x14)
 262:	3738                	fld	f14,104(x14)
  asm volatile("flw     %0,   20(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 264:	6f772f33          	0x6f772f33
  asm volatile("flw     %0,   20(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 268:	6b72                	flw	f22,28(x2)
 26a:	6864732f          	0x6864732f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 26e:	616c702f          	0x616c702f
  asm volatile("flw     %0,   24(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 272:	6779                	lui	x14,0x1e
  asm volatile("flw     %0,   24(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 274:	6f72                	flw	f30,28(x2)
 276:	6e75                	lui	x28,0x1d
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 278:	2f64                	fld	f9,216(x14)
 27a:	6962                	flw	f18,24(x2)
  asm volatile("flw     %0,   28(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 27c:	616c6267          	0x616c6267
  asm volatile("flw     %0,   28(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 280:	6564                	flw	f9,76(x10)
 282:	652d                	lui	x10,0xb
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 284:	656e                	flw	f10,216(x2)
 286:	6772                	flw	f14,28(x2)
  asm volatile("flw     %0,   32(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 288:	2f79                	jal	a26 <_gp+0x21e>
 28a:	7362                	flw	f6,56(x2)
  asm volatile("flw     %0,   32(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 28c:	6c625f67          	0x6c625f67
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 290:	6461                	lui	x8,0x18
 292:	7265                	lui	x4,0xffff9
  asm volatile("flw     %0,   36(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 294:	6e75                	lui	x28,0x1d
 296:	656e                	flw	f10,216(x2)
  asm volatile("flw     %0,   36(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 298:	2f72                	fld	f30,280(x2)
 29a:	7362                	flw	f6,56(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 29c:	616d5f67          	0x616d5f67
  asm volatile("flw     %0,   40(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2a0:	796e                	flw	f18,248(x2)
 2a2:	65726f63          	bltu	x4,x23,900 <_gp+0xf8>
  asm volatile("flw     %0,   40(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2a6:	666f732f          	0x666f732f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2aa:	7774                	flw	f13,108(x14)
  asm volatile("flw     %0,   44(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2ac:	7261                	lui	x4,0xffff8
 2ae:	2f65                	jal	a66 <_gp+0x25e>
  asm volatile("flw     %0,   44(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2b0:	7362                	flw	f6,56(x2)
 2b2:	616d5f67          	0x616d5f67
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2b6:	796e                	flw	f18,248(x2)
  asm volatile("flw     %0,   48(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2b8:	65726f63          	bltu	x4,x23,916 <_gp+0x10e>
  asm volatile("flw     %0,   48(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2bc:	6c5f 6269 622f      	0x622f62696c5f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2c2:	735f6773          	csrrsi	x14,0x735,30
  asm volatile("flw     %0,   52(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2c6:	7465                	lui	x8,0xffff9
  asm volatile("flw     %0,   52(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2c8:	745f 6c69 5f65      	0x5f656c69745f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2ce:	5f78                	lw	x14,124(x14)
  asm volatile("flw     %0,   56(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2d0:	2e79                	jal	66e <kernel_energy_fadd_demo+0x48e>
 2d2:	5f5f0063          	beq	x30,x21,8b2 <_gp+0xaa>
  asm volatile("flw     %0,   56(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2d6:	7362                	flw	f6,56(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2d8:	72675f67          	0x72675f67
  asm volatile("flw     %0,   60(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2dc:	6469                	lui	x8,0x1a
 2de:	645f 6d69 785f      	0x785f6d69645f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2e4:	6700                	flw	f8,8(x14)
 2e6:	7072                	flw	f0,60(x2)
  asm volatile("flw     %0,   64(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2e8:	6f5f 6772 795f      	0x795f67726f5f
  asm volatile("flw     %0,   64(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2ee:	705f 5f00 625f      	0x625f5f00705f
  asm volatile("flw     %0,   68(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 2f4:	745f6773          	csrrsi	x14,0x745,30
  asm volatile("flw     %0,   68(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 2f8:	6c69                	lui	x24,0x1a
 2fa:	5f65                	li	x30,-7
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 2fc:	756f7267          	0x756f7267
  asm volatile("flw     %0,   72(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 300:	5f70                	lw	x12,124(x14)
 302:	6469                	lui	x8,0x1a
  asm volatile("flw     %0,   72(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 304:	6600                	flw	f8,8(x12)
 306:	6f6c                	flw	f11,92(x14)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 308:	7461                	lui	x8,0xffff8
 30a:	5f00                	lw	x8,56(x14)
  asm volatile("flw     %0,   76(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 30c:	625f 6773 675f      	0x675f6773625f
  asm volatile("flw     %0,   76(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 312:	7072                	flw	f0,60(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 314:	6f5f 6772 795f      	0x795f67726f5f
  asm volatile("flw     %0,   80(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 31a:	5f00                	lw	x8,56(x14)
  asm volatile("flw     %0,   80(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 31c:	625f 6773 675f      	0x675f6773625f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 322:	6972                	flw	f18,28(x2)
  asm volatile("flw     %0,   84(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 324:	5f64                	lw	x9,124(x14)
 326:	6964                	flw	f9,84(x10)
  asm volatile("flw     %0,   84(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 328:	5f6d                	li	x30,-5
 32a:	0079                	c.nop	30
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 32c:	726f772f          	0x726f772f
  asm volatile("flw     %0,   88(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 330:	6c672f6b          	0x6c672f6b
  asm volatile("flw     %0,   88(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 334:	6c61626f          	jal	x4,169fa <_bsg_elf_stack_ptr+0x159fe>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 338:	38636c2f          	0x38636c2f
  asm volatile("flw     %0,   92(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 33c:	772f3337          	lui	x6,0x772f3
  asm volatile("flw     %0,   92(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 340:	2f6b726f          	jal	x4,b7636 <_bsg_elf_stack_ptr+0xb663a>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 344:	2f686473          	csrrsi	x8,0x2f6,16
  asm volatile("flw     %0,   96(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 348:	6c70                	flw	f12,92(x8)
 34a:	7961                	lui	x18,0xffff8
  asm volatile("flw     %0,   96(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 34c:	756f7267          	0x756f7267
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 350:	646e                	flw	f8,216(x2)
 352:	6769622f          	0x6769622f
  asm volatile("flw     %0,  100(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 356:	6c62                	flw	f24,24(x2)
  asm volatile("flw     %0,  100(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 358:	6461                	lui	x8,0x18
 35a:	2d65                	jal	a12 <_gp+0x20a>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 35c:	6e65                	lui	x28,0x19
 35e:	7265                	lui	x4,0xffff9
  asm volatile("flw     %0,  104(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 360:	622f7967          	0x622f7967
  asm volatile("flw     %0,  104(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 364:	625f6773          	csrrsi	x14,0x625,30
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 368:	616c                	flw	f11,68(x10)
 36a:	6564                	flw	f9,76(x10)
  asm volatile("flw     %0,  108(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 36c:	7572                	flw	f10,60(x2)
 36e:	6e6e                	flw	f28,216(x2)
  asm volatile("flw     %0,  108(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 370:	7265                	lui	x4,0xffff9
 372:	6773622f          	0x6773622f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 376:	6d5f 6e61 6379      	0x63796e616d5f
  asm volatile("flw     %0,  112(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 37c:	2f65726f          	jal	x4,57672 <_bsg_elf_stack_ptr+0x56676>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 380:	74666f73          	csrrsi	x30,0x746,12
  asm volatile("flw     %0,  116(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 384:	65726177          	0x65726177
  asm volatile("flw     %0,  116(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 388:	6773622f          	0x6773622f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 38c:	6d5f 6e61 6379      	0x63796e616d5f
  asm volatile("flw     %0,  120(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 392:	5f65726f          	jal	x4,57988 <_bsg_elf_stack_ptr+0x5698c>
  asm volatile("flw     %0,  120(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 396:	696c                	flw	f11,84(x10)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 398:	2f62                	fld	f30,24(x2)
 39a:	7362                	flw	f6,56(x2)
  asm volatile("flw     %0,  124(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 39c:	69745f67          	0x69745f67
  asm volatile("flw     %0,  124(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 3a0:	656c                	flw	f11,76(x10)
 3a2:	635f 6e6f 6966      	0x69666e6f635f
  asm volatile("flw     %0,  128(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 3a8:	61765f67          	0x61765f67
  asm volatile("flw     %0,  128(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 3ac:	7372                	flw	f6,60(x2)
 3ae:	632e                	flw	f6,200(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 3b0:	5f00                	lw	x8,56(x14)
 3b2:	695f 746e 3233      	0x3233746e695f
  asm volatile("flw     %0,  132(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 3b8:	745f 6300 6475      	0x64756300745f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 3be:	5f61                	li	x30,-8
  asm volatile("flw     %0,  136(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 3c0:	6966                	flw	f18,88(x2)
 3c2:	696e                	flw	f18,216(x2)
  asm volatile("flw     %0,  136(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 3c4:	735f6873          	csrrsi	x16,0x735,30
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 3c8:	6769                	lui	x14,0x1a
 3ca:	616e                	flw	f2,216(x2)
  asm volatile("flw     %0,  140(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 3cc:	5f6c                	lw	x11,124(x14)
 3ce:	6461                	lui	x8,0x18
  asm volatile("flw     %0,  140(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 3d0:	7264                	flw	f9,100(x12)
 3d2:	6300                	flw	f8,0(x14)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 3d4:	6475                	lui	x8,0x1d
 3d6:	5f61                	li	x30,-8
  asm volatile("flw     %0,  144(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 3d8:	7261                	lui	x4,0xffff8
 3da:	705f7667          	0x705f7667
  asm volatile("flw     %0,  144(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 3de:	7274                	flw	f13,100(x12)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 3e0:	6300                	flw	f8,0(x14)
 3e2:	6475                	lui	x8,0x1d
  asm volatile("flw     %0,  148(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 3e4:	5f61                	li	x30,-8
 3e6:	6966                	flw	f18,88(x2)
  asm volatile("flw     %0,  148(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 3e8:	696e                	flw	f18,216(x2)
 3ea:	735f6873          	csrrsi	x16,0x735,30
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 3ee:	6769                	lui	x14,0x1a
  asm volatile("flw     %0,  152(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 3f0:	616e                	flw	f2,216(x2)
 3f2:	5f6c                	lw	x11,124(x14)
  asm volatile("flw     %0,  152(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 3f4:	6176                	flw	f2,92(x2)
 3f6:	006c                	addi	x11,x2,12
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 3f8:	6e676973          	csrrsi	x18,0x6e6,14
  asm volatile("flw     %0,  156(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 3fc:	6c61                	lui	x24,0x18
 3fe:	705f 7274 5f00      	0x5f007274705f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 404:	755f 6e69 3374      	0x33746e69755f
  asm volatile("flw     %0,  160(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 40a:	5f32                	lw	x30,44(x2)
  asm volatile("flw     %0,  160(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 40c:	0074                	addi	x13,x2,12
 40e:	616d                	addi	x2,x2,240
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 410:	6e69                	lui	x28,0x1a
 412:	6c00                	flw	f8,24(x8)
  asm volatile("flw     %0,  164(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 414:	20676e6f          	jal	x28,7661a <_bsg_elf_stack_ptr+0x7561e>
  asm volatile("flw     %0,  164(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 418:	6f6c                	flw	f11,92(x14)
 41a:	676e                	flw	f14,216(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 41c:	6920                	flw	f8,80(x10)
 41e:	746e                	flw	f8,248(x2)
  asm volatile("flw     %0,  168(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 420:	7700                	flw	f8,40(x14)
 422:	6972                	flw	f18,28(x2)
  asm volatile("flw     %0,  168(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 424:	6574                	flw	f13,76(x10)
 426:	665f 6e69 7369      	0x73696e69665f
  asm volatile("flw     %0,  172(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 42c:	5f68                	lw	x10,124(x14)
 42e:	6e676973          	csrrsi	x18,0x6e6,14
  asm volatile("flw     %0,  172(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 432:	6c61                	lui	x24,0x18
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 434:	7300                	flw	f8,32(x14)
 436:	6f68                	flw	f10,92(x14)
  asm volatile("flw     %0,  176(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 438:	7472                	flw	f8,60(x2)
 43a:	6920                	flw	f8,80(x10)
  asm volatile("flw     %0,  176(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 43c:	746e                	flw	f8,248(x2)
 43e:	2f00                	fld	f8,24(x14)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 440:	6b726f77          	0x6b726f77
  asm volatile("flw     %0,  180(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 444:	6f6c672f          	0x6f6c672f
  asm volatile("flw     %0,  180(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 448:	6162                	flw	f2,24(x2)
 44a:	2f6c                	fld	f11,216(x14)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 44c:	636c                	flw	f11,68(x14)
 44e:	3738                	fld	f14,104(x14)
  asm volatile("flw     %0,  184(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 450:	6f772f33          	0x6f772f33
  asm volatile("flw     %0,  184(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 454:	6b72                	flw	f22,28(x2)
 456:	6864732f          	0x6864732f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 45a:	616c702f          	0x616c702f
  asm volatile("flw     %0,  188(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 45e:	6779                	lui	x14,0x1e
  asm volatile("flw     %0,  188(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 460:	6f72                	flw	f30,28(x2)
 462:	6e75                	lui	x28,0x1d
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 464:	2f64                	fld	f9,216(x14)
 466:	6962                	flw	f18,24(x2)
  asm volatile("flw     %0,  192(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 468:	616c6267          	0x616c6267
  asm volatile("flw     %0,  192(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 46c:	6564                	flw	f9,76(x10)
 46e:	652d                	lui	x10,0xb
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 470:	656e                	flw	f10,216(x2)
 472:	6772                	flw	f14,28(x2)
  asm volatile("flw     %0,  196(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 474:	2f79                	jal	c12 <_gp+0x40a>
 476:	7362                	flw	f6,56(x2)
  asm volatile("flw     %0,  196(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 478:	6c625f67          	0x6c625f67
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 47c:	6461                	lui	x8,0x18
 47e:	7265                	lui	x4,0xffff9
  asm volatile("flw     %0,  200(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 480:	6e75                	lui	x28,0x1d
 482:	656e                	flw	f10,216(x2)
  asm volatile("flw     %0,  200(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 484:	2f72                	fld	f30,280(x2)
 486:	7362                	flw	f6,56(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 488:	616d5f67          	0x616d5f67
  asm volatile("flw     %0,  204(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 48c:	796e                	flw	f18,248(x2)
 48e:	65726f63          	bltu	x4,x23,aec <_gp+0x2e4>
  asm volatile("flw     %0,  204(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 492:	666f732f          	0x666f732f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 496:	7774                	flw	f13,108(x14)
  asm volatile("flw     %0,  208(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 498:	7261                	lui	x4,0xffff8
 49a:	2f65                	jal	c52 <_gp+0x44a>
  asm volatile("flw     %0,  208(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 49c:	646d7073          	csrci	0x646,26
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 4a0:	73622f2f          	0x73622f2f
  asm volatile("flw     %0,  212(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 4a4:	75635f67          	0x75635f67
  asm volatile("flw     %0,  212(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 4a8:	6164                	flw	f9,68(x10)
 4aa:	6c5f 7469 5f65      	0x5f6574696c5f
  asm volatile("flw     %0,  216(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 4b0:	7572                	flw	f10,60(x2)
 4b2:	746e                	flw	f8,248(x2)
  asm volatile("flw     %0,  216(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 4b4:	6d69                	lui	x26,0x1a
 4b6:	2f65                	jal	c6e <_gp+0x466>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 4b8:	69616d2f          	0x69616d2f
  asm volatile("flw     %0,  220(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 4bc:	2f6e                	fld	f30,216(x2)
 4be:	616d                	addi	x2,x2,240
  asm volatile("flw     %0,  220(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 4c0:	6e69                	lui	x28,0x1a
 4c2:	632e                	flw	f6,200(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 4c4:	6300                	flw	f8,0(x14)
 4c6:	6475                	lui	x8,0x1d
  asm volatile("flw     %0,  224(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 4c8:	5f61                	li	x30,-8
 4ca:	6e72656b          	0x6e72656b
  asm volatile("flw     %0,  224(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 4ce:	6c65                	lui	x24,0x19
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 4d0:	705f 7274 6300      	0x63007274705f
  asm volatile("flw     %0,  228(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 4d6:	6475                	lui	x8,0x1d
  asm volatile("flw     %0,  228(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 4d8:	5f61                	li	x30,-8
 4da:	7261                	lui	x4,0xffff8
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 4dc:	6c006367          	0x6c006367
  asm volatile("flw     %0,  232(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 4e0:	20676e6f          	jal	x28,766e6 <_bsg_elf_stack_ptr+0x756ea>
  asm volatile("flw     %0,  232(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 4e4:	6f6c                	flw	f11,92(x14)
 4e6:	676e                	flw	f14,216(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 4e8:	7520                	flw	f8,104(x10)
 4ea:	736e                	flw	f6,248(x2)
  asm volatile("flw     %0,  236(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 4ec:	6769                	lui	x14,0x1a
 4ee:	656e                	flw	f10,216(x2)
  asm volatile("flw     %0,  236(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 4f0:	2064                	fld	f9,192(x8)
 4f2:	6e69                	lui	x28,0x1a
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 4f4:	0074                	addi	x13,x2,12
 4f6:	61647563          	bgeu	x8,x22,b00 <_gp+0x2f8>
  asm volatile("flw     %0,  240(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 4fa:	6b5f 7265 656e      	0x656e72656b5f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 500:	5f6c                	lw	x11,124(x14)
 502:	6f6e                	flw	f30,216(x2)
  asm volatile("flw     %0,  244(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 504:	5f74                	lw	x13,124(x14)
 506:	6f6c                	flw	f11,92(x14)
  asm volatile("flw     %0,  244(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 508:	6461                	lui	x8,0x18
 50a:	6465                	lui	x8,0x19
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 50c:	765f 6c61 6300      	0x63006c61765f
  asm volatile("flw     %0,  248(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 512:	616c                	flw	f11,68(x10)
  asm volatile("flw     %0,  248(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 514:	676e                	flw	f14,216(x2)
 516:	7620                	flw	f8,104(x12)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 518:	7265                	lui	x4,0xffff9
 51a:	6e6f6973          	csrrsi	x18,0x6e6,30
  asm volatile("flw     %0,  252(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 51e:	3120                	fld	f8,96(x10)
  asm volatile("flw     %0,  252(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 520:	2e30                	fld	f12,88(x12)
 522:	2e30                	fld	f12,88(x12)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 524:	2030                	fld	f12,64(x8)
 526:	6828                	flw	f10,80(x8)
  asm volatile("flw     %0,  256(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 528:	7474                	flw	f13,108(x8)
 52a:	7370                	flw	f12,100(x14)
  asm volatile("flw     %0,  256(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 52c:	2f3a                	fld	f30,392(x2)
 52e:	7469672f          	0x7469672f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 532:	7568                	flw	f10,108(x10)
  asm volatile("flw     %0,  260(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 534:	2e62                	fld	f28,24(x2)
 536:	2f6d6f63          	bltu	x26,x22,834 <_gp+0x2c>
  asm volatile("flw     %0,  260(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 53a:	6562                	flw	f10,24(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 53c:	6b6f7073          	csrci	0x6b6,30
  asm volatile("flw     %0,  264(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 540:	2d65                	jal	bf8 <_gp+0x3f0>
 542:	696c6973          	csrrsi	x18,0x696,24
  asm volatile("flw     %0,  264(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 546:	2d6e6f63          	bltu	x28,x22,824 <_gp+0x1c>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 54a:	756f7267          	0x756f7267
  asm volatile("flw     %0,  268(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 54e:	2f70                	fld	f12,216(x14)
  asm volatile("flw     %0,  268(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 550:	6c6c                	flw	f11,92(x8)
 552:	6d76                	flw	f26,92(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 554:	702d                	c.lui	x0,0xfffeb
 556:	6f72                	flw	f30,28(x2)
  asm volatile("flw     %0,  272(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 558:	656a                	flw	f10,152(x2)
 55a:	672e7463          	bgeu	x28,x18,bc2 <_gp+0x3ba>
  asm volatile("flw     %0,  272(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 55e:	7469                	lui	x8,0xffffa
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 560:	3220                	fld	f8,96(x12)
 562:	6536                	flw	f10,76(x2)
  asm volatile("flw     %0,  276(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 564:	3064                	fld	f9,224(x8)
 566:	3462                	fld	f8,56(x2)
  asm volatile("flw     %0,  276(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 568:	6636                	flw	f12,76(x2)
 56a:	6334                	flw	f13,64(x14)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 56c:	6336                	flw	f6,76(x2)
 56e:	3630                	fld	f12,104(x12)
  asm volatile("flw     %0,  280(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 570:	3461                	jal	fffffff8 <_bsg_dram_end_addr+0x7efffff8>
 572:	6666                	flw	f12,88(x2)
  asm volatile("flw     %0,  280(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 574:	65323437          	lui	x8,0x65323
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 578:	3966                	fld	f18,120(x2)
 57a:	6539                	lui	x10,0xe
  asm volatile("flw     %0,  284(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 57c:	3138                	fld	f14,96(x10)
 57e:	6230                	flw	f12,64(x12)
  asm volatile("flw     %0,  284(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 580:	62373337          	lui	x6,0x62373
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 584:	6431                	lui	x8,0xc
 586:	6138                	flw	f14,64(x10)
  asm volatile("flw     %0,  288(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 588:	2932                	fld	f18,264(x2)
 58a:	7200                	flw	f8,32(x12)
  asm volatile("flw     %0,  288(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 58c:	625f 7261 6972      	0x69727261625f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 592:	7265                	lui	x4,0xffff9
  asm volatile("flw     %0,  292(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 594:	5f00                	lw	x8,56(x14)
 596:	6f6c                	flw	f11,92(x14)
  asm volatile("flw     %0,  292(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 598:	5f6c6163          	bltu	x24,x22,b7a <_gp+0x372>
 59c:	6c61                	lui	x24,0x18
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 59e:	7265                	lui	x4,0xffff9
  asm volatile("flw     %0,  296(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 5a0:	0074                	addi	x13,x2,12
 5a2:	645f 6e6f 5f65      	0x5f656e6f645f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 5a8:	696c                	flw	f11,84(x10)
 5aa:	5f007473          	csrrci	x8,0x5f0,0
  asm volatile("flw     %0,  300(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 5ae:	415f 5252 5941      	0x59415252415f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 5b4:	535f 5a49 5f45      	0x5f455a49535f
  asm volatile("flw     %0,  304(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 5ba:	5954                	lw	x13,52(x10)
  asm volatile("flw     %0,  304(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 5bc:	4550                	lw	x12,12(x10)
 5be:	5f5f 6200 6773      	0x677362005f5f
  asm volatile("flw     %0,  308(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 5c4:	725f 776f 625f      	0x625f776f725f
  asm volatile("flw     %0,  308(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 5ca:	7261                	lui	x4,0xffff8
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 5cc:	6972                	flw	f18,28(x2)
 5ce:	7265                	lui	x4,0xffff9
  asm volatile("flw     %0,  312(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 5d0:	5f00                	lw	x8,56(x14)
 5d2:	4e5a                	lw	x28,148(x2)
  asm volatile("flw     %0,  312(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 5d4:	3531                	jal	3e0 <kernel_energy_fadd_demo+0x200>
 5d6:	7362                	flw	f6,56(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 5d8:	6f725f67          	0x6f725f67
  asm volatile("flw     %0,  316(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 5dc:	61625f77          	0x61625f77
  asm volatile("flw     %0,  316(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 5e0:	7272                	flw	f4,60(x2)
 5e2:	6569                	lui	x10,0x1a
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 5e4:	4972                	lw	x18,28(x2)
 5e6:	694c                	flw	f11,20(x10)
  asm volatile("flw     %0,  320(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 5e8:	4531                	li	x10,12
 5ea:	3545                	jal	48a <kernel_energy_fadd_demo+0x2aa>
  asm volatile("flw     %0,  320(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 5ec:	6572                	flw	f10,28(x2)
 5ee:	45746573          	csrrsi	x10,0x457,8
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 5f2:	0076                	c.slli	x0,0x1d
 5f4:	6572                	flw	f10,28(x2)
  asm volatile("flw     %0,  324(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 5f6:	00746573          	csrrsi	x10,0x7,8
 5fa:	5a5f 314e 6235      	0x6235314e5a5f
  asm volatile("flw     %0,  328(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 600:	725f6773          	csrrsi	x14,0x725,30
  asm volatile("flw     %0,  328(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 604:	625f776f          	jal	x14,f8428 <_bsg_elf_stack_ptr+0xf742c>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 608:	7261                	lui	x4,0xffff8
 60a:	6972                	flw	f18,28(x2)
  asm volatile("flw     %0,  332(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 60c:	7265                	lui	x4,0xffff9
 60e:	4c49                	li	x24,18
  asm volatile("flw     %0,  332(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 610:	3169                	jal	29a <kernel_energy_fadd_demo+0xba>
 612:	4545                	li	x10,17
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 614:	7334                	flw	f13,96(x14)
 616:	6e79                	lui	x28,0x1e
  asm volatile("flw     %0,  336(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 618:	00684563          	blt	x16,x6,622 <kernel_energy_fadd_demo+0x442>
 61c:	5a5f 314e 6235      	0x6235314e5a5f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 622:	725f6773          	csrrsi	x14,0x725,30
  asm volatile("flw     %0,  340(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 626:	625f776f          	jal	x14,f844a <_bsg_elf_stack_ptr+0xf744e>
  asm volatile("flw     %0,  340(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 62a:	7261                	lui	x4,0xffff8
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 62c:	6972                	flw	f18,28(x2)
 62e:	7265                	lui	x4,0xffff9
  asm volatile("flw     %0,  344(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 630:	4c49                	li	x24,18
 632:	3169                	jal	2bc <kernel_energy_fadd_demo+0xdc>
  asm volatile("flw     %0,  344(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 634:	4545                	li	x10,17
 636:	6135                	addi	x2,x2,352
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 638:	656c                	flw	f11,76(x10)
 63a:	7472                	flw	f8,60(x2)
  asm volatile("flw     %0,  348(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 63c:	7645                	lui	x12,0xffff1
 63e:	5f00                	lw	x8,56(x14)
  asm volatile("flw     %0,  348(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 640:	4e5a                	lw	x28,148(x2)
 642:	3531                	jal	44e <kernel_energy_fadd_demo+0x26e>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 644:	7362                	flw	f6,56(x2)
 646:	6f725f67          	0x6f725f67
  asm volatile("flw     %0,  352(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 64a:	61625f77          	0x61625f77
  asm volatile("flw     %0,  352(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 64e:	7272                	flw	f4,60(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 650:	6569                	lui	x10,0x1a
 652:	4972                	lw	x18,28(x2)
  asm volatile("flw     %0,  356(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 654:	694c                	flw	f11,20(x10)
 656:	4531                	li	x10,12
  asm volatile("flw     %0,  356(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 658:	3145                	jal	2f8 <kernel_energy_fadd_demo+0x118>
 65a:	7732                	flw	f14,44(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 65c:	6961                	lui	x18,0x18
 65e:	5f74                	lw	x13,124(x14)
  asm volatile("flw     %0,  360(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 660:	735f6e6f          	jal	x28,f7594 <_bsg_elf_stack_ptr+0xf6598>
  asm volatile("flw     %0,  360(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 664:	6e79                	lui	x28,0x1e
 666:	00764563          	blt	x12,x7,670 <kernel_energy_fadd_demo+0x490>
 66a:	74696177          	0x74696177
  asm volatile("flw     %0,  364(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 66e:	6f5f 5f6e 7973      	0x79735f6e6f5f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 674:	636e                	flw	f6,216(x2)
 676:	5f00                	lw	x8,56(x14)
  asm volatile("flw     %0,  368(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 678:	4e5a                	lw	x28,148(x2)
 67a:	3531                	jal	486 <kernel_energy_fadd_demo+0x2a6>
  asm volatile("flw     %0,  368(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 67c:	7362                	flw	f6,56(x2)
 67e:	6f725f67          	0x6f725f67
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 682:	61625f77          	0x61625f77
  asm volatile("flw     %0,  372(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 686:	7272                	flw	f4,60(x2)
  asm volatile("flw     %0,  372(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 688:	6569                	lui	x10,0x1a
 68a:	4972                	lw	x18,28(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 68c:	694c                	flw	f11,20(x10)
 68e:	4531                	li	x10,12
  asm volatile("flw     %0,  376(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 690:	3145                	jal	330 <kernel_energy_fadd_demo+0x150>
 692:	69617733          	0x69617733
  asm volatile("flw     %0,  376(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 696:	5f74                	lw	x13,124(x14)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 698:	615f6e6f          	jal	x28,f74ac <_bsg_elf_stack_ptr+0xf64b0>
  asm volatile("flw     %0,  380(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 69c:	656c                	flw	f11,76(x10)
 69e:	7472                	flw	f8,60(x2)
  asm volatile("flw     %0,  380(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 6a0:	7645                	lui	x12,0xffff1
 6a2:	7700                	flw	f8,40(x14)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 6a4:	6961                	lui	x18,0x18
 6a6:	5f74                	lw	x13,124(x14)
  asm volatile("flw     %0,  384(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 6a8:	615f6e6f          	jal	x28,f74bc <_bsg_elf_stack_ptr+0xf64c0>
  asm volatile("flw     %0,  384(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 6ac:	656c                	flw	f11,76(x10)
 6ae:	7472                	flw	f8,60(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 6b0:	4200                	lw	x8,0(x12)
 6b2:	5241                	li	x4,-16
  asm volatile("flw     %0,  388(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 6b4:	4952                	lw	x18,20(x2)
 6b6:	5245                	li	x4,-15
  asm volatile("flw     %0,  388(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 6b8:	585f 445f 4d49      	0x4d49445f585f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 6be:	6200                	flw	f8,0(x12)
  asm volatile("flw     %0,  392(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 6c0:	725f6773          	csrrsi	x14,0x725,30
  asm volatile("flw     %0,  392(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 6c4:	625f776f          	jal	x14,f84e8 <_bsg_elf_stack_ptr+0xf74ec>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 6c8:	7261                	lui	x4,0xffff8
 6ca:	6972                	flw	f18,28(x2)
  asm volatile("flw     %0,  396(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 6cc:	7265                	lui	x4,0xffff9
 6ce:	313c                	fld	f15,96(x10)
  asm volatile("flw     %0,  396(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 6d0:	003e                	c.slli	x0,0xf
 6d2:	61625f63          	bge	x4,x22,cf0 <_gp+0x4e8>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 6d6:	7272                	flw	f4,60(x2)
  asm volatile("flw     %0,  400(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 6d8:	6569                	lui	x10,0x1a
 6da:	0072                	c.slli	x0,0x1c
 6dc:	7362                	flw	f6,56(x2)
  asm volatile("flw     %0,  400(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 6de:	6f635f67          	0x6f635f67
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 6e2:	5f6c                	lw	x11,124(x14)
  asm volatile("flw     %0,  404(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 6e4:	6162                	flw	f2,24(x2)
 6e6:	7272                	flw	f4,60(x2)
  asm volatile("flw     %0,  404(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 6e8:	6569                	lui	x10,0x1a
 6ea:	0072                	c.slli	x0,0x1c
 6ec:	5a5f 314e 6235      	0x6235314e5a5f
  asm volatile("flw     %0,  408(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 6f2:	635f6773          	csrrsi	x14,0x635,30
  asm volatile("flw     %0,  408(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 6f6:	625f6c6f          	jal	x24,f751a <_bsg_elf_stack_ptr+0xf651e>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 6fa:	7261                	lui	x4,0xffff8
  asm volatile("flw     %0,  412(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 6fc:	6972                	flw	f18,28(x2)
 6fe:	7265                	lui	x4,0xffff9
  asm volatile("flw     %0,  412(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 700:	4c49                	li	x24,18
 702:	3169                	jal	38c <kernel_energy_fadd_demo+0x1ac>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 704:	4545                	li	x10,17
 706:	7235                	lui	x4,0xfffed
  asm volatile("flw     %0,  416(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 708:	7365                	lui	x6,0xffff9
 70a:	7465                	lui	x8,0xffff9
  asm volatile("flw     %0,  416(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 70c:	7645                	lui	x12,0xffff1
 70e:	5f00                	lw	x8,56(x14)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 710:	4e5a                	lw	x28,148(x2)
 712:	3531                	jal	51e <kernel_energy_fadd_demo+0x33e>
  asm volatile("flw     %0,  420(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 714:	7362                	flw	f6,56(x2)
 716:	6f635f67          	0x6f635f67
  asm volatile("flw     %0,  420(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 71a:	5f6c                	lw	x11,124(x14)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 71c:	6162                	flw	f2,24(x2)
 71e:	7272                	flw	f4,60(x2)
  asm volatile("flw     %0,  424(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 720:	6569                	lui	x10,0x1a
 722:	4972                	lw	x18,28(x2)
  asm volatile("flw     %0,  424(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 724:	694c                	flw	f11,20(x10)
 726:	4531                	li	x10,12
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 728:	3445                	jal	1c8 <write_finish_signal>
 72a:	636e7973          	csrrci	x18,0x636,28
  asm volatile("flw     %0,  428(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 72e:	6845                	lui	x16,0x11
  asm volatile("flw     %0,  428(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 730:	0068                	addi	x10,x2,12
 732:	5a5f 314e 6235      	0x6235314e5a5f
  asm volatile("flw     %0,  432(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 738:	635f6773          	csrrsi	x14,0x635,30
  asm volatile("flw     %0,  432(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 73c:	625f6c6f          	jal	x24,f7560 <_bsg_elf_stack_ptr+0xf6564>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 740:	7261                	lui	x4,0xffff8
 742:	6972                	flw	f18,28(x2)
  asm volatile("flw     %0,  436(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 744:	7265                	lui	x4,0xffff9
 746:	4c49                	li	x24,18
  asm volatile("flw     %0,  436(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 748:	3169                	jal	3d2 <kernel_energy_fadd_demo+0x1f2>
 74a:	4545                	li	x10,17
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 74c:	6135                	addi	x2,x2,352
 74e:	656c                	flw	f11,76(x10)
  asm volatile("flw     %0,  440(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 750:	7472                	flw	f8,60(x2)
 752:	7645                	lui	x12,0xffff1
  asm volatile("flw     %0,  440(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 754:	5f00                	lw	x8,56(x14)
 756:	4e5a                	lw	x28,148(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 758:	3531                	jal	564 <kernel_energy_fadd_demo+0x384>
 75a:	7362                	flw	f6,56(x2)
  asm volatile("flw     %0,  444(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 75c:	6f635f67          	0x6f635f67
  asm volatile("flw     %0,  444(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 760:	5f6c                	lw	x11,124(x14)
 762:	6162                	flw	f2,24(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 764:	7272                	flw	f4,60(x2)
 766:	6569                	lui	x10,0x1a
  asm volatile("flw     %0,  448(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 768:	4972                	lw	x18,28(x2)
 76a:	694c                	flw	f11,20(x10)
  asm volatile("flw     %0,  448(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 76c:	4531                	li	x10,12
 76e:	3145                	jal	40e <kernel_energy_fadd_demo+0x22e>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 770:	7732                	flw	f14,44(x2)
 772:	6961                	lui	x18,0x18
  asm volatile("flw     %0,  452(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 774:	5f74                	lw	x13,124(x14)
 776:	735f6e6f          	jal	x28,f76aa <_bsg_elf_stack_ptr+0xf66ae>
  asm volatile("flw     %0,  452(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 77a:	6e79                	lui	x28,0x1e
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 77c:	00764563          	blt	x12,x7,786 <kernel_energy_fadd_demo+0x5a6>
 780:	5a5f 314e 6235      	0x6235314e5a5f
  asm volatile("flw     %0,  456(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 786:	635f6773          	csrrsi	x14,0x635,30
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 78a:	625f6c6f          	jal	x24,f75ae <_bsg_elf_stack_ptr+0xf65b2>
  asm volatile("flw     %0,  460(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 78e:	7261                	lui	x4,0xffff8
  asm volatile("flw     %0,  460(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 790:	6972                	flw	f18,28(x2)
 792:	7265                	lui	x4,0xffff9
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 794:	4c49                	li	x24,18
 796:	3169                	jal	420 <kernel_energy_fadd_demo+0x240>
  asm volatile("flw     %0,  464(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 798:	4545                	li	x10,17
 79a:	3331                	jal	4a6 <kernel_energy_fadd_demo+0x2c6>
  asm volatile("flw     %0,  464(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 79c:	74696177          	0x74696177
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 7a0:	6f5f 5f6e 6c61      	0x6c615f6e6f5f
  asm volatile("flw     %0,  468(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 7a6:	7265                	lui	x4,0xffff9
  asm volatile("flw     %0,  468(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 7a8:	4574                	lw	x13,76(x10)
 7aa:	0076                	c.slli	x0,0x1d
 7ac:	4142                	lw	x2,16(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 7ae:	5252                	lw	x4,52(x2)
  asm volatile("flw     %0,  472(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 7b0:	4549                	li	x10,18
 7b2:	5f52                	lw	x30,52(x2)
  asm volatile("flw     %0,  472(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 7b4:	5f59                	li	x30,-10
 7b6:	4944                	lw	x9,20(x10)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 7b8:	004d                	c.nop	19
 7ba:	7362                	flw	f6,56(x2)
  asm volatile("flw     %0,  476(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 7bc:	6f635f67          	0x6f635f67
  asm volatile("flw     %0,  476(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 7c0:	5f6c                	lw	x11,124(x14)
 7c2:	6162                	flw	f2,24(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 7c4:	7272                	flw	f4,60(x2)
 7c6:	6569                	lui	x10,0x1a
  asm volatile("flw     %0,  480(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 7c8:	3c72                	fld	f24,312(x2)
 7ca:	3e31                	jal	2e6 <kernel_energy_fadd_demo+0x106>
  asm volatile("flw     %0,  480(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 7cc:	5f00                	lw	x8,56(x14)
 7ce:	746e6563          	bltu	x28,x6,f18 <__invoke_kernel+0x14>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 7d2:	7265                	lui	x4,0xffff9
  asm volatile("flw     %0,  484(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 7d4:	785f 635f 726f      	0x726f635f785f
  asm volatile("flw     %0,  484(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 7da:	0064                	addi	x9,x2,12
 7dc:	635f 6e65 6574      	0x65746e65635f
  asm volatile("flw     %0,  488(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 7e2:	5f72                	lw	x30,60(x2)
  asm volatile("flw     %0,  488(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 7e4:	5f79                	li	x30,-2
 7e6:	64726f63          	bltu	x4,x7,e44 <_GLOBAL__sub_I_kernel.cpp+0xc>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 7ea:	6200                	flw	f8,0(x12)
  asm volatile("flw     %0,  492(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 7ec:	625f6773          	csrrsi	x14,0x625,30
  asm volatile("flw     %0,  492(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 7f0:	7261                	lui	x4,0xffff8
 7f2:	6972                	flw	f18,28(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 7f4:	7265                	lui	x4,0xffff9
 7f6:	5f00                	lw	x8,56(x14)
  asm volatile("flw     %0,  496(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 7f8:	4e5a                	lw	x28,148(x2)
 7fa:	3131                	jal	406 <kernel_energy_fadd_demo+0x226>
  asm volatile("flw     %0,  496(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 7fc:	7362                	flw	f6,56(x2)
 7fe:	61625f67          	0x61625f67
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 802:	7272                	flw	f4,60(x2)
  asm volatile("flw     %0,  500(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 804:	6569                	lui	x10,0x1a
 806:	4972                	lw	x18,28(x2)
  asm volatile("flw     %0,  500(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 808:	694c                	flw	f11,20(x10)
 80a:	4531                	li	x10,12
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 80c:	694c                	flw	f11,20(x10)
 80e:	4531                	li	x10,12
  asm volatile("flw     %0,  504(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 810:	3545                	jal	6b0 <kernel_energy_fadd_demo+0x4d0>
 812:	6572                	flw	f10,28(x2)
  asm volatile("flw     %0,  504(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 814:	45746573          	csrrsi	x10,0x457,8
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 818:	0076                	c.slli	x0,0x1d
 81a:	5a5f 314e 6231      	0x6231314e5a5f
  asm volatile("flw     %0,  508(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 820:	625f6773          	csrrsi	x14,0x625,30
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 824:	7261                	lui	x4,0xffff8
 826:	6972                	flw	f18,28(x2)
  asm volatile("flw     %0,  512(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 828:	7265                	lui	x4,0xffff9
 82a:	4c49                	li	x24,18
  asm volatile("flw     %0,  512(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 82c:	3169                	jal	4b6 <kernel_energy_fadd_demo+0x2d6>
 82e:	4c45                	li	x24,17
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 830:	3169                	jal	4ba <kernel_energy_fadd_demo+0x2da>
 832:	4545                	li	x10,17
  asm volatile("flw     %0,  516(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 834:	7334                	flw	f13,96(x14)
 836:	6e79                	lui	x28,0x1e
  asm volatile("flw     %0,  516(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 838:	00764563          	blt	x12,x7,842 <_gp+0x3a>
 83c:	7362                	flw	f6,56(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 83e:	61625f67          	0x61625f67
  asm volatile("flw     %0,  520(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 842:	7272                	flw	f4,60(x2)
  asm volatile("flw     %0,  520(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 844:	6569                	lui	x10,0x1a
 846:	3c72                	fld	f24,312(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 848:	2c31                	jal	a64 <_gp+0x25c>
 84a:	3120                	fld	f8,96(x10)
  asm volatile("flw     %0,  524(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 84c:	003e                	c.slli	x0,0xf
 84e:	00647473          	csrrci	x8,0x6,8
 852:	5f5f 6e69 3874      	0x38746e695f5f
  asm volatile("flw     %0,  528(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 858:	745f 5f00 695f      	0x695f5f00745f
  asm volatile("flw     %0,  528(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 85e:	746e                	flw	f8,248(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 860:	3631                	jal	36c <kernel_energy_fadd_demo+0x18c>
 862:	745f 5f00 695f      	0x695f5f00745f
  asm volatile("flw     %0,  532(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 868:	746e                	flw	f8,248(x2)
 86a:	3436                	fld	f8,360(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 86c:	745f 5f00 695f      	0x695f5f00745f
  asm volatile("flw     %0,  536(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 872:	746e                	flw	f8,248(x2)
  asm volatile("flw     %0,  536(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 874:	6c5f 6165 7473      	0x747361656c5f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 87a:	5f38                	lw	x14,120(x14)
  asm volatile("flw     %0,  540(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 87c:	0074                	addi	x13,x2,12
 87e:	5f5f 6e69 5f74      	0x5f746e695f5f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 884:	656c                	flw	f11,76(x10)
 886:	7361                	lui	x6,0xffff8
  asm volatile("flw     %0,  544(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 888:	3174                	fld	f13,224(x10)
 88a:	5f36                	lw	x30,108(x2)
  asm volatile("flw     %0,  544(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 88c:	0074                	addi	x13,x2,12
 88e:	5f5f 6e69 5f74      	0x5f746e695f5f
  asm volatile("flw     %0,  548(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 894:	656c                	flw	f11,76(x10)
 896:	7361                	lui	x6,0xffff8
  asm volatile("flw     %0,  548(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 898:	3374                	fld	f13,224(x14)
 89a:	5f32                	lw	x30,44(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 89c:	0074                	addi	x13,x2,12
 89e:	5f5f 6e69 5f74      	0x5f746e695f5f
  asm volatile("flw     %0,  552(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 8a4:	656c                	flw	f11,76(x10)
 8a6:	7361                	lui	x6,0xffff8
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 8a8:	3674                	fld	f13,232(x12)
 8aa:	5f34                	lw	x13,120(x14)
  asm volatile("flw     %0,  556(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 8ac:	0074                	addi	x13,x2,12
 8ae:	5f5f 6e69 6d74      	0x6d746e695f5f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 8b4:	7861                	lui	x16,0xffff8
 8b6:	745f 5f00 695f      	0x695f5f00745f
  asm volatile("flw     %0,  560(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 8bc:	746e                	flw	f8,248(x2)
 8be:	7470                	flw	f12,108(x8)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 8c0:	5f72                	lw	x30,60(x2)
 8c2:	0074                	addi	x13,x2,12
 8c4:	5f5f 6975 746e      	0x746e69755f5f
  asm volatile("flw     %0,  564(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 8ca:	5f38                	lw	x14,120(x14)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 8cc:	0074                	addi	x13,x2,12
 8ce:	6e75                	lui	x28,0x1d
  asm volatile("flw     %0,  568(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 8d0:	6e676973          	csrrsi	x18,0x6e6,14
  asm volatile("flw     %0,  568(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 8d4:	6465                	lui	x8,0x19
 8d6:	7320                	flw	f8,96(x14)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 8d8:	6f68                	flw	f10,92(x14)
 8da:	7472                	flw	f8,60(x2)
  asm volatile("flw     %0,  572(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 8dc:	5f00                	lw	x8,56(x14)
 8de:	755f 6e69 3174      	0x31746e69755f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 8e4:	5f36                	lw	x30,108(x2)
 8e6:	0074                	addi	x13,x2,12
 8e8:	5f5f 6975 746e      	0x746e69755f5f
  asm volatile("flw     %0,  576(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 8ee:	3436                	fld	f8,360(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 8f0:	745f 7500 6e69      	0x6e697500745f
  asm volatile("flw     %0,  580(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 8f6:	5f74                	lw	x13,124(x14)
  asm volatile("flw     %0,  580(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 8f8:	6166                	flw	f2,88(x2)
 8fa:	5f387473          	csrrci	x8,0x5f3,16
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 8fe:	0074                	addi	x13,x2,12
 900:	6975                	lui	x18,0x1d
  asm volatile("flw     %0,  584(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 902:	746e                	flw	f8,248(x2)
  asm volatile("flw     %0,  584(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 904:	665f 7361 3174      	0x31747361665f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 90a:	5f36                	lw	x30,108(x2)
  asm volatile("flw     %0,  588(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 90c:	0074                	addi	x13,x2,12
 90e:	6975                	lui	x18,0x1d
  asm volatile("flw     %0,  588(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 910:	746e                	flw	f8,248(x2)
 912:	665f 7361 3374      	0x33747361665f
  asm volatile("flw     %0,  592(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 918:	5f32                	lw	x30,44(x2)
 91a:	0074                	addi	x13,x2,12
 91c:	6975                	lui	x18,0x1d
  asm volatile("flw     %0,  592(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 91e:	746e                	flw	f8,248(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 920:	665f 7361 3674      	0x36747361665f
  asm volatile("flw     %0,  596(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 926:	5f34                	lw	x13,120(x14)
  asm volatile("flw     %0,  596(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 928:	0074                	addi	x13,x2,12
 92a:	5f5f 6975 746e      	0x746e69755f5f
  asm volatile("flw     %0,  600(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 930:	6c5f 6165 7473      	0x747361656c5f
  asm volatile("flw     %0,  600(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 936:	5f38                	lw	x14,120(x14)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 938:	0074                	addi	x13,x2,12
 93a:	5f5f 6975 746e      	0x746e69755f5f
  asm volatile("flw     %0,  604(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 940:	6c5f 6165 7473      	0x747361656c5f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 946:	3631                	jal	452 <kernel_energy_fadd_demo+0x272>
  asm volatile("flw     %0,  608(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 948:	745f 5f00 755f      	0x755f5f00745f
  asm volatile("flw     %0,  608(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 94e:	6e69                	lui	x28,0x1a
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 950:	5f74                	lw	x13,124(x14)
 952:	656c                	flw	f11,76(x10)
  asm volatile("flw     %0,  612(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 954:	7361                	lui	x6,0xffff8
 956:	3374                	fld	f13,224(x14)
  asm volatile("flw     %0,  612(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 958:	5f32                	lw	x30,44(x2)
 95a:	0074                	addi	x13,x2,12
 95c:	5f5f 6975 746e      	0x746e69755f5f
  asm volatile("flw     %0,  616(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 962:	6c5f 6165 7473      	0x747361656c5f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 968:	3436                	fld	f8,360(x2)
 96a:	745f 5f00 755f      	0x755f5f00745f
  asm volatile("flw     %0,  620(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 970:	6e69                	lui	x28,0x1a
 972:	6d74                	flw	f13,92(x10)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 974:	7861                	lui	x16,0xffff8
 976:	745f 5f00 755f      	0x755f5f00745f
  asm volatile("flw     %0,  624(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 97c:	6e69                	lui	x28,0x1a
 97e:	7074                	flw	f13,100(x8)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 980:	7274                	flw	f13,100(x12)
 982:	745f 5f00 4e5a      	0x4e5a5f00745f
  asm volatile("flw     %0,  628(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 988:	3531                	jal	794 <kernel_energy_fadd_demo+0x5b4>
 98a:	7362                	flw	f6,56(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 98c:	6f725f67          	0x6f725f67
  asm volatile("flw     %0,  632(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 990:	61625f77          	0x61625f77
  asm volatile("flw     %0,  632(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 994:	7272                	flw	f4,60(x2)
 996:	6569                	lui	x10,0x1a
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 998:	4972                	lw	x18,28(x2)
 99a:	694c                	flw	f11,20(x10)
  asm volatile("flw     %0,  636(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 99c:	4531                	li	x10,12
 99e:	4345                	li	x6,17
  asm volatile("flw     %0,  636(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 9a0:	4532                	lw	x10,12(x2)
 9a2:	0076                	c.slli	x0,0x1d
 9a4:	6874                	flw	f13,84(x8)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 9a6:	7369                	lui	x6,0xffffa
  asm volatile("flw     %0,  640(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 9a8:	5f00                	lw	x8,56(x14)
 9aa:	4e5a                	lw	x28,148(x2)
  asm volatile("flw     %0,  640(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 9ac:	3131                	jal	5b8 <kernel_energy_fadd_demo+0x3d8>
 9ae:	7362                	flw	f6,56(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 9b0:	61625f67          	0x61625f67
  asm volatile("flw     %0,  644(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 9b4:	7272                	flw	f4,60(x2)
 9b6:	6569                	lui	x10,0x1a
  asm volatile("flw     %0,  644(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 9b8:	4972                	lw	x18,28(x2)
 9ba:	694c                	flw	f11,20(x10)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 9bc:	4531                	li	x10,12
 9be:	694c                	flw	f11,20(x10)
  asm volatile("flw     %0,  648(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 9c0:	4531                	li	x10,12
 9c2:	4345                	li	x6,17
  asm volatile("flw     %0,  648(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 9c4:	4532                	lw	x10,12(x2)
 9c6:	0076                	c.slli	x0,0x1d
 9c8:	5f5f 7863 5f78      	0x5f7878635f5f
  asm volatile("flw     %0,  652(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 9ce:	626f6c67          	0x626f6c67
  asm volatile("flw     %0,  652(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 9d2:	6c61                	lui	x24,0x18
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 9d4:	765f 7261 695f      	0x695f7261765f
  asm volatile("flw     %0,  656(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 9da:	696e                	flw	f18,216(x2)
  asm volatile("flw     %0,  656(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 9dc:	0074                	addi	x13,x2,12
 9de:	0069                	c.nop	26
 9e0:	5a5f 314e 6235      	0x6235314e5a5f
  asm volatile("flw     %0,  660(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 9e6:	635f6773          	csrrsi	x14,0x635,30
  asm volatile("flw     %0,  660(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 9ea:	625f6c6f          	jal	x24,f780e <_bsg_elf_stack_ptr+0xf6812>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 9ee:	7261                	lui	x4,0xffff8
  asm volatile("flw     %0,  664(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 9f0:	6972                	flw	f18,28(x2)
 9f2:	7265                	lui	x4,0xffff9
  asm volatile("flw     %0,  664(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 9f4:	4c49                	li	x24,18
 9f6:	3169                	jal	680 <kernel_energy_fadd_demo+0x4a0>
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 9f8:	4545                	li	x10,17
 9fa:	76453243          	fmadd.q	f4,f10,f4,f14,rup
  asm volatile("flw     %0,  668(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 9fe:	6b00                	flw	f8,16(x14)
  asm volatile("flw     %0,  668(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a00:	7265                	lui	x4,0xffff9
 a02:	656e                	flw	f10,216(x2)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a04:	5f6c                	lw	x11,124(x14)
 a06:	6e65                	lui	x28,0x19
  asm volatile("flw     %0,  672(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a08:	7265                	lui	x4,0xffff9
 a0a:	665f7967          	0x665f7967
  asm volatile("flw     %0,  672(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a0e:	6461                	lui	x8,0x18
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a10:	5f64                	lw	x9,124(x14)
 a12:	6564                	flw	f9,76(x10)
  asm volatile("flw     %0,  676(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a14:	6f6d                	lui	x30,0x1b
 a16:	5f00                	lw	x8,56(x14)
  asm volatile("flw     %0,  676(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a18:	424f4c47          	fmsub.d	f24,f30,f4,f8,rmm
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a1c:	4c41                	li	x24,16
 a1e:	5f5f 7573 5f62      	0x5f6275735f5f
  asm volatile("flw     %0,  680(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a24:	5f49                	li	x30,-14
 a26:	6e72656b          	0x6e72656b
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a2a:	6c65                	lui	x24,0x19
  asm volatile("flw     %0,  684(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a2c:	632e                	flw	f6,200(x2)
 a2e:	7070                	flw	f12,100(x8)
  asm volatile("flw     %0,  684(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a30:	4100                	lw	x8,0(x10)
 a32:	735f 6d70 4200      	0x42006d70735f
  asm volatile("flw     %0,  688(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a38:	735f 6d70 4100      	0x41006d70735f
  asm volatile("flw     %0,  688(%1)"   : "=f"(B_tmp) : "r"(B_ptr) : "memory");
 a3e:	4200                	lw	x8,0(x12)
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a40:	4300                	lw	x8,0(x14)
 a42:	4e00                	lw	x8,24(x12)
  asm volatile("flw     %0,  692(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a44:	4200                	lw	x8,0(x12)
 a46:	705f 7274 4100      	0x41007274705f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a4c:	705f 7274 4300      	0x43007274705f
  asm volatile("flw     %0,  696(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a52:	745f 706d 4100      	0x4100706d745f
  asm volatile("fadd.s  %0, %1, %2"     : "+f"(C_tmp) : "f"(A_tmp),  "f"(B_tmp));
 a58:	745f 706d 4200      	0x4200706d745f
  asm volatile("flw     %0,  700(%1)"   : "=f"(A_tmp) : "r"(A_ptr) : "memory");
 a5e:	745f 706d       	0x706d745f

Disassembly of section .debug_loc:

00000000 <.debug_loc>:
  li  x1, 0
   0:	003c                	addi	x15,x2,8
   2:	0000                	unimp
  li  x3, 0
   4:	0044                	addi	x9,x2,4
   6:	0000                	unimp
  li  x4, 0
   8:	0002                	c.slli64	x0
   a:	9f30                	0x9f30
	...
  li  x7, 0
  14:	0f2c                	addi	x11,x2,920
  16:	0000                	unimp
  li  x8, 0
  18:	0f38                	addi	x14,x2,920
  1a:	0000                	unimp
  li  x9, 0
  1c:	0005                	c.nop	1
  1e:	00004403          	lbu	x8,0(x0) # 0 <_bsg_data_start_addr>
	...
  li  x12,0
  2a:	d000                	sw	x8,32(x8)
  li  x13,0
  2c:	0001                	nop
  2e:	dc00                	sw	x8,56(x8)
  li  x14,0
  30:	0001                	nop
  32:	0500                	addi	x8,x2,640
  li  x15,0
  34:	0300                	addi	x8,x2,384
  36:	0044                	addi	x9,x2,4
	...
  li  x18,0
  40:	0000                	unimp
  42:	003c                	addi	x15,x2,8
  li  x19,0
  44:	0000                	unimp
  46:	0048                	addi	x10,x2,4
  li  x20,0
  48:	0000                	unimp
  4a:	0001                	nop
  li  x21,0
  4c:	005a                	c.slli	x0,0x16
  4e:	0000                	unimp
  li  x22,0
  50:	0000                	unimp
  52:	0000                	unimp
  li  x23,0
  54:	3c00                	fld	f8,56(x8)
  56:	0000                	unimp
  li  x24,0
  58:	4c00                	lw	x8,24(x8)
  5a:	000c                	0xc
  li  x25,0
  5c:	0100                	addi	x8,x2,128
  5e:	5b00                	lw	x8,48(x14)
	...
  li  x29,0
  6c:	0c58                	addi	x14,x2,532
  6e:	0000                	unimp
  li  x30,0
  70:	0001                	nop
  72:	005c                	addi	x15,x2,4
	...
  csrs mstatus, t0 # enable FPU
  7c:	0000                	unimp
  7e:	1400                	addi	x8,x2,544
  fscsr x0
  80:	0000                	unimp
  82:	0100                	addi	x8,x2,128
  li t0, 0
  84:	5d00                	lw	x8,56(x10)
	...
  8e:	003c                	addi	x15,x2,8
  fcvt.s.w f2, x0 
  90:	0000                	unimp
  92:	0c58                	addi	x14,x2,532
  fcvt.s.w f3, x0 
  94:	0000                	unimp
  96:	08720003          	lb	x0,135(x4) # ffff9087 <_bsg_dram_end_addr+0x7eff9087>
  fcvt.s.w f4, x0 
  9a:	009f 0000 0000      	0x9f
  fcvt.s.w f6, x0 
  a0:	0000                	unimp
  a2:	3c00                	fld	f8,56(x8)
  fcvt.s.w f7, x0 
  a4:	0000                	unimp
  a6:	5800                	lw	x8,48(x8)
  fcvt.s.w f8, x0 
  a8:	000c                	0xc
  aa:	0400                	addi	x8,x2,512
  fcvt.s.w f9, x0 
  ac:	7200                	flw	f8,32(x12)
  ae:	0884                	addi	x9,x2,80
  fcvt.s.w f10,x0 
  b0:	009f 0000 0000      	0x9f
  fcvt.s.w f11,x0 
  b6:	0000                	unimp
  fcvt.s.w f12,x0 
  b8:	1400                	addi	x8,x2,544
  ba:	0000                	unimp
  fcvt.s.w f13,x0 
  bc:	5400                	lw	x8,40(x8)
  be:	0000                	unimp
  fcvt.s.w f14,x0 
  c0:	0200                	addi	x8,x2,256
  c2:	3000                	fld	f8,32(x8)
  fcvt.s.w f15,x0 
  c4:	549f 0000 5800      	0x58000000549f
  fcvt.s.w f16,x0 
  ca:	000c                	0xc
  fcvt.s.w f17,x0 
  cc:	0200                	addi	x8,x2,256
  ce:	9000                	0x9000
  fcvt.s.w f18,x0 
  d0:	0020                	addi	x8,x2,8
  d2:	0000                	unimp
  fcvt.s.w f19,x0 
  d4:	0000                	unimp
  d6:	0000                	unimp
  fcvt.s.w f20,x0 
  d8:	1c00                	addi	x8,x2,560
  da:	0000                	unimp
  fcvt.s.w f21,x0 
  dc:	2c00                	fld	f8,24(x8)
  de:	0000                	unimp
  fcvt.s.w f22,x0 
  e0:	0200                	addi	x8,x2,256
  e2:	9000                	0x9000
  fcvt.s.w f23,x0 
  e4:	4420                	lw	x8,72(x8)
  e6:	0000                	unimp
  fcvt.s.w f24,x0 
  e8:	5800                	lw	x8,48(x8)
  ea:	000c                	0xc
  fcvt.s.w f25,x0 
  ec:	0200                	addi	x8,x2,256
  ee:	9000                	0x9000
  fcvt.s.w f26,x0 
  f0:	0021                	c.nop	8
  f2:	0000                	unimp
  fcvt.s.w f27,x0 
  f4:	0000                	unimp
  f6:	0000                	unimp
  fcvt.s.w f28,x0 
  f8:	2c00                	fld	f8,24(x8)
  fa:	0000                	unimp
  fcvt.s.w f29,x0 
  fc:	4800                	lw	x8,16(x8)
  fe:	0000                	unimp
  fcvt.s.w f30,x0 
 100:	0200                	addi	x8,x2,256
 102:	9000                	0x9000
  fcvt.s.w f31,x0 
 104:	4820                	lw	x8,80(x8)
 106:	0000                	unimp
  la gp, _gp
 108:	5800                	lw	x8,48(x8)
 10a:	000c                	0xc
 10c:	0200                	addi	x8,x2,256
 10e:	9000                	0x9000
  la  tp, _bsg_data_end_addr + 63
 110:	0022                	c.slli	x0,0x8
 112:	0000                	unimp
 114:	0000                	unimp
 116:	0000                	unimp
  and tp, tp, -64
 118:	6000                	flw	f8,0(x8)
 11a:	000c                	0xc
  la sp, _sp
 11c:	7c00                	flw	f8,56(x8)
 11e:	000c                	0xc
 120:	0300                	addi	x8,x2,384
 122:	1100                	addi	x8,x2,160
  j main
 124:	9f01                	0x9f01
 126:	0c7c                	addi	x15,x2,540
  bsg_remote_store(0,0,bsg_x_v,0);
 128:	0000                	unimp
 12a:	0c90                	addi	x12,x2,592
 12c:	0000                	unimp
 12e:	00110003          	lb	x0,1(x2)
 132:	009f 0000 0000      	0x9f
 138:	0000                	unimp
 13a:	6000                	flw	f8,0(x8)
  bsg_remote_store(0,0,bsg_y_v,0);
 13c:	000c                	0xc
 13e:	7400                	flw	f8,40(x8)
 140:	000c                	0xc
 142:	0300                	addi	x8,x2,384
  bsg_wait_while(*bsg_x_v < 0);
 144:	1100                	addi	x8,x2,160
 146:	9f01                	0x9f01
 148:	0c74                	addi	x13,x2,540
 14a:	0000                	unimp
  bsg_wait_while(*bsg_y_v < 0);
 14c:	0c90                	addi	x12,x2,592
 14e:	0000                	unimp
 150:	00110003          	lb	x0,1(x2)
  if (!*bsg_x_v && !*bsg_y_v)
 154:	009f 0000 0000      	0x9f
 15a:	0000                	unimp
 15c:	6000                	flw	f8,0(x8)
 15e:	000c                	0xc
 160:	6400                	flw	f8,8(x8)
 162:	000c                	0xc
        bsg_remote_store(x,y,bsg_x_v,x);
 164:	0300                	addi	x8,x2,384
 166:	1100                	addi	x8,x2,160
        bsg_remote_store(x,y,bsg_y_v,y);
 168:	9f01                	0x9f01
 16a:	0c64                	addi	x9,x2,540
  grp_org_x_p = bsg_remote_ptr_control( __bsg_x, __bsg_y, CSR_TGO_X );
 16c:	0000                	unimp
 16e:	0c90                	addi	x12,x2,592
 170:	0000                	unimp
 172:	00110003          	lb	x0,1(x2)
 176:	009f 0000 0000      	0x9f
 17c:	0000                	unimp
 17e:	6000                	flw	f8,0(x8)
 180:	000c                	0xc
 182:	9000                	0x9000
 184:	000c                	0xc
 186:	0100                	addi	x8,x2,128
 188:	5b00                	lw	x8,48(x14)
	...
 192:	0c60                	addi	x8,x2,540
  grp_org_y_p = bsg_remote_ptr_control( __bsg_x, __bsg_y, CSR_TGO_Y );
 194:	0000                	unimp
 196:	0c90                	addi	x12,x2,592
  __bsg_grp_org_x  = * grp_org_x_p;
 198:	0000                	unimp
 19a:	0001                	nop
  __bsg_grp_org_y  = * grp_org_y_p;
 19c:	0000005b          	0x5b
  __bsg_id = __bsg_y * bsg_tiles_X + __bsg_x;
 1a0:	0000                	unimp
 1a2:	0000                	unimp
  __bsg_grid_dim_x = 1;
 1a4:	7c00                	flw	f8,56(x8)
 1a6:	000c                	0xc
  __bsg_grp_org_y  = * grp_org_y_p;
 1a8:	9000                	0x9000
 1aa:	000c                	0xc
  __bsg_id = __bsg_y * bsg_tiles_X + __bsg_x;
 1ac:	0100                	addi	x8,x2,128
 1ae:	5b00                	lw	x8,48(x14)
	...
 1b8:	0c84                	addi	x9,x2,592
  __bsg_tile_group_id_x = 0;
 1ba:	0000                	unimp
  __bsg_tile_group_id_y = 0;
 1bc:	0c88                	addi	x10,x2,592
 1be:	0000                	unimp
  __bsg_tile_group_id = 0;
 1c0:	00110003          	lb	x0,1(x2)
}
 1c4:	889f 000c 9000      	0x9000000c889f
  if (__bsg_id == 0) 
 1ca:	000c                	0xc
 1cc:	0300                	addi	x8,x2,384
 1ce:	1100                	addi	x8,x2,160
     *signal_ptr = cuda_finish_signal_val;     
 1d0:	9f01                	0x9f01
	...
 1da:	0c84                	addi	x9,x2,592
}
 1dc:	0000                	unimp
 1de:	0c90                	addi	x12,x2,592
int kernel_energy_fadd_demo(float *A, float *B, float *C, int N) {
 1e0:	0000                	unimp
 1e2:	087b0003          	lb	x0,135(x22)
 1e6:	009f 0000 0000      	0x9f
 1ec:	0000                	unimp
	...

Disassembly of section .comment:

00000000 <.comment>:
  li  x1, 0
   0:	3a434347          	fmsub.d	f6,f6,f4,f7,rmm
  li  x3, 0
   4:	2820                	fld	f8,80(x8)
   6:	29554e47          	fmsub.s	f28,f10,f21,f5,rmm
  li  x4, 0
   a:	3920                	fld	f8,112(x10)
  li  x5, 0
   c:	322e                	fld	f4,232(x2)
   e:	302e                	fld	f0,232(x2)
  li  x6, 0
  10:	6300                	flw	f8,0(x14)
  12:	616c                	flw	f11,68(x10)
  li  x7, 0
  14:	676e                	flw	f14,216(x2)
  16:	7620                	flw	f8,104(x12)
  li  x8, 0
  18:	7265                	lui	x4,0xffff9
  1a:	6e6f6973          	csrrsi	x18,0x6e6,30
  li  x9, 0
  1e:	3120                	fld	f8,96(x10)
  li  x10,0
  20:	2e30                	fld	f12,88(x12)
  22:	2e30                	fld	f12,88(x12)
  li  x11,0
  24:	2030                	fld	f12,64(x8)
  26:	6828                	flw	f10,80(x8)
  li  x12,0
  28:	7474                	flw	f13,108(x8)
  2a:	7370                	flw	f12,100(x14)
  li  x13,0
  2c:	2f3a                	fld	f30,392(x2)
  2e:	7469672f          	0x7469672f
  li  x14,0
  32:	7568                	flw	f10,108(x10)
  li  x15,0
  34:	2e62                	fld	f28,24(x2)
  36:	2f6d6f63          	bltu	x26,x22,334 <kernel_energy_fadd_demo+0x154>
  li  x16,0
  3a:	6562                	flw	f10,24(x2)
  li  x17,0
  3c:	6b6f7073          	csrci	0x6b6,30
  li  x18,0
  40:	2d65                	jal	6f8 <kernel_energy_fadd_demo+0x518>
  42:	696c6973          	csrrsi	x18,0x696,24
  li  x19,0
  46:	2d6e6f63          	bltu	x28,x22,324 <kernel_energy_fadd_demo+0x144>
  li  x20,0
  4a:	756f7267          	0x756f7267
  li  x21,0
  4e:	2f70                	fld	f12,216(x14)
  li  x22,0
  50:	6c6c                	flw	f11,92(x8)
  52:	6d76                	flw	f26,92(x2)
  li  x23,0
  54:	702d                	c.lui	x0,0xfffeb
  56:	6f72                	flw	f30,28(x2)
  li  x24,0
  58:	656a                	flw	f10,152(x2)
  5a:	672e7463          	bgeu	x28,x18,6c2 <kernel_energy_fadd_demo+0x4e2>
  li  x25,0
  5e:	7469                	lui	x8,0xffffa
  li  x26,0
  60:	3220                	fld	f8,96(x12)
  62:	6536                	flw	f10,76(x2)
  li  x27,0
  64:	3064                	fld	f9,224(x8)
  66:	3462                	fld	f8,56(x2)
  li  x28,0
  68:	6636                	flw	f12,76(x2)
  6a:	6334                	flw	f13,64(x14)
  li  x29,0
  6c:	6336                	flw	f6,76(x2)
  6e:	3630                	fld	f12,104(x12)
  li  x30,0
  70:	3461                	jal	fffffaf8 <_bsg_dram_end_addr+0x7efffaf8>
  72:	6666                	flw	f12,88(x2)
  li  x31,0
  74:	65323437          	lui	x8,0x65323
  li t0, 0x00003000 # mstatus.FS
  78:	3966                	fld	f18,120(x2)
  7a:	6539                	lui	x10,0xe
  csrs mstatus, t0 # enable FPU
  7c:	3138                	fld	f14,96(x10)
  7e:	6230                	flw	f12,64(x12)
  fscsr x0
  80:	62373337          	lui	x6,0x62373
  li t0, 0
  84:	6431                	lui	x8,0xc
  86:	6138                	flw	f14,64(x10)
  fcvt.s.w f0, x0 
  88:	2932                	fld	f18,264(x2)
	...

Disassembly of section .riscv.attributes:

00000000 <.riscv.attributes>:
  li  x1, 0
   0:	2a41                	jal	190 <bsg_set_tile_x_y+0x68>
   2:	0000                	unimp
  li  x3, 0
   4:	7200                	flw	f8,32(x12)
   6:	7369                	lui	x6,0xffffa
  li  x4, 0
   8:	01007663          	bgeu	x0,x16,14 <__bsg_grid_dim_y>
  li  x5, 0
   c:	0020                	addi	x8,x2,8
   e:	0000                	unimp
  li  x6, 0
  10:	1004                	addi	x9,x2,32
  12:	7205                	lui	x4,0xfffe1
  li  x7, 0
  14:	3376                	fld	f6,376(x2)
  16:	6932                	flw	f18,12(x2)
  li  x8, 0
  18:	7032                	flw	f0,44(x2)
  1a:	5f30                	lw	x12,120(x14)
  li  x9, 0
  1c:	326d                	jal	fffff9c6 <_bsg_dram_end_addr+0x7efff9c6>
  1e:	3070                	fld	f12,224(x8)
  li  x10,0
  20:	615f 7032 5f30      	0x5f307032615f
  li  x11,0
  26:	3266                	fld	f4,120(x2)
  li  x12,0
  28:	3070                	fld	f12,224(x8)
	...

Disassembly of section .debug_frame:

00000000 <.debug_frame>:
  li  x1, 0
   0:	000c                	0xc
   2:	0000                	unimp
  li  x3, 0
   4:	ffff                	0xffff
   6:	ffff                	0xffff
  li  x4, 0
   8:	0001                	nop
   a:	7c01                	lui	x24,0xfffe0
  li  x5, 0
   c:	0d01                	addi	x26,x26,0
   e:	0002                	c.slli64	x0
  li  x6, 0
  10:	000c                	0xc
  12:	0000                	unimp
  li  x7, 0
  14:	0000                	unimp
  16:	0000                	unimp
  li  x8, 0
  18:	0128                	addi	x10,x2,136
  1a:	0000                	unimp
  li  x9, 0
  1c:	00a0                	addi	x8,x2,72
  1e:	0000                	unimp
  li  x10,0
  20:	000c                	0xc
  22:	0000                	unimp
  li  x11,0
  24:	ffff                	0xffff
  26:	ffff                	0xffff
  li  x12,0
  28:	0001                	nop
  2a:	7c01                	lui	x24,0xfffe0
  li  x13,0
  2c:	0d01                	addi	x26,x26,0
  2e:	0002                	c.slli64	x0
  li  x14,0
  30:	000c                	0xc
  32:	0000                	unimp
  li  x15,0
  34:	0020                	addi	x8,x2,8
  36:	0000                	unimp
  li  x16,0
  38:	01c8                	addi	x10,x2,196
  3a:	0000                	unimp
  li  x17,0
  3c:	0018                	0x18
  3e:	0000                	unimp
  li  x18,0
  40:	000c                	0xc
  42:	0000                	unimp
  li  x19,0
  44:	0020                	addi	x8,x2,8
  46:	0000                	unimp
  li  x20,0
  48:	0e70                	addi	x12,x2,796
  4a:	0000                	unimp
  li  x21,0
  4c:	00d4                	addi	x13,x2,68
  4e:	0000                	unimp
  50:	0010                	0x10
  li  x22,0
  52:	0000                	unimp
  li  x23,0
  54:	ffff                	0xffff
  56:	ffff                	0xffff
  li  x24,0
  58:	0004                	0x4
  5a:	0004                	0x4
  li  x25,0
  5c:	7c01                	lui	x24,0xfffe0
  5e:	0c01                	addi	x24,x24,0
  li  x26,0
  60:	0002                	c.slli64	x0
  62:	0000                	unimp
  li  x27,0
  64:	0010                	0x10
  66:	0000                	unimp
  li  x28,0
  68:	0050                	addi	x12,x2,4
  6a:	0000                	unimp
  li  x29,0
  6c:	01e0                	addi	x8,x2,204
  6e:	0000                	unimp
  li  x30,0
  70:	0c58                	addi	x14,x2,532
  72:	0000                	unimp
  li  x31,0
  74:	0e44                	addi	x9,x2,788
  76:	1080                	addi	x8,x2,96
  li t0, 0x00003000 # mstatus.FS
  78:	000c                	0xc
  7a:	0000                	unimp
  csrs mstatus, t0 # enable FPU
  7c:	0050                	addi	x12,x2,4
  7e:	0000                	unimp
  fscsr x0
  80:	0e38                	addi	x14,x2,792
  82:	0000                	unimp
  li t0, 0
  84:	0038                	addi	x14,x2,8
	...

Disassembly of section .debug_ranges:

00000000 <.debug_ranges>:
  li  x1, 0
   0:	01c8                	addi	x10,x2,196
   2:	0000                	unimp
  li  x3, 0
   4:	01e0                	addi	x8,x2,204
   6:	0000                	unimp
  li  x4, 0
   8:	0e70                	addi	x12,x2,796
   a:	0000                	unimp
  li  x5, 0
   c:	0f44                	addi	x9,x2,916
	...
